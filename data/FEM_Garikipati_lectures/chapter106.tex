\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{bbold}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{arydshln}
\graphicspath{ {./images/} }

\title{Transcripts}

\date{}

%New command to display footnote whose markers will always be hidden
\let\svthefootnote\thefootnote
\newcommand\blfootnotetext[1]{%
  \let\thefootnote\relax\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \let\thefootnote\svthefootnote%
}

%Overriding the \footnotetext command to hide the marker if its value is `0`
\let\svfootnotetext\footnotetext
\renewcommand\footnotetext[2][?]{%
  \if\relax#1\relax%
    \ifnum\value{footnote}=0\blfootnotetext{#2}\else\svfootnotetext{#2}\fi%
  \else%
    \if?#1\ifnum\value{footnote}=0\blfootnotetext{#2}\else\svfootnotetext{#2}\fi%
    \else\svfootnotetext[#1]{#2}\fi%
  \fi
}

\begin{document}

\section*{ID: oCm0rxmWrxs}
Okay, so we have an isoparametric mapping. For geometry. All right. So that says, as we know very well now, x sub i sub e, all right, As a function of, c vector is again obtained as a sum over the nodes, n a. Right? And now, na we know is a function of, is parametrized by the coordinates, and this by unit of mean. And we have here, xA ie, right? this is exactly the same as before. Okay, and once we have this, we know what other use we can put it to, right? Do you remember what else we do with this? All right. We use it to write out our gradients, right? So, for gradients. And what are the gradients we need when we look back at our finite dimensional weak form, we, we already see this, that sort of gradient. Right? Whi comma j. Right? This now over the element is sum over A. NA comma j, cAie, all right? I'm, I'd probably add an e in there, as well, okay, just to keep directing it. All right. And, of course, the same thing for uhi comma j. All right. Uhi comma j, is over element e. Is again, sum over A. NA comma j, dAie. Okay, And we know straightaway where we expect to use this right of course this shows up directly in the weak form, when we look at it, right, just recall. Recall the term on left-hand side in our weak form, integral over omega, whi comma j. We have sigma h, but we know of course that sigma h is just Cijkl. Okay. Sigma ijCijkl epsilon hkl. Okay? But here is where I'm going to use the, one of those properties of our, elasticity tensor. And the property I'm going to use is the fact that where as the string is properly defined as the symmetric bar to the displacement radiant. Right? That's the stream. However, because we've talked about how the elasticity tensor is Is possessed of minor symmetry in those two indices, we're actually completely free, to not worry about the symmetrization of the displacement gradient. In, in using this constitutive relation. Okay, so what I'm saying is that we are completely correct, long as we make sure that c has minor symmetry, you're completely correct in writing this as Cijkl, u,k, comma l. Okay. And, the reason for this is minor symmetry. Okay? All right? And, and, if you're wondering, yes, it is indeed of course true that, for that term also, whereas, I've just written it as a gradient of the weighting function, we would be right if we want to go the other way there, and say that it's the, it's the symmetric part of the gradient of the weighting function. All right? But we just don't need it. We can leave it this way, a minor symmetry with respect to the ij indices, which we also have, takes care of things for us. Okay. But any, but at any rate, we see clearly what gradience we need to compute, right? You should remember that k and l are of course just dummy indices because they are being summed away, right? Or even otherwise the would be dummy indices. And so when, when I say I am going to compute i comma j here it's, it's really the same. All right, so, we do need to compute gradients. But once we have our isoparametric mapping, we know how to go about that as well, right? And what we are seeing here now is that NA comma j is just NA comma xi capital I, right? Using as before, the uppercase index for coordinates in the biunit domain. You have this times the derivative of xi I. With respect to X, J. Right, for all J. As before. Alright, that's one, two, three. Okay. And of course, we know how to compute this now. Right, using the Jacobian of the mapping. All right? So, what we do here is use the Jacobian of the mapping. All right, and that, when we write it out as a matrix, is the following. Right, J. Right, depending upon the coordinates and the by-unit to me, is You know this all very well now. X 1 comma c 1, x 1 comma c 2, x 1 comma c 3 equal 1. Until we come down here and we get x of 3 comma xi 3. Right? But then of course, we also know that J inverse of C. Is. C, one, comma, X, one. Under C, three, sorry. One comma X3, and we go on. Until we come to C3 comma X3. Okay? And once again because we have only a three by three to invert here, it's actually not that hard to do it analytically. Right? So in our element formulations, as I suggested before for the steerer problems, we can do this analytically. So we thereby get each of these derivatives that we need. Right, and therefore we know how to computer the gradience. Okay, well, if we know how to compute the gradience, we can go ahead and, assemble our problem. Right, our, weak form. We do that in the next segment. We'll end this segment here.

\section*{ID: 034gY2jXGnY}
All right. So, we'll move on. We've established our finite dimensional weak form. We've looked at our basis functions. We made the somewhat important observation. That for this problem, because we have a vector problem, the number of nodes is not identical to the number of degrees of freedom. Right? But then we made the identification and we know how to relate them. All right. Let's go on. We'll get into assembling the integrals in our weak form, in our finite dimensional weak form. So, we will call this segment the element integrals. And in order to get to the element integrals, we first need to make the observation that our finite dimensional weak form. Because it is an integral over the entire domain, right? Or the boundary of the relevant Neumann boundaries also allows us under this partition to write it as a sum over a, the, the individual sub-elements, right? Or the subelement boundaries. Okay, so the finite dimensional weak form can also be written as. Sum over e, integral over omega e, w h i comma j, sigma h i comma j, dv equals sum over e, integral over omega e, w, h, i, f, i, d v. Plus, now here, we need to be a little more careful, right? We are talking here of doing the following. We are talking here of doing a sum I equals 1 to Nsd. Okay? We're summing here over our spatial dimensions. And where as earlier we could directly put down the corresponding Neumann boundary, we are going to write that also as that integral also as a sum over sub-integrals, right? Each of them is a boundary. So we need to say here that we are going to take the sum, not over all the elements, but the elements belonging to let me see, right, En, right? Remember, E was a set of elements that had one of their boundaries coincide with a Neumann boundary. All very well except that that too needs to be indexed by the spatial dimension. All right? Because for each of the i's, i equals 1, 2, 3. We could have a different set of elements whose boundaries coincide with the Neumann boundary for that particular dimension. All right? Okay. So we have that and then the integral is over partial omega t bar, I, and I'll put the E up there. All right. And this, of course, is the same whi t, bar I, d of S. Right? And all right, so this is what we have. What we are going to do is just as before, assemble each of these integrals over the elements of domains, or in this case, over the special element boundary sub-domain. Right? And of course we are also going to use the fact that this is given to us by B, elasticity tensor, now multiplying U, K, comma F. All right. Okay. So, we're, we're going to proceed with this now. So, we've, we will as always start with the, with the left hand side integrals, consider first integral over omega e, w h i comma j I'm going to directly go to the representation including the elasticity tensor. Okay, so sigma h i g. Oh, if I'm going to use the sigma h, I need to have an h there, all right. Because that's where the finite dimensionality of this comes in. Okay, so we have here C, i, j, k, l, u, h, k,I dv, right? Now on a previous slide, belonging to the previous segment, we wrote out the, the expansions for w h, and sort of, for the gradient of w h and for the gradient of u h. We will now invoke both, right, and in doing so, I'm going to write it here. We have here again, allow me to skip, well, okay. Mm, I won't skip a step right away. going to write this as integral over omega e, the w h, w h i comma j, is written as sum over A, N A, comma j CA I E, okay? This is whi, j, and I put it in parentheses. We have here C, I, J, K, L. And again we have sum over B, N D. Now, the gradient is represented as A, using the coordinate of direction L. And of course it's, L runs over 1, 2, 3. So that means n b here has to take a comma l, right, that's where the gradient is computed. And we have d b k e d v, okay. Now if you were go back and stare at the way we did the corresponding step for our scalar 3D problems, you would see something very similar except the fact that we had no index on the degree of freedom, degrees of freedom for the reading function. Nor on the degrees of freedom for the trial solution for the displacement field, okay. The fact that we do have indices here, comes from the fact that these are actual vector degrees of freedom. And i and k here both run over one two three. And the fact that we have those indices also shows up in the fact that we have a couple of extra indices here, right. The coefficient there, if you want to think about it as that. The elasticity's tensor's actually coefficient of elasticity, is a full taut tensor unlike the conductivity tensor or the diffusivity tensor, which are second order indices, all right. So that's, that's really all there is. And once we take, once we understand that, and we are comfortable with that bookkeeping essentially, all is well, all right. So we proceed, and as you may imagine, what is the next step here? Or as, as you may recall, what is the next step? Right. It is to observe that the degrees of freedom, nevermind the fact that they're vectors now are still, after all, independent of position, all right. And so they can be pulled out of our integral. And in doing so, we can also because integration and summation in this case commute because of linearity and all that. We can pull those summations also outside the integral, right? Okay. What that gives us is. Now I am going to write this as a sum over A and B. And let's recall, let's remember just here that A and B run over 1 to number of nodes in the element, right? Integral, oh, sorry. We need to have here c A i e, okay? I have here, NA comma j, okay, C i j k L, right? And for our representation of the gradient of the displacement, from that representation of the gradient of the displacement, we get an NB comma L here. Okay? Our dV, all right, I'll put a parenthesis here, or pair of parentheses. And, all right. What we've done in the process is pull the d B k e out, okay. Right? Straightforward enough. Oh, this is an integral over omega e, right? To proceed, and remember that we know how to compute these gradients, right? We looked at that on a, at the end of the last segment, right? So we know how to compute these gradients, no problem, all right. Let's move on. Remember what the next step is, right? It is to convert it to, we, we carry out a change of variables and rewrite the integral here as an integral of the bi unit domain. So, once again, sum over A and B, and I'll forgo writing the limits of that sum. We get here c A i e integral over omega xi, all right. That's our parent domain. N A comma j, C i j k L, N B comma l, right. Now, just as before, d V can be written as determinant of the Jacobian of the mapping. D V sub, thing was putting it there, right? Okay, now, of course, I could rewrite this in another step by specifying that this integral over omega C really in, involves integrals of C1, C2, and C3. It's a triple integral, each one of them going between minus one and one, and the fact that this is essentially d xi, d xi2, d xi3, all right? And this integral basically becomes something like, it becomes actually a triple integral, all right? Minus 1 to 1, minus 1 to 1, minus 1 to 1, all right? So, that, that step is given, all right? So, so well we can go ahead and compute it. Now observe that, in general, depending upon the basis functions we've chosen, whether we've, you know, decided to stick with trilinears, or tri-quadratics, or, or, or rank higher order, these are functions of c 1 c 2 c 3. Now, the way I've constructed this, I've been thinking to myself, at least, that C is independent of position. It doesn't need to be, right. In general, it, too, can be a function of position, right. That, that would allow us to go to inhomogeneous materials. Okay, all of that will simply add a higher order dependence on position to this integrant. And of course, we know that in general, the determinant would also involve a dependence upon position, okay. But nevertheless, we not integrate this, right? We can be doing numerical quadrature. Right, so we do a numerical quadrature or numerical integration, which is quadrature. Right, and since we're working here with Lagrange polynomials defined on hexahedral elements, we have available to us the optimality of Gaussian quadrature. I ought to admit here though that if our elasticity tensor has some strange dependence upon position that is not just polynomial, we made, Gaussian quadrature may not remain optimum, all right? But, but, but still, it's, it's, it's an approximation, and that approximation is understood. Okay, so essentially we know how to compute this, right? Let's com, let's assume that we, we go ahead and compute this, right? If we go ahead and compute it. Let's, let's write it out, okay? Let's write it out. And let us write it out in this fashion, okay, so. All right? So, this thing is now equal to sum over A and B, c A i e. We've carried out the integral, okay? So we have something in there. So this entire integral here that we have here, this whole entire integral, Is done. Now we could realize now that I omitted to write my DBKE here. Okay, that integral with the raised bracket is done. So when that integral is done, we will be left here with a dBke, which is this one, right? Okay. I've left a, an amount of blank space there because I want to fill it in with something and I want you to think of what kind of object goes in there. In particular, is it a scalar, a vector, or a tensor? As a guide to getting to that answer, recall that the. The integral that we are trying to work with here is the one that I am now showing to you on this slide. Right? It's the one that is written next to the word consider. What kind of an object is that? Is that integral itself, once you valuate it, is that a scalar, a vector, or tensor? All right? It is a scalar. Because though the C has fu, free indices, I, J, K, L. Those are all being contracted out, right, and a sum over each of those dummy indices, I, J, K, L is indeed implied. Okay, so what we expect to see is that this thing is a scalar. But the way we've constructed it, we see that the c A, the, the, the c and d, right. By, by c here, I mean this c, not the elasticity tensor. Degrees of freedom have indices, free indices. With the final thing should be a scalar, there have to be other three free indices in whatever object is going to go into the black space. Which will be contracted out with INK. Okay. So, whatever object we have here, I'm going to denote it as K, of course. It will also have free indices I, K. Okay? Right. And it is essentially that integral. Okay? So the integral we have here is Kik. Okay? It is a particular component, the IK component of a tensor. Right? Thought of as a matrix, it is a 3 by 3 matrix, right? Because I and K run over. 1, 2 and 3, because we're operating in three dimensions here. All right. Now there's something else I haven't added there. And can you tell me what that well can you think of what it is? The indices A and B, right, because those indices are still here. So anything that we compute for the integral is um,specific to the combination of nodes A and B, which went into that integral. Right, that, that form that intergrand. So we have an object here which, which I'm going to write as KABIK. All right? Now there are indices all over the place here. And it's useful to think to just sort this out. So when I say I comma K go 1 over 1, 2, 3. I am going to write here the, the statement that's almost a contradiction in terms which is that a sum is implied.  Okay, over IK. So I do not have an explicit summation here, but over the A and B indices, I do have an explicit summation. All right, it's, it's just a matter of taste in terms of what I choose to write as an expressed summation and which I choose to invoke the Einstein summation convention on, okay? The fact that I'm invoking Einstein's summation convention on the spacial indices, spacial dimensions comes from a sort of hangover of continuum physics.

\section*{ID: nDDY9xAGcs8}
There was a minor error in board work that remained on the slide I have before me here, and that you have on your screen. It appears right about here. That term should not be sigma h with subscripts i comma j, it should just be sigma sup h, subscripts i j. The comma would suggest that there is a derivative in the j direction, which is not correct. Notably, however, if you were to just follow what was written up here, for sigma h i j, all would have been well. Right? But nevertheless it's important to make that fix if ever you come back and look at this slide. That's it. And with that everything is, consistent.

\section*{ID: JvFTOg-Csno}
All right, so this work we have. Let's just look at this object and understand a little more about it. Okay, so one way to understand it is to realize that we could also write that as follows. Sum over A and B of a vector, c A e, right? Transpose, right? K AB, 3 by 3 tensor, d B, e, okay? And for each of them what I have here is the following. C A e, and d B e, both of which we've encountered before, and we have had occasion to note that they belong to R3. Okay? Whereas this quantity K AB, right. It is a it is a matrix right? And it belongs to GL 3, right? It is a general tensor. It does not necessarily have to be symmetric. In some special cases, it's symmetric, okay. If you go through the process, you will, you will discover later that it is symmetric for A equals B. Okay? All right, but for now it is a general, it is a generally tensor in three dimensions. All right, so hopefully this, this helps. What I've done here is get rid of the implied summation over the indices that run over spatial dimensions, and replace those with vector tensor products. Okay? Now any, so each member of the sum is indexed by A and B. Okay? Fine, so this is what we have here. Let's go through and fairly quickly compute the one of the other integral. All right, so next consider The following integral over omega e W h i, f i dV. Okay, this is the one we want to integrate now. So, we have integral over omega e. Sum over A, N A no gradient on it, C A ie. That sum gives us our waiting function components. All right. This times fi, right or this actually multiplying fi and this is sum and glide over the i dV. Using our, using our usual tricks and here I will take the liberty of skipping several steps at once. All right, and still hope to get it right. Okay. So we get sum over A, c A ie, integral over omega C, N A, fi, determinant of J C dV c. All right, and of course now we know that dv c is dc1 dc2 dc3. The integral over omega C is just the triple integral minus 1 to 1 over the 3 coordinate dimensions. Right? In the bi-unit domain. Right, okay. As before, we are going to call this integral here. We are going to denote it as F internal. All right. Note that it has a an index A coming from the fact that it was computed with the basis function corresponding to node A. And it is each F internal A is a 3 vector. Right, and this also we could write as sum over A, using the notation we used to write out our left hand side, we have C A e, transpose F internal A Okay? All right, at this point we, we've assembled the two somewhat easy integrals. We will return in the next segment to finish up the the integral involving the traction terms.

\section*{ID: puYCOSoTMrk}
All right, time now to grapple with the traction integral. So let's recall what it looks like. It is the following. It is sum over spatial dimensions. So sum now over e belonging to each of these ones, right? Of okay now and we do an integral here partial omega e t bar i w h i t bar i dS. Okay? So what that tells us is that it's really this integral that we need to consider. Okay? So we have this one Remembering that we do not have here a, a sum implied. Okay, that's straightforward. We need to do that as integral over partial omega e t bar i. For w h i, we have sum over A, NA, CA, IE. That's whi. T bar I, DS. Which is sum over A, CA ie integral partial omega E t bar I. N a, t bar i, d S. All right? And now we recall the, the cases that we've actually considered before, right? So we just need to recall them. I don't think we need to remotivate and re sort of discuss them in great detail ago, again. So the the situation that we tend to have in general is this. That is omega E. And let us consider the, the general situation where, straightaway let's consider the general situation where this face is the one of interest, right, partial omega t bar I. Okay? So what this says is that traction component i is being controlled on that surface. All right. And I've drawn it, hopefully it appears to you that it is at an angle. If that is our basis set. Okay. All right. So that is the general situation we have. Recall of course, the something we know and we have looked at before. Which is that we are somewhat saved by the fact that As I have drawn it, perhaps that one can think of that face as coming from this one. Right? So for the way I'm drawing things here, I am implying that the face of interest, is a is this face, right? It is a xi 2, xi 3 face, right? So this is partial omega xi t bar i. Sorry, t bar subscript i, for this particular element. All right?  And so it is that we know where to con, to compute this, this integral except that we also know that when it comes to constructing our mapping, we may need to to construct local coordinates just in order to, to get the, the, the Jacobian of the mapping right. Right? So, let's suppose that in this setting, I'm calling that x delta 1. And the x delta 2 direction. Right, actually those vectors really are, e, should probably be written as e tilde 1 and e tilde 2. Anyway, those are the directions that we have, okay? And from this phase to that phase, we may think of there being a map that I denote as J sub S. Okay? C. All right? Okay. So we have all that and of course, I okay. So, so let, so, so I will, I will, I'm going to use that in a second. Before I do that, I just want to point that I also need to recall that the sum over nodes may not be over all, may not need to be over every single node, right? It may need to be only over that set of nodes. Right? And previously we've used the notation that this node, A, belongs to the set A sub n. Right? To say that that is one of the nodes corresponding to a surface with a Neumann boundary condition on it. Right? So really the sum is over A sub n, as is this one. Okay? All right, so using this map, the way we would construct this integral would be this. Now, the integral here would be over partial omega c t bar i. And for the way I've drawn it here, I am suggesting that that is C2 C3. Okay? All right. That is the, that is the C2 C3. Right? So then we have here our NA, t bar i, right? And now we're going to do the integral over dS sub C, right, which is the elemental area on the partial omega c d sub d bar i. You know, face in the bi-unit domain. And I've left some blank space here because I know that I need to construct, I know that I need to put in here determinant of js. Okay? Because js maps a surface to a surface. What is the order of js? What kind of a tensor or what kind of if you think of it as a matrix, what kind of matrix is it? Js is a 2 by 2 matrix, okay? So jS, using the notation that we've used is g l 2. Right? It maps two vectors to two vectors. Okay. It's probably useful for me to point out in addition that for the way I've constructed this particular example, dsc. It's something I stated already, but what is dsc? It is dc2, dc3. Okay? And therefore that integral would be over C2 and C3 going from minus 1 to 1, all right? Okay. So we have all of this and what we need to do is essentially go ahead and construct our vector representation of this. Okay? So in constructing the, the vector representation I'm going to write this as, now, I'm going to write this as follows. I'm going to write it as a sum A belonging to A, A sub n. Okay? Okay. And we write this as CA IE. Now that entire integral once I evaluate it, I am going to write as F. I'm going to write a T bar here,which just is reminding us that this particular type of forcing vector come to us, this particular forcing, comes to us from the traction. Okay. It is the it is an I component. Okay. And it also involved node A, okay? So that entire F with all kinds of decorations on it now with subscripts and superscripts galore, actually it has just three of them. Is the result of that integral that we carried out, right? That the integral over the surface. Okay? All right, so this is what we have. Now where does this go? Remember where this all came from. And in order to remind you of it, let me just go back to the previous slide. This is where it came from. We have at the very top of our slide here. The original integral from which this came. Right? And note, in doing this, that really there is a sum over the spatial dimensions, as the outermost sum here. Okay? And then there is the inner sum over the element integrals. Okay? So, what this is suggesting is that when it comes to assembly, okay. We will first assemble the contributions from each element. And then account for the sum over the spatial dimensions. Okay? But, but before we finally do that, there is one thing we can do which is going to get us rid of the restriction to the special set A sub N. Okay, right? And what that let's, what, what that involves is the fact that okay, so let me now say let me say the following. Mm, actually let me do one thing. Let me put a bar on this F first, okay, because what I am going to do now is just rewrite that as a sum over A, okay? Now I'm going to say that this sum runs over all the nodes in the element, CA ie, F, t bar, A, i, okay? And what I mean here is that F, t bar A i equals the F bar that I calculated on, on the line above. If A belongs to AN, right? Right, and it's equal to 0 otherwise. All right and, and you would probably recall that this was the, the approach we used when we constructed the the contribution from the Neumann boundary condition, also for the, for the scale of problem. Okay? All right. So, what have we here? We are now in a position to look at our total finite dimension you'll be performing with all these element integrals accounted for. Okay, so.  Right? It is the following. We have sum over e. C e, so let me see, sum over e oh right, we have yeah, one more thing, yeah. We have sum over e, we also have a sum over A comma B, c, A, e transpose, right? K, AB, d, B e, okay, this is the contribution from the left hand integral, equals sum over e, sum over A, c A e transpose F internal A, okay? And plus sum over spatial dimensions. Then the sum over, elements belonging to the Neumann boundary condition corresponding to that particular spatial dimension, right? And all right. And then we have yet another sum here over A. Right? And this will over all the nodes c, a, i, e, f, t-bar, a, i. All right? Okay. Now, in writing all of these, I did notice a few minutes ago that when I introduced this matrix K, it really corresponds to a particular element, because it arose from a specific element integral, right? And it arose from the element integral for element e. So strictly speaking, I need to have it, an E there. It's just to remind us that it is the contribution from that particular element. Okay? Likewise here and likewise if there's any room here for more indices, for more subscripts. There we go. Okay. So this is where things stand. The next step that I'm going to take is one in which I am going to collapse, well not collapse actually. Expand out these vectors, okay. And in order to do that let's just let's go to a new slide.

\section*{ID: 9PtK8-ByJbQ}
Recall what we have here. Okay. So we have a general element, right. Now, now we are, we are, we are rid of our bi-unit domain, right. We are rid of that domain. So I have an element So I think I may have distorted a little too much, but we'll see. There we go. Okay. So, let's suppose that this is the node A. Okay? Let me look at them all. Because I do need to know. There is a node in the back here. All right. And up here we have. Okay. So this is node. Equals 1, 2, 3, 4, 5. A equals 6, 7, 8. Okay, and the situation that we have is that C A E is C a 1, C a 2, C a 3, right, for element e, right, likewise d. So we would have, look I would say like, d a e. Or d B e, that's a dummy index of course. Anyway, let's write it as d B e is equal to d B 1, d B 2, d B 3, element e. All right. Essentially what I'm going to do is to observe that now, in the case of the trilinear element. How many total scalar degrees of freedom do I have? All right. We've actually done this calculation, right. Which is that we have, Nne times Nsd degrees of freedom per element. Right? Okay, so if this is the case, what it tells us is that we can actually write a, c e vector, which we can define as basically being C 1 e. Now, note, C 1 e is a vector. It's a three vector. Okay, it is the set of, it's this vector or A equals one, and so on. C 2 e to C number of nodes in the element e. Okay? Likewise, d e, it's just the d vector. Right? It's the collection of all the degrees of freedom that are used to build or interpolate, if you want to use that term, to interpolate our trial solution, our displacement field over the element, right? Okay, so there's a collection of three vectors, so it's d 1 e, right? And, and at that node 1, we have d 1, the one direction, d 1 and the two direction d 3 and d 1 in the three direction, right? Those are the three degrees of freedom at that node, right? Okay, so we have d 1 e, d 2 e, and so on all the way up to d n, n. E and d. Right? Note that c e and d e belong to r, NNE times NSD. Okay? They are big vectors. In particular if you are doing trilineals, we have a, how many degrees of freedom on a trilinear element here, for elasticity? twenty four. Okay so what we are seeing is that twenty four degrees of freedom on trilinear elements. Okay? And this 24 has got, as a, is the product of n n e. Times N sd. Okay? All right, well, what are we going to use that for? What we're going to use that for is the following, right? We are going to use that in order to write out this first integral here, and actually the second one, too. Given the first integral on the left, it's not the integral, sorry, the sum on the left and the sum on the, first sum on the right, okay? And in particular, what that's going to let us do is get rid of which of the two summation symbols on the left hand side. Right. It's going to let us get rid of the sum over A and B. All right? And in this case it's going to let us get rid of the sum over A. We're not going to do anything different with the, the code the code just yet. Okay? All right. Okay. So doing all this, what we get is, the following. Okay. So. Now, the finite. dimensional weak form. Really, this is already a matrix vector form Right? We have, we, we, we are already talking from matrix vector form. It's going to be the same following. It is sum over the elements c, e. Transpose. Now, because we're getting rid of the c, e, e, and the d, b, e, we also can, dispense with the subset the superscript in b under K e. All right? But what that means is we now get a larger matrix, K e. Right? D e equals sum over e. C. Transpose. Now we're going to call this the F internal for element e. And like I said, we're going to wait a little to get this last stub. Done, taken care of. Okay? So, for trilinears right, I'm going to stick with okay, let me talk about this in general. What are the dimensions of that matrix, K e? All right? It's got to accommodate the C transposing D e, in general. Right? So that is going to be N, N, E. Cross, times NSD. Squared. For the generally case right, we know that we still need to account for the Dirichlet boundary condition and we come back and do that later. Okay, so this is the generally case. All right? This is also, therefore number of nodes in the element times n s d. Okay? Just to point out, our K matrix, K e matrix now is a block. So, sorry, it's constructed of many three by three blocks. Right? Because each of the K a b, sorry, K a d, is was a three by three block, all right. So we have a three by three block. K 1 1. E. Another three by three block. K 1 2. E. Because, if we were bi-linear hold with trilinears we would have eight such blocks but let me call this K, one, number of nulls in the element E. Okay. You could come down all the way, until you came down, you, you would have, N N E rows, right. And this is K, E, N, N, E 1. Right? The one there is for the column. Until you come all the way here, you will get K N, N E, N N E. Right? For a trilinear element we would have eight by eight blocks, right. Eight blocks along the column direction, and eight blocks along the row direction. Right, each would be a three by three. Right, each of these is three by three. Right. Which, well it's actually by N S D times N S D. Okay? And likewise we would have FE That's a three vector. All right, I think this is a great place to end this segment. When we come back, we will pick up from here. And, completed

\section*{ID: jzXr4-vG0q4}
Welcome back. We are now at a, very close to an end game stage of our formulation for 3D elasticity. What we are going to try to do in this segment, and perhaps it will spill over into one more segment, is to assemble a global matrix factor equations. And talk about Dirichlet boundary conditions, and the final solution step, okay? So let's get started on that program. What we will do now, in this segment is, write out the global matrix vector equations. And in order to do this, what I'm going to do is, just write in the first line here the actually, the, the, the final matrix vector weak form, but retaining explicitly the sum over elements and then we work ahead from there, okay. So this is an equation we developed toward the end of the last segment. It's, sum over e, c e transpose, k e d e, right? And remember that your k e is our, elements difference matrix, right? This is equal to sum over e. Ce transpose fe internal plus sum over i, right? Over the spatial dimensions. Sum over the elements that have some part of their element boundary as coinciding with the alignment boundary of the problem, right? And then for such elements we have the sum over the nodes that actually over all the nodes, right? because we worked out the bit about nodes belonging only to the Dirichlet boundary over such elements, right? We got past that point. So we have the c is our vector of degrees of freedom for the weighting function. And we have this forcing vector, which we've been denoting as f t bar node a, spatial dimension i element e. All right from here we go on to the business of assembly. Okay? And in order to see how that works out, we are guided by our global definition of the c and d vectors, right. So let's start out with the global c vector, right. That is c and the way it is defined is the following. We have we start out from the, we start out by following the global nodes. Right, so we have for global node 1, we have degree of freedom 1. Right? Which would be in our case the it would correspond to the spatial dimension one. And then we would have the same node. Degree of freedom two corresponding to spatial dimension two, and spatial dimension three. Right? This would carry on, and for the general node A, we would have the same situation. Right, until it came down to the very last of our c degrees of freedom. Alright, you note that I'm not, locking us into a situation where the very last degree of freedom, right? Or the very last node which would be sitting here. Those degrees of freedom would be sitting there. Degrees of freedom would be sitting there. I'm not walking us into a situation where that has to be the last node in the problem, or the last numbered node. Because of course we know that the definition of Dirichlet boundary conditions may very well eliminate such nodes from having weighted functions being interpolated off. All right? So, I'm leaving open that flexibility here. So this is the global c vector, all right, and likewise the global d vector, all right. And I'm going to now call this a d bar vector, all right. And you may recall from our previous treatments of 1D problems as well as the 3D problems. But for scalar variables that we are doing, we are calling this d bar. Because we know that there are some of those degrees of freedom that we want to later on move over in order to impose Dirichlet conditions. Okay? So okay. So the same thing happens here. We have d one, one, d one, two, d one, three. All right. Carries on to da1 da2, da3, right? That's for some general note, right. dA1, dA2, dA3 simply represent the displacement, degrees of freedom In the respective directions. One, two, three. Along with respective coordinate directions, one, two, three. For node A. And then this carries through all of them. D down to number of nodes in the problem. One, two Okay? In general, the D bar vector will be. Will be what? Bigger or smaller than the c vector? Will d bar have more components, or fewer than c, or all the same? What do you think? All right. If there are any Dirichlet conditions at all, and there have to be Dirichlet conditions for this problem, the D bar vector will have more components than the C vector. I should also mention that in setting this up, I'm assuming that the very first node here does not have Dirichlet condition set up on it, okay? So let me just say that. No Dirichlet boundary condition on the very first node. But yes, there could be Dirichlet conditions on the very last node. So I haven't specified which node we're talking of at the, as the last component of the c vector. Okay, so we have these global, so these are our global. C and d bar vectors. Okay? And then once we have this, the, the degrees of freedom that we have are, are now to be viewed as simply those corresponding to these entries, right? Each of these, for the whole problem, right, viewed as a vector problem, each of these is a different degree of freedom, right? Never mind the fact that they come from the same node, right? As far the problem's concerned, they're different degrees of freedom, right? Likewise these, right? And of course for, for, for general nodes as well, okay? All right, so in this sense, one, one would say that d bar has number of nodes in the problem, times nsd degrees of freedom, right? All components, right? c has number of nodes in the problem times nsd minus ND where this now is the number of degrees of freedom with Dirichlet conditions on them. Okay, and in calculating ND, it is not necessary. Well let me ask you, do you think it, it is necessary that ND, right, ND, is it necessary that ND should be a multiple of the spatial dimension? Right, I'm asking, is, da, does it have to be a multiple of a number of spatial dimensions? And in, in particular I'm, the reason I'm asking this question is bec, is because I want you to think about whether Dirichlet boundary conditions have to be applied to all three degrees of freedom at each node. 'Kay, so the answer to this question is that is no, right? Because we, we've, we've, we know that we could apply Dirichlet conditions on a particular coordinate direction at a point and not on the others, okay? So in ge, so, so this answer in general is no, okay? Right, all right. Okay, so we have these things in hand, and now what we will do is to go ahead and essentially write out the global form, right, from that contribution. So what we have here is that sum over e ce transpose, Ke, de equals c transpose, K bar, d bar, right? Okay? Now we already know what our c vector and our d bar vector are. The K bar itself, is obtained by this assembly operation over the individual element's stiffness matrices. Right, and, and note, of course, that here, because we have confirmed indeed that we are doing 3D elasticity, the term stiffness matrix is is, is relevant, right? It's, it's, there, there, there, there's no confusion there. Okay now this proceed, this proceeds just as before, right? What we want to, to realize is that any single entry in the K bar matrix, which corresponds to degrees of freedom belonging to different elements, right, but the same global degree of freedom will have the corresponding terms added on, okay? So this thing works just as before when we realize that we just carry out the assembly over degrees of freedom over global degrees of freedom. 'Kay? You just have to carry out assembly of a globally numbered degrees of freedom and forming K bar, okay? And when we do this, we get that K bar as units, sorry, has, has dimensions of number of nodes in the problem times nsd minus ND, okay, times number of nodes in the problem times nsd, okay? In order to sort of further explain this process, let's try to do it for a pair of elements. Let's me try, let me try and draw something that's doesn't have very complicated surfaces. 'Kay I suppose that this thing goes a little longer. Okay, this is sa, somewhat similar to the si, sort of situation we'd looked at in the case of the 3D scalar problem. Right? So, let me label only, or let me draw only the common nodes here. Okay. And let us suppose that these nodes have global, global numbering. A, B, C, D. Okay, and furthermore these elements are omega, E1, and omega E2. Okay, all right. So, let's, look at what the, the Ke1 stiffness matrix may look like, okay? Now, let's suppose that for the Ke1 stiffness matrix we have a numbering, which comes from the, from the, from the local ordering of nodes, right? We, well, we know that's always the case, but let me just label the the local number in with nodes, right? For the local numbering of nodes in element omega e1 we know that what I've labeled here is global node c, supposing we say that, that, that is local node 2. Right, and element e1, right? According to that, D would be local node 3, right? A would be local node 6 and B would be local node 7. Okay? Now, for element omega e2 exactly those nodes. Suppose that they are local node 1. D is local node 4. Right? A here would be global node, A would be local node 5 for element e2. And B would be local node 8 for element e2. All right? So, with this background, all right? Let me try and write our Ke1. Okay? Ke1 would be a matrix where I'm not going to write out all of the components, because I'm just going to write the blocks, okay? So we know that this going to be Ke1, the 11 block up to the, up to Ke1, the 18 block, okay. Because, of course, we're working with bilineals here to fix ideas. So we have Ke1 88, all right? And down here we would have Ke1 81, okay? And Ke2. Is Ke2, 11. Ke2, 18. To Ke2, 88. Ke2, 81. All right.

\section*{ID: lcDP8zC6vrg}
Okay, with this in mind, I would like to go into our global stiffness matrix, and just talk about where the where the matrices are going to be added on, okay? I should, I should mention here, of course, that each of the entries in these K e 1 and K e 2 matrices is a is not a scalar, right? What is it? Each of these is a, that's right, a 3 by 3 matrix. Right? Okay? All right. Okay, right, and, and that's the same for K e 2. Right, so now let's look at our global K bar matrix, okay? And in setting it up. Okay, let me suppose that this is row A, row B, row C and row D. Okay. And in terms of columns also I have I may have A here, B, C and D. All right, with all of this in place let's look at which sub-matrices from the K e 1 and K e 2 which I wrote in previous slide, are going to make their appearance here, okay? So let's look at the A A contribution. Okay, for the A A contribution we will have, it should be here, right? We would have from K e 1, right, if you look back at the figure I drew of the two elements e 1 omega e 1 and omega e 2, it should be clear that from K e 1 we have the 6 6 component, right? And from K, and from omega e 2 we have the, which one, that's right, 5 5 component, okay? You know, if we filled out all the ABCDs here, we would have 16 entries, and I'm not going to try to do all of that, right? So let's look instead at what happens with the CC entries, okay? So the CC entry from G1 would be K e 1, 2 2 plus from e 2 which would be K e 2, 1 1, okay? And this would go on. Of course, neighboring omega e 1 and omega e 2 there may be other elements which also share our global nodes A, B, C, D, all right, and contributions from those elements, stiffness matrices would also be added in here and here. Right, so. Okay? Okay. Now look, let's look at what happens with a with maybe the AB combination of global nodes, okay? So if we look at AB, what we observe is that the, the contribution from element e 1 is going to be, will be from the matrix K e 1. What do you think? What, which particular block is going to contribute here? It would be the 6 7, okay? And from e 2. From e 2 it would be the, right, 5 8, okay? And so on. So let's do one more. Maybe we do the, what do I have room here for? Let me do the AD. Okay? So AD, from K e 1 is going to be 6 4, and from e 2 is going to be. Oh, I'm sorry. From A 1 it will be 6 5. Right, and from e 2 it will be I'm sorry. I can't, I can't read my own, own handwriting. It would be 6 3. Really sorry. 6 3 from e 1 and for, from e 2 it would be 5 4. Let me double check that. Okay, and of course, there could be other, there will be other contributions from other neighboring elements that share the same nodes. Okay? So this is our global K bar matrix. Right? With this in mind, let's also try to assemble our forcing vector, okay? I believe that with this in place, we can do this, we can assemble the forcing vectors fairly quickly, okay? So, what we see here is that when we look at our sum over elements, c e transpose F internal e. Okay? Now we have this written as c transpose F internal, right? Okay, where we already know what the c vector is we only need to say what the, what the F vector is, okay? And since I have some room here, let me try and write out the F vector here. Okay, and I'll try to do it for the same combination that we have, okay? So for the F internal vector. It's for the same, I'm, I'm going to try to do this for the same combination of nodes that I've written out for the, that I've used for the stiffness matrix. Okay, let's do this. Hopefully that gives me enough room. And let me say that the nodes A, B, C and D make their appearance at roughly those points of, of the, of the vector. Okay, global node A. What contributions does it get from element e 1? Right, from element e 1 it gets the, the F internal e 1 from which local node of element e 1? Right, local node 6. And from e 2. From e 2 it gets a contribution from local node 5. Right, this continues and let me try to do the same for global node C. So from element e 1, it gets F e 1 internal node 2. And from A two, it gets F internal, 1, okay? Right, and of course there could be more contributions here, right, because of the fact that there are more nodes, sorry, more elements off to the side, right? Okay, so all of those contributions would go into those entries for global nodes A and C. Okay. So that's how we go, set about assembling our global stiffness matrix K bar and our global force vector F internal. We'll end the segment here. When we come back, we will talk about how we treat the traction or the Neumann boundary condition terms.

\section*{ID: x-PTHIibfSs}
There was an error in board work that I made on, this slide here in front of me. The error is in, where I put that block matrix in the larger K bar matrix. Properly, if you look at those terms, K e1 sup 6 7 and K e2 sup 5 8, and look at where they come from, and in order to do this, let's just go back one slide. Okay? So now if you look at the way the elements and nodes have been written out for, or have been sketched out for this little assembly of two elements, you will note that the K e1 6 7 component Is map, is one that maps on to the global K bar AB block of the matrix. And the same holds for the K e2 sup 5 8 components, which are those two, okay? They also map onto the, to the global D bar AB block of the matrix. When you go to the block matrix K bar, what you will you note that I've written then in the K bar BA position for, in terms of blocks. This just needs to be moved up here which is the K bar AB position. Right? It's the AB position because the rows are got from there and the columns are got from there. It's a bit of a squeeze the way I've written it because the  K bar AA component turned out to be a little wider than I should have written out, but, the important thing is that this, block should appear right there. Okay? With that correction, which is an important one of course, we also note that the same sort of thing may have happened with the block that we've written out here. Let's just check that. So we have K e1 6 3 and K e2 5 4. Let's go back and see where they come from. So K e1 6 3 would be the A d component, right? And K e2 5 4, when you look at this assembly of two elements, would also be the global A d component. That term however, that block term however, is in the right position, okay? And once we look at things in that light, we see that now this K bar matrix is correct with this one correction. Right? That block should appear in that position. With that, everything's consistent and you can go ahead and, program this into your code.

\section*{ID: Nv22ARg6J90}
In this segment, we'll start looking at the homework coding template for homework four. All right, and that will be the 3-D linear elasticity problem, the steady state problem. Okay, so let's come over here to the code and we'll look first at the main.cc file. And as you can see, almost nothing has changed from the previous homework assignment. I, of course, changed the name of the include file but it's still 3D passing in the mesh size. This is, for example, 10 x 10 x 10 element mesh. Okay, create our object and then go through the same steps as before. All right, so we can go straight over to our header file. And we have our same header files here. But now, in this homework assignment, we are going to be using DL2's quadrature rules. We'll be using DL2's basis functions. And so that will make things a lot easier on the coding end of things, but then it does change the structure of our code a little bit. So we'll be looking at those changes here. First off, I'm going to declare order and quadRule as global variables. Actually not variables, they're constants. I've designated that here, that they are both constant integers. And I've defined them here, because I use both of these numbers in the constructor of some of our class objects, okay. So, let's scroll down and look at the declaration of objects in our class. Declaration of objects and functions. We have, of course, the same class constructor and destructor. Here I have a function called C, this is our elasticity tenser. Now, DL2 actually does have the capability of creating a fourth order tenser, which the elasticity tenser is. I've set that up here as a function where the inputs are just the four indexes, and then it outputs that component of the tenser. Okay? So you can use that when you're creating k local. The solution steps themselves are all the same as well as these first three class objects, but now we have, again, the DL2 quadrature rules. We have two quadrature rules, a quadrature formula for volume integrals and a quadrature formula for surface integrals, which is the face quadrature formula. We'll be showing you how to use those later on. Other than that, the k, d, and f matrices and vectors are the same. Slight change here, I've changed this object for the table. Instead of no location, it is dof location, or the location of the degrees of freedom. The reason I've done that change is because since this is 3D elasticity, we now have three degrees of freedom per node. And so, there are three times as many degrees of freedom in the system as there are nodes, okay. And, this table gives you the location of each degree of freedom. So, what that means is degree of freedom, zero, one and two, which all correspond to the same node, would have the same location. But they each have their own row within this table DOF location. Okay, course bound, you guys, map is the same. I'll scroll down to the construction destructor. Here in the constructor, again we're, we call the constructor for FEM dof-handler, but I'm also calling the constructor for quadrature-formula and face-quadrature-formula. All right, because they need to know what the quadrature rule is. And so that's what you've defined up at the top. The default value is quadRule of 2. Leave it at 2 when you turn in your homework. But if you want to you can easily change that to 3, 4, whatever, DL2 would automatically take care of that here. Also, you'll notice that I left order as a variable that can be defined. Again, I have defined it as one at the top, leave it as one when you turn in your homework. However, feel free to, on your own, to change it to a higher order of basis functions if you would like, d02 automatically takes care of that. Okay? But again, when you turn it in leave it at order equals one and quadRule equals two. Okay? So those are the small changes in our constructor again. Small change here with the names of the output vectors, because again it's a vector field instead of a scaler field. Let's scroll down and look at this function C, which is the elasticity tensor. This is the first part that you actually have to add that something. And it's simply to input the values for the Young's modulus and the Poisson's ratio. From those values, I can reconstruct the Lame parameters, lambda and mu. And with lambda and mu, I use the formula that you saw in the class, in the lectures, to create, define the particular component of the elasticity tensor. Now if you recall. C = lambda times your second order isotropic tensor, tensor product with, again, the second order isotropic tensor plus one-half mu times the the fourth order isotropic tensor. Okay? And what that means in indicial notation, is that we have Cijkl equal to lambda times delta ij times delta kl. Of course, delta here is the Kronecker delta, where if i equals j. Oh, let me write that down here. Delta ij is equal to 1 if i equals j and 0 if i does not equal j. Okay. Sorry, slight mistake up there, it should be 2 times mu instead of one-half. Okay, so we have 2 mu, and then here we have one-half times delta I K, delta J L plus delta I L, delta J K. Okay? Of course those can cancel out. And that's what you see in the code here. You notice I'm using these conditional statements here. If i equals j, if k equals l. If i equals j, then the condition is true and so it returns one. If i is not equal to j, then the condition is false or returns 0. So it's acting the same as a chronic or delta. All right, so it's a little bit cleaner or quicker than typing in an if statement, but it serves the same purpose in this case. All right? If we look at generate mesh this is exactly the same as our 3D heat conduction problem. We simply have to define our, the limits of our domain. And that creates a mesh for us. All right, for define boundary conditions, again this is something you'll fill in for yourself, and it will be very straightforward, similar to the previous assignments. Again, a slight difference here is that we're using DUF location instead of node location, but that's a small change. Another element that gets introduced here, though, is the fact that you may have different Dirichlet boundaries for each degree of freedom, for each nodal degree of freedom. And by that, I mean you may want to fix on a certain phase, the displacements and the extraction, but not fixed the displacements in the y or z direction. If that's the case, then your if statement, you would check not only the location of the degree of freedom, but you'd also have to find out what's the nodule, the corresponding nodule degree of freedom. In other words, is that degree of freedom a Dirichlet placement in the x, y or z direction? And so I've explained that a little bit here, in the notes, in the template. However, you don't have to worry about that in this assignment because our only Dirichlet boundary condition is to fix all degrees of freedom on the face where z equals zero. So all have to do is check is the z component of DOF location equal to zero? If it is, set that degree free equal to zero, whether it's in the x, y, or z direction, okay? But in the future, if you want to, you actually can distinguish between displacements in the x, y, or z direction when you're playing Dirichlet boundary conditions, okay? Let's quickly look at setup system. There's actually no difference here, other than the fact that we're creating dofLocation as a table rather than no location, but nothing that you have to change. Okay, so we'll stop this segment here, and in the next segment, we'll look at the single system, which again, will be the meat of this template.

\section*{ID: k3pswnNaT-U}
In this segment we'll move on to looking at the assemble system function for the homework four template. So let's look at that code now. You'll notice first off we have two new objects. We have this fe-values and fe-face-values. These objects are DO2 objects that hold information about the basis functions, the basis function gradients, information about the quadrature points, the Jacobians, and all this. But we no longer have to calculate the Jacobians. We don't have to write out the basis functions themselves. We don't have to write out the quantiger points It does all that for us, all right? So if you'll look, the first two are just fe and quadrature formula so that it knows what basis function order we're using and it knows what quadrature rule we're using. The third input value is actually a series of input values, of flags that tell fe values what information we're going to be using and that's the information that it'll be updating. So it makes a little bit faster or saves on memory that we don't need to update information that we won't actually be using. All right, so for fe values, which is what we use for volume integrals. We're going to be updating the values, which are the values of the basis function. Update gradients, that's again the basis function gradients. And then, this JxW, that's supposed to be J times W. J stands for the determinate of the Jacobian, and W stands for the quadrature weights, so it's all three quadrature weights multiply together in 3D. All right, so it takes the care of all of that 4s. The gradients we use in Klocal, the values we would use in Flocal if we had a body force. Okay, and course J times W we would use in any volume integral. If we move on to fe face values, you'll see I'm updating values. Quadrature points in J times W values. J times W values is as before. Only now you'll note that since it's a surface integral, it'll be the determinant of the Jacobian mapping from the 2D by unit domain to the 2D surface domain, right? update-values is, of course, still the basis function value on that surface. update-quadrature-points, this actually will give you the position vector of each quadrature point in the real domain, all right? So we need that in this problem because the traction for a Neumann boundary condition depends on the X1 component. Okay, so it varies as X1 varies on that Neumann surface Z equals 1. Okay, so that's why we're updating those values. So, let's scroll down into our element loop. Now, you can see here the first thing is that we do fe-values.reinit(elen), so fr-values is reinitializing for this particular element. So it's getting all the correct values for the quadrature, for the Jacobians and so on. The first step that we're going to look at is defining Klocal. Now before you look any any further at the code, let's look at the board at what that general form is. Okay, so in class we, or in the lectures we looked at Klocal and we had four indices that we were dealing with. Klocal AB ij. And the idea was that AB run over the nodes in your element. Okay, so I will go from 0 up to just less than the number of nodes, In the element. Okay, I and J are nodal degrees of freedom. And so that we run it from 0, 1, and 2 in this case for the 3D elasticity. All right, and the way we pictured that is that we had our Klocal matrix and then inside, we had these little sub-matrices. All right. And so, again there are eight nodes in a hexahedral element and so, these went from 0, 1, 2, 3, up to 7, all right, the same on the side, 0, 1 to 7. Now within the submatrices, we had indices 0, 1, 2, 0,1, 2. Now those correspond to the degrees of freedom at that particular node, okay? Now of course Klocal is not a matrix or matrices in d0l 2. It's just a matrix that's 24 by 24, all right? So we can look at this instead. This makes it, as 0, 1 2, 3, 4, 5, and so on up to 21, 22, 23. Okay, so let me label these. These would be our element degrees of freedom here. Going from 0 to 23, then we have our element nodes, Here. Going from zero to seven. And then we have our nodal degrees of freedom. Here. Going from zero, one, and two, all right? So you will notice when you look at the code again that our loops are actually looping over the element nodes and the nodal degrees of freedom. However, the indices in Klocal will be in terms of the element degrees of freedom. Okay, so how do we do that conversion? Because the indices start at zero it actually makes it simpler in this case. So we would do it like this. Klocal ABij corresponds to . I guess I should do square brackets on both of those, right? And you can see that that's true. Let's do it for 22 here. So that would be A is equal to 7, so 3 times 7 is 21. The nodal degree of freedom would be 1 at that point. So 21 plus 1 gives us an element degree freedom of 22, okay? And we'll work the same way for Flocal. For F local, it'll be F local A sub i, would be the same as F local of 3A, 3 times 8 plus 9, we'll look at that again in a second. Now let's look at how we actually calculate Klocal ABij. Let me write out the formula here. So we have Klocal ABij = the integral over the domain of the element, basis function A, the derivative to with respect to X of j, Our elasticity tensors Cijjl times our basis function B, ldV. All right and notice, we have repeated indices here. So there's an implied summation over j and l. For j and l going from 0. One and two, okay. All right, so let's look at what that will be in our node, in our code over here. All right, so first off, in our loops, we have a loop over quadrature points. Notice it's a single loop over quadrature points. d0l2 has combined all three loops since this is a 3D case into a single loop, all right? And it's keeping track of that for us. Now we have our loop over A and i, which is the loop over nodes A and then loop over nodal degrees of freedom. B and k again looping over element nodes and element or nodal degrees of freedom. Now, actually, I need to come back here and make a small change that I noticed. That's actually not the way I've written it here. That's not for Klocal ABij. It's actually for Klocal ABik, and the reason you should be able to see that is because j has already been removed through the summation. ink are three variables here, and so that's what should show up in the indexes of Klocal, all right? So that's why I have A and i grouped together, then B andk. j and l,, we have a loop there because of the implied summation over j and l. Okay, and now in here you'll define Klocal, using of course this integral that we're written out. Now one thing that's important for you to know is that when we use fe-values to get the gradient, which we do using fe-values.shape-grad() It's actually given us the gradient with respect to x and the real domain. You'll notice in the previous assignments when we wrote the basis gradient functions, the basis function gradients we wrote the gradient with respect to c and the bi unit domain and then we had to find the Jacobian. Do the inverse and so on, right? That's all taken care of here. Okay, so we don't have to deal with the Jacobian in order to make that a gradient with respect to the real domain, that's already done for us. Okay, so in order to access that gradient, you do fe-values.shape-grad, and then you'd input the element degree of freedom. Okay now, notice that's a little bit different than what we've written on the board here. In the lectures we always use the element node number to designate what basis function we're using. Here in d0l2, it's the element degree of freedom, okay? So it will be the same as whatever index you're using in Klocal. So this wouldn't be, for example, this wouldn't be A, this would be 3A plus i. And this wouldn't be B, it would be 3B plus j, for d0l2, okay? Sorry not j, plus k, all right. Again, you'll need to use the elasticity tensor function that I created before. And in order to use det to get your dertiminate of j times the quadrature weights we'll use fe-values.Jxw(q)*/ for this particular quadrature point. Notice also that we aren't inputting the value of c at the quadrature point, we're just inputting this index q which tells you what quadrature point we're at in the loop. Okay, also, to clarify, fe-values.shape-grad gives you a position vector. It's actually a d0l2.object, but you can think of it as a position vector. Or sorry, it's actually a first order tensor, which is very similar to a point and d0l team. Okay, so if you want to use a particular component, which of course you will, you can use just these square brackets. i or j or whatever it may be, okay? So, that should cover it for creating Klocal. Let's move down to Flocal. Now we don't have a body force in this problem or any forcing function like that. But we do have Neumann boundary condition. And so that will involve an integral, Over the Neumann boundary, okay? So let's write that out here. So for Flocal A sub i, which again is the same as in our code, it will be 3A or times A since is equal to 3, + i = this integral over a surface and so I'm going to designate that with this partial omega. And I'll use T to specify its attraction. It's the Neumann condition, and it's for a particular element, okay? And we'll be integrating hiI, so h is the traction, i is the component of the traction, the traction is the first order tense of our vector, times NA, and again it's a surface integral. All right? Okay, so let's go back to the code. You'll notice first, I'm doing a loop over the faces of the element, the current element. Of course there are six faces. So we loop over those and we're going to update fe-face-values for this, not only this current element, but also for the current face. That will put this quadrature points on the face itself that we're on. Now we're going to check to see if that face is at our Neumann boundary, okay. So this lm arrow face arrow center, that gives us a position vector at the center of the current face. And since I'm interested in the z component, I use square brackets too. Okay so here in this if statement, I am checking to see the point at the center of this face at the boundary z = 1, which is our Neumann boundary, okay? If it is, then I'll perform this surface integral, okay? If not then I will just move on. Either to another face, and if none of those faces were Neumann faces I'd move onto another element, and Flocal would be zero for this element, okay? But once we are, once we have found that Neumann face and we are performing that surface integral, we'll move inside and loop over our face quadrature points. Okay, notice that, the number of face quadrature points. Here I've extracted for you the value of X, the x-coordinate of the current quadrature point, okay, and I've done that using this fe-face-values.quadrature-point(1). If I wanted the z component then I would just change that zero to a two. If I wanted a y, I would change it to a one, okay. But then what you need to take that value of x and specify what the value of the traction vector h is at that quadrature point, okay. Now, once you've done that we'll move inside our loop over the nodes and the nodal degrees of freedom, okay. And, once inside there you will again use this integral that we've written out on the board to define Flocal. Now you'll notice I am looping over all eight nodes of the element. Even though we're only doing a surface integral. How are the quadrature points themselves, D02, is placed on the appropriate, correct, surface the correct face. So, we are only integrating over the surface itself. All right, notice again, we'll be using fe-face-values to find the basis function value. Okay, and you are still passing in the element degree of freedom. So that's 3 times A plus i. Not just A, okay. And again when you're finding JxW, the determinant of J times the quadrature weights. Again use fe-face-values, all right. Everything involved with the service integral will be using fe-face-values, not fe-values at all, all right? So once you've filled that in, you'll have Flocal created as well, and once you have Flocal and Klocal. A symbol system will be very straightforward. It will be exactly the same as previous assignments, all right. Applied boundary conditions will be applied in the same way. Again, you've already specified your knowing your boundary condition. Fixing all degrees of freedom, X equals 0. And I'll scroll down a little bit more just to finish up quickly. Solve is exactly the same and output results again is the same. Outputting our displacement results as a .vtk file which you can then open up using para view or visit to look at the displacements. All right so that concludes our this segment and it concludes our discussion of the template for homework four

\section*{ID: H1aHhCENGmM}
Welcome back. We are aiming here, to complete our assembly of the global matrix vector equations. And, talk about the final Dirichlet boundary conditions. So, to do that let's get on to the contribution that we have not yet tackled for the global equations. And this is the contribution from the Neumann or the traction boundary term, okay? So, the contribution. To global matrix vector equations. From the traction, right. Remember the traction is simply our Neumann boundary condition for this problem. Right. So the term we are talking about is this one. Sum over i, right, i running over the spatial dimensions. Right. Sum over i, sum e belongs to E Neumann, right. Sum over A, that's all the nodes in that particular element, right. We have here CAie Ft bar. We have the A index there. We have the i index there and we have the e index here. Okay, what I'm going to tell you in one fell swoop is that this is going to show up as c transpose Ft bar, right, globally. And I will write down on the next line the detail construction of the F matrix. And in order to do that, I am going to take I am going to write here first the C transpose vector a, as a row vector. Okay? And I am going to get myself room for it here. Okay, and the idea is that multiplying it is our FD bar vector. Okay. And here too, let me get myself enough room. Okay. So let's construct C. Sticking with the same assumptions I've made before we have a contribution from the very first numbered global node, okay. Because I'm assuming that our, in considering the case, where we don't have the Dirichlet boundary conditions on any degree of freedom on the first node. So, we have C1. Okay. And we're working with the outer sum first, right? The sum over spatial dimensions. So I'm setting i equals 1, and that is the 1 that shows up here. Okay, and that comes from some element, right? The fact that we're doing a sum over elements is already accounted for in the fact that we have this global node here, okay. Right so that contribution would be. F t bar. Let me see. It would be local node number one for that element. Okay? And since we are talking of global coordinate direction one. We would have a one here. Okay? It's going to be some element, let's call it, let's just leave it as E. Okay? And let's go on now, with this. And actually in going on, let me also use the same numbering that we used in order to construct the stiffness matrix and the F internal force vector, okay? So I have before me here those two elements, omega e1 and omega e2 and you probably noted them down in your in your book, or your notebook. So I would encourage you to go back and look at those. Okay? Because what I'm going to do now is look at the contributions to global node A. Okay? So let's suppose that global node A shows up here. Wrong C vector. Let's suppose that B shows, shows up here. Global node C shows up there, and global node D shows up there, okay? So that's, A is going to be here, B, C, D, okay? Now we start out as as I did for, for this very first degree of freedom, we start out with the spatial dimension one, okay? So the global node here, right, is cA1, okay. And let's suppose that on this force vector A shows up here. B shows up there, C and D. Okay? Now the only we would have a contribution from the A node is what? Okay. What we need to have is that the local well what we need to have is actually we, we can talk of it, of it in terms of the global nodes and so global node A, right, lies in partial omega t bar one. Right? That's the only way we would have a non zero contribution to the F vector from global node A. Okay? So let's assume that this is true. Let's consider the case where A does lie in omega, in partial omega t bar one. Okay? Alright, so you could go back and look at that at that figure that I drew back there two two or three slides ago. What I am seeing is that node A from that figure does indeed lie on, lying on, partially on , partially on omega T bar one. Okay. So, we would have a contribution, then, from element e 1. And the contribution from element e 1 would be F t bar local node 6, right, spatial dimension 1, element e 1. Okay? Right, now element e 2 also would have a contribution here, right? So we would have F, t bar, right? From element e 2, the contribution would come from local node 5, okay? The spatial dimension would still be 1, right? And of course, there's element e 2, okay? So this would be the situation if I'll reproduce that figure of two elements, somewhat more defined. All right, so again we have omega e 1, omega e 2, right? And I'd lo, I'd label those nodes as A, B, C and D, okay? What I'm seeing now is that let us suppose that D surfaces. Right, that, those are the sort of front surfaces of both the elements, right? Belong to belong to partial omega D bar. Sorry. Actually let me, let, let me write this properly. Okay, bo, both those surfaces I'm saying belong to partial omega t bar, okay, 1. All right. Okay, right. And, and then in, in terms of local numbering, what I'm seeing is that let me identify the surfaces I'm speaking of here. Okay, for element omega e 1, that's, nodes are 1, 2, 3, 4, 5, 6, 7, 8. And for. Omega e 2, the nodes are 1, 2, 3, 4, 5, 6, 7, 8. All right? Okay, so we would have those two contributions, right? Let's suppose then for omega, for, for the Neumann boundary in the 2 direction, right, which means the degrees of freedom are being controlled in the 2 direction. Sorry, not the degrees of freedom, but, but the traction components in the 2 direction are being controlled on the other surfaces, right? So let's suppose that it, it's on this surface and it's on this surface, okay? So let's supposed that this belongs to partial omega t bar 2. And this also belongs to partial omega t bar 2, okay? So the, can you think of which surface, do you see which surface I'm saying belongs to partial omega t bar 2 from element e 1? It is the 5, 6, 7, 8 surface, right, of element e 1. On element e 2 also it's a 5, 6, 7, 8 surface. Likewise, on element e 1 the 1, 2, 6, 5 surface belongs to partial omega t bar 1. And in element e 2, which one is it? It's the 1, 2, 6, 5 surface, okay? All right, so if you underst, if we are clear about that, let me put in the contributions then. All right, so for for the contributions from the 2 direction to the, to this traction force vector, would there be anything from node A, from global node A? There would be, right? So we, we would have a C A 2, okay? And that would show up now right here, right? It would be F t bar global spatial dimension 2, right. We would get a contribution from element e 1, right, from its node number 6, okay. Right, and we would get a contribution F t bar global 2 direction element e 2 local node number 5. Okay? All right. Which other nodes would contribute? So let's look at node B, okay? What contributions would it have? It would only have contributions from the 2 spatial dimension, right? Spatial dimension i equals 2. All right? So, for this node we would get a contribution from C B. Let's put the C B 1 contribution, then let's talk about the C B 2 contribution. Since the C B 1 contribution, right, on that node is 0, right? There is no contribution to the traction there, right? We are not controlling the traction there, okay? But that's a free surface, right, because that, that is a surface on which a traction may be specified, right? We have just not specified the 2 component there. So when it comes to the B node, we get a 0, okay? The contributions that do come there are from the 2 direction. And we have then F t bar, we are talking the 2 dimension, so we have 2 here. We are, okay, let's look now at the contribution from e 1. From element e 1, which local degree of freedom contributes there? It's the 7, okay? From F. Sorry from element T2. Sorry element E2. The contribution along the two direction, right, would be from local node eight. Okay? All right. Now, let's suppose that no other boundaries, of these two elements correspond to Neumann boundaries for the global problem. Okay. That means that if we go ahead and look at ca 3, aas well as cb in 3 dimension, right? We would get 0s, right? So here we would get a 0, and here too we would get a 0. Okay? All right? Let's see what node c does as I have drawn it, what traction surface does global node c lie on? Right? Also in the global spacial dimension one surface. Right? So when we come back here we have C and unfortunately the global  number of that degree of freedom is also c but hopefully we can cope with that, with that repetition. Okay. There is going to be something from the cc 1 direction right, from the one direction there. So we move along, right? And then we come to the c node. We get a contribution of the form F D bar, along the one spacial dimension, from element e1, right? So, which node from element e 1 contributes? It's the local node two. From element e 2. Which one is it? Local node one. Okay? Now, as I've drawn it, for node c, right? Global node c. There are, no other, spacial dimension, no other, traction boundaries that contain that node. Okay? All right? So what that says here is that for C c 2 and C c 3, I would get 0 and 0, okay? So let's just complete this particular line that I wrote. Global node a lies in omega t, omega t bar one. C also lies in partial omega t bar one. B Lies in partial omega t bar two. Okay. But to note, the way I've drawn it, A lies in this and in partial omega t bar 2. Okay? There's a partition there. Okay? So A the way I've drawn it node A is the only one that lies on two traction surfaces. C lies on one, and B lies on one. Okay. And which one the line has been written, has, has been denoted here. So, and, and for the more, for the way I've drawn it here, let's suppose that D belongs to no traction boundary. D lies in none of the boundary subsets. Partial omega t bar, i where i equals one, two, three. Given that, what contributions would we find in this traction force vector for no, global node D? You're right, all zeroes. So you get a zero, zero, zero, and we would go on. So, hopefully this process has given us some idea of how to construct this global traction force vector. Okay? This is what we are calling it. FT Bar. Okay?

\section*{ID: y1kCV1v8b-Y}
With all of that, when we put things together, we now have our global matrix vector equations. All right, and they are the following. C, T, K bar, d bar equals C, T, F internal plus C, T, F, T bar. Okay. What's the last step you need to take? Dirichlet boundary conditions, right? Okay? And in doing that, we need to rec, we need to come to the fact that our K bar, probably due without that arrow. What are the dimensions of our K bar matrix? Right, they are number of nodes times nsd minus Nd, right, where the Nd corresponds to Nd is the total number of Dirichlet degrees of freedom total number of degrees of freedom where Dirichlet boundary conditions are specified. Right, and this could be you know this could draw maybe, the, you, the, the one direction on some node, the two direction on some other node and the three direction on yet another node, if we sum this up we get three, in that case Nd would be 3. Okay, so, this times the number of nodes in the problem times nsd. Right? So K bar, these are the dimensions of our K bar matrix. Okay. Right. Okay. So clearly K bar is a rectangular matrix right? And what we need account for is the fact that when we look at the c transpose vector here, all right, multiplying K bar, right. And here we have our global d bar vector, right. Let's suppose that now when I label the degrees of freedom for the d bar vector, right, that is d bar 11 d bar 12, d bar 13. Okay. Now let me suppose that some global degree of freedom, all right? So let's suppose d a, d bar a 1, d bar b 2, and d bar c 3. Okay? Let's suppose that these global degrees of freedom are known Dirichlet boundary conditions. Okay? What this says is that d bar a 1 is known. I'm now going to write d bar a2 and d bar a3 because those are not specified. Right? Okay? Well, actually, actually, let me write them and, and specify and, and so to mark other ones that were known. Since I've run out of room here  let me just say the d bar, let me just get rid of d bar C, 3. Okay. So those are the ones that are known. Okay, so d bar a 1 and d bar b 2 are the, are two known Dirichlet boundary conditions, right? And, and there, there will be more, of course, in this sort of problem. Okay, so, that means that that degree of freedom is known, and that degree of freedom is known Okay. All right. And when we carry out this matrix vector product, we know that this entire column Right? And another one, right, are going to be known. Okay? So, for the way we had, numbered it previously, this column is what I would call the K bar, let me see. The column number here is the following. Nsd times a, right?, where a is the global node number, all right, plus 1. All right, because it corresponds to d bar a 1, right, 1, coordinate direction of global node number a. Okay. And this column likewise is K bar. Column number nsd times b plus 2, right. Right? This is the column.  Okay? So, since d bar a 1 and d bar b 2 are known. We do just what we've done before which is to account for the fact that those, that these columns multiplied by those known degrees of freedom can be moved to the right hand side. Okay? So we do that. Right? And then we are left with a reduced system, c transpose K d equals C transpose, F internal plus F t bar, right, minus d bar A1, which is a scalar degree of freedom, multiplying the column that we identified on the previous slide K bar nsd times a for the global node number plus 1 minus d bar. B2 scalar degree of freedom, multiplying the quantum number of K bar. nsd times global node number B plus 2. Okay. And as we've been doing in previous problems, that is our final F, vector. Okay? So what this implies for us then is c transpose, K d Minus F equals 0, right? And the degrees of freedom sorry, the dimensions of this K matrix now, it's square, right? because we got rid of all the Dirichlet degrees of freedom which were known and moved them to the right hand side. Okay, so K finally is number of nodes times nsd minus the total number of degrees of freedom that have their Dirichlet conditions specified on the N square. Okay? That is, those are the dimensions of K bar. Now of course we invoke our waiting function condition that our weak form, our finite dimensional weak form must hold for all waiting functions in the appropriate space. And the fact that it must hold for all waiting functions in the appropriate space is enforced here. By the requirement that this matrix vector equation that we have as the last line of the slide, must hold for all c vectors belonging to a Euclidean space of dimension number of nodes, times number of spacial dimensions minus ND. Okay? Which implies for us finally that we get back the same matrix vector from the equations. We know Kd equals F. Right? And we solve this for D, which will give us our global displacement vector. Okay? I should make one remark here that since we are talking of d being defined as K inverse F. Right? Under what conditions does the solution exist? Okay? Solution exists. Or there exists a solution d if our K matrix is positive is, invertible of course, Right? Under what conditions is it invertible. What, what, can you think of what it is that guarantees invertibility of that matrix? It turns out that for the 3D elasticity problem, K is positive definite. What conditions make K positive definite? One of the things that makes a positive definite is because our elasticity tensor, C is positive definite. Is there any other condition? Yeah. If you have some experience with these types of methods and with solving linear systems of equations, you will probably recognize that it has something to do with our boundary conditions as well. All right? We need to have enough Dirichlet boundary conditions to eliminate what are sometimes called rigid body modes in the context of elasticity. Okay? So K is positive definite and C is positive definite. And if the Dirichlet boundary conditions eliminate rigid body modes. Okay. And the question of how to do that is a little more involved which we really won't get into here at this point. All right. At this point we are actually done with our treatment of 3D linearized elasticity. This was our example of a vector problem and we'll end this segment and this unit here. When we come back, we will move on to a wholly new class of problems.

\section*{ID: Agvq4CxFTDU}
Welcome back. With this segment we are going to start a new unit, and this will take us away from elliptic problems. We are going to start looking at parabolic problems. Right? And we're going to, going to stick with linear parabolic PDEs in three dimensions, but for a scalar variable. The kinds of problems we are looking at, therefore, are very similar to ones we've looked at, we've already considered. They are the, the unsteady heat conduction problem in three dimensions, or the unsteady mass diffusion problem also in three dimensions. You will recall that previously we studied the steady state versions of these two physical problems, and, because we were looking at the steady state versions, those, particular PDEs, are what we call elliptic PDEs. When we bring back the the time dependence, and say they're unsteady problems, we have parabolic PDEs. Okay. So with that somewhat verbal introduction let's get on with it, right?. Linear. Parabolic PDE in a scalar variable, in three dimensions as well.  Okay? And, like I said, the physical problems we are considering here are unsteady. Heat conduction. Unsteady heat conduction and mass diffusion. In 3D. Okay? And just remember that unsteady here means that we're talking of time dependent. All right. So, what is the situation we have here? I don't have with me today my my basis vectors, but we don't really need them. We have our body, right? We have basis vectors here, three dimensional. Everything that we talked about, the, the steady state heat conduction problem holds. Okay, so we have surfaces on which we are going to specify Dirichlet and Neumann conditions for the temperature if you're doing heat conduction or the concentration, if we are doing mass diffusion. That's fixed, okay, that remains the same. We have a source dom. We have the notion of the conductivity tensor, or the diffusivity tensor. All the same. The additional component is that we are saying now that at every point in the domain. Either the temperature if it's the heat conduction problem. Or the concentration if it's the As diffusion problem, is changing with time. Because of flexes, or because of the source term. Okay? So at every point, we will have an addition, a time dependent term. Its going to be a first order time dependence, because that is the nature of parabolic problems, right? And that is indeed the nature of the heat con, of the time dependent on unsteady heat conduction and master fusion problem, right? Their first order in time. Okay, so with that setting, let's let's wr-, essentially write out the strong form. Okay, and as we've been doing, let's begin by drawing a picture. The figure, these are our basis vectors E1, E2, E3. Right, our domain, that, right? Three dimensional, of course. We have three basis vectors here. Omega. Right? Somewhat mercifully perhaps, we are back to a scalar problem. Right? So, we don't need to worry about the three different, decompositions of the boundary, right? So we have here, partial of omega u, right? Because u is now a scalar once again, and here we have partial, I believe omega j is how we denoted it, right? All right. Now point here has position vector X which we will use, right?. And at this point the picture here, the usual pill box argument that's given is the following, right? We look at a little elemental volume. Okay. What we see is that we have a flux is coming into it. Okay? And since we've already introduced the notion of a flux before, we can use it now, okay? So, The flux is coming into it, and, and for certain it could be exiting some part also, right? So next one. So this is our flux factor J, okay? Now, inside that little volume element, we have some source stone. And that source stone, you recall, if we're de, dealing with a heat conduction problem, would represent local heating, right, through some external source. Or for the mass diffusion problem, it would represent a local supply of mass, okay? So let me write an F if I can there. Okay? That's F. Now, what we are seeing in this unsteady description of the problem, the description of the unsteady problem is that the result of the fluxes, the net flux into that volume element and the effect of the source dom they're combined effect is to change either the temperature for unit time. Right? With respect to time either the concentration changes, or the temperature changes, with respect to time. Okay, so let's also add in here essentially a, just to portray this, let me say that there is a d u, with respect to d t dom also coming up, right? T of course is time, okay? So, the strong form is the following. As always, given the data, given, I think we were still calling it Ug back then, we had Jn, which is our influx condition. Our source f, right? And the constitutive relation that we are now very familiar with, All right, using coordinate notation kappa i j being the conductivity tensor, right? Given all of this, now, we have one extra piece of not quite detail, but it really is a coefficient that is relevant to the problem. And I want to put it down here to have relevance to make connection with the physical problems that we are trying to keep at the back of our mind. Heat conduction and as diffusion problem. That quantity is going to be denoted as rho. Okay. I'll tell you once we set up the problem what rho is. Okay. So given all of these, what we're trying to do, is the following. Find u, okay, such that the following holds, right. Rho, partial of u, with respect to time, equals minus ji comma i plus f in. Now, here is this, this part is important. When you are doing the steady problem you specify the, all our steady, all our previous problems were time independent. Right? They were all steady state problems. We specify the PDEs therefore only over a spacial dimension, over a spacial domain omega, right? Subset of R 3, in general, in the 3D case. But now we have time dependence as well. So we say that this PDE holds in a combination of the spatial dimension, or the spatial domain and the time interval of interest. And that is indicated by a cross 0 comma capital T, okay? So the closed 0 to capital T is our time interval of interest. 'Kay? And when we write omega across that time interval we are just saying that our PDE holds over a certain spacial domain omega. And over a time interval 0 to T. Okay? All right. As before we have boundary conditions. We have u equals ug on the Dirichlet boundary. We have our Neumann condition, minus ji, ni equals j sub n on partial omega j. Is our problem complete with specifying boundary conditions? No. We need initial conditions as well. Alright? Because it's a first order problem in time, we have a single initial condition. Okay? And the way we do that is to say that U, which can be a function of position. It is indeed in general a function of position and this is what we saw in our steady state problems. Right. So, we have U as a function of, as, as, as parametrized we have position and at time t equals 0, okay? Equal sum U. Not function of position only, okay? All right? And perhaps this is best clarified by also saying here that U is a function of position. And time. Okay? All right. That indeed does complete the specification of our problem. PDE boundary conditions and initial conditions. What I'm going to do here is just make one or two remarks. Okay? The first remark is that, we need to say something about this new coefficient we've introduced, rho. Okay? For a heat conduction problem And for heat conduction problems, can you tell me what rho is? Yeah. For heat conduction problem, rho would be the, rho is the specific heat.  Okay? And, and in the case of heat conduction, do you also know where our p d comes from? What, what physical principle leads to our PDE? It's actually the first law of thermodynamics. Okay? So in that setting rho is the specific heat, okay, and the way we've written it, rho would be the specific heat per unit volume. Okay? So it does as we went you know row with specific heat per unit volume. The specific heat also can be determined as a can also be defined per unit mass. Okay but in our in our setting for the way we've set up the problem. Loads the specific heat per unit volume. Right? It turns out that if however we were looking at the the mass diffusion problem. Rho is equal to 1. Okay? We don't need a notion of spe, of specific of anything like a specific heat in the context of mass diffusion. Mass diffusion just rises from a, physical principal, which is, the conservation principal. Okay, so that is the setting for, for, for, for this problem, sorry, that is the, sort of, setting of context for For, for the physical problems. Okay, so let me see. Is there anything else we need to really talk about here? Actually I believe not. So, we have laid down our strong form of the linear parabolic PDE in scalar varia, in a scalar variable in 3D. It connects up with our heat conduction, mass diffusion. Physical problems and  we'll end the segment here. When we return we will do the usual take the usual steps that we've taken before right? The weak form and then talk about the the finite element formulation.

\section*{ID: AFS1OqCquQ8}
There was a minor error in board work on this slide. It appears just about here where I written out incoordinate notation. The flux with the conductivity and the, what was meant to be the gradient in the field on the right hand side. And what's missing is, in this term, the evidence of the gradient. And that should appear as U comma J. Right, the comma was missing there, which did not suggest the gradient with respect to spacial coordinant. With that in place this equation and the rest of the slide are both consistent.

\section*{ID: 1ZSooWlRUYM}
Welcome back. We're ready now to work on our linear parabolic problems in three dimensions in scalar variables. What we did in the previous segment was setup the strong form of the problem. We'll just write it down very quickly now and, proceed on to the weak form and other things, all right? So we write, start out here with the strong form. All right. And just remember we are still talk, we are back now to talking about scalar variables. All right. Or scalar unknown, really, let me call it that. Okay, so the setting, as before, involves our domain. We have our basis vectors, e1, e2, e3. That is our domain of interest. It is omega, a point on it is x, the position vector x. And we have the setting of our Dirichlet boundary subset and the Neumann boundary subset, okay? This is the setting, what we are seeing is now given for data, right? We are given ug, jn, f. We have our, our, our old constitutive relation for these problems in 3D as well, right? Which is that minus ji equals, sorry. Plus ji equals minus kappa ij, u comma j, right? These are all the data that we use when we did the steady state problem, right? We have in addition, another coefficient, which I'm calling just rho, okay. And we made the point last time that this would be the specific heat for, unit volume, if we were doing the heat conduction problem. If we were doing mass diffusion problems, rho would typically be one, okay. Given all these data, what we want to do is find u such that. Right? The following holds. Rho time derivative with a partial time derivative of u equals minus j i comma i plus f in omega, the domain cross the time interval of interest, okay? For boundary conditions we have the same boundary, the same sort of boundary conditions that we encountered when we did the steady state problem, right? U equals u g on the Dirichlet boundary. And, right, minus ji ni equals j sub n, the influx heat, the heat influx or the mass influx, on the Neumann boundary. Additionally, we made the point that we need initial conditions, right, or an initial condition here. We have only one initial condition, because because of what? Do you, do you recall? It's because our problem has a single derivative in time, right? It's first order in time. Okay. So we need a single initial condition. And that is specified as u. Remember u is in general a function of position and time, but now we set the time equal to 0. And we say that this is some given function, u naught, suggesting the initial value, right, of u over the domain, okay? So this is what we have. And what we are faced with in this segment is setting up the, the weak form. All right, we are going to take the approach for the weak form that we'd taken before, which is, we, we have the strong form. We multiply it by a weighting function and integrate over the domain. All right, so to get to the weak form. All right. And remember this is going to be the infinite dimensional weak form. All right. In order to get to that, we see the following, right. Consider. W belonging to V, where V consists of now all functions such that w, equals 0 on partial of omega u, right, our same old weighting function, all right? We consider this, right? And we, essentially we multiply and integrate, okay? And we will do that in the next slide, okay. So what we are doing is we multiply. So we say the following, right? We have w rho, partial of u, with respect to time, equals minus w j i comma i plus wf, right? So we multiply all of this, and we integrate over the domain, right? So we integrate this over omega. So here we pick up a dv, all right? And the same thing happens here. We pick up a integral over omega. D v, and here, too, we pick up an integral, okay? That's what we have. Right, now, we proceed just as before, which is that we integrate by parts, okay. From here we integrate by parts, and just as we did in the case of the steady state problem, we integrate by parts only to have a different way to pose that, divergence theorem, right? We want to transfer that divergence theorem into something else, want to convert it into something else. And so we say all right, we see it there, and we are going to integrate by parts. Okay, now we are knowledge experts in this, so we don't need to go through all the steps. Let's just jump directly to the final form that we get on integration by parts, okay? And that is the following. It is, that, on the left-hand side now we have integral over omega w rho time derivative of u, partial time derivative of u dv equals. Now, the way that integral works is the, the way integration by parts works here is to give us two terms. One is integral over omega w comma i, j i, dV. I'll write the second volume term, which is at this point just a bystander, and in fact, indeed is a bystander through most of our, deriv, our, our, the development of our formulation. And we have, of course, the boundary term, right? We get integral over partial omega w ji ni, right? And that's in an, an integral over the surface so we have ds, all right? So nothing happening with the time dependent term on the left-hand side or the forcing function, okay? And then of course we take the usual steps which is to observe that this term, right? Is equal to integral over partial omega u, w ji ni dS minus integral over partial omega j w ji ni dS. Right, we have these two terms and then we invoke our boundary conditions, all right, on the strong form, as well as our, our homogeneous boundary condition on the weighting function, right? Given the way we've defined the weighting function, the way we've always defined the weighting function, we know that w goes to 0 on the Dirichlet boundary. So that term drops out. And here, we know that ji ni on the Neumann boundary is minus jn. All right, so, making these substitutions we arrive at integral over omega w rho partial time derivative of u, dV equals integral over omega, w comma i, ji dV plus integral over omega w f dv plus integral over the Neumann boundary, w jn dS, all right. Now, let me do just one more thing and we'll have the final weak form. I'm going to invoke the constitutive relation here, right? And we know that ji is minus kappa i j, u comma j. So, we invoke this, and then also observing that we have a minus sign in front of it, I'm going to move it to the left-hand side, okay? Right? So, what we have finally is the following. Integral over omega, w rho, partial time derivative of u, dV plus integral over omega, w comma i, kappa ij, u comma j, dV. Equals integral over omega, w f dV plus integral over the Neumann boundary, w jn dS, okay. This is everything we have, right. What, let, let me just write out now the finite dimensional weak form and we'll be ready to go, right? The finite dimensional weak form from here is obtained by just observing that any attempts to solve the, the infinite dimensional weak form are not likely to be any more easy than the strong form. So we decide to go to an approximate representation of it, all right. And what this says, is now find u h belonging to S h, all right. Which is a subset of S, okay? And what is Sh? Sh now is a collection of all functions of the type of denoted u h which, as before, we will expect to come from h1 on omega. Right, so the spatial dependence is going to be the same. Right, even in the time-dependent problem we are assuming that the kind of approximations we are going to construct will have the same dependents that we know from, from before on the spatial variable, okay? So we have this. U h equals u g on the Dirichlet boundary, okay? So find u h given this. Now we'll, let's assume all the data, right. So we know everything about the data, all right? Find u h belonging to S h such that for all w h belonging to V h subset of V, right? Where again, V h is also drawn from the space of H1 functions. Okay. Now, for all w h belonging to V h, the above weak form should hold, except that every function that is obtained from either w or u is replaced with the finite dimensional version of it, right? So we say that integral over omega w h rho partial time derivative of u h dV. Equals integral over omega w h comma i kappa i j u h, sorry, comma j. I realize I got the sign pro, I brought in the equality too early, plus sign here. DV equals integral over omega, w h f dV, plus integral over the Neumann boundary, w h j n dS, okay? This is our finite dimensional weak form for the, for the unsteady problem, right? Now, lets just stare at this for a few minutes, right? Or maybe, maybe not that long, but for a few seconds at least. Right, so now when we go through the whole process, what we expect is that just as before, right? We are going to do everything as before, right? Let's we, we, we are going to now, how do we go to these finite dimensional weak forms? Well we are, remember that, that, that these are, at this point, at this point, this problem is still finite dimensional only in space. We've done nothing about time, right? Because time is still very much of a true derivative, right? That is, that is a time derivative. We haven't done spe, anything special about approximating it yet, okay? So, as before, we will construct our finite dimensional basis by, by a partition of the domain, right? So as usual we will say partition. Omega equals union over e of each of these omegas. So e's, right, we have all that, right? Okay. And the picture is, is also the same as before. If this is omega you know, let's suppose again since we are in 3D, let us suppose that we are using our hexahedral element subdomains and. That is one of our elements, all right. This is omega sup B. Okay, all of that is the same.



\end{document}