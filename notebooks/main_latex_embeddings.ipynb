{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loading functions from the scripts\n",
    "\"\"\"\n",
    "Mostafa:\n",
    "I used the new structured output for question generation.\n",
    "It's a beta version, but it works on my end (10/23/2024).\n",
    "https://platform.openai.com/docs/guides/structured-outputs/structured-outputs\n",
    "\n",
    "For answer generation, I had some issues, so I used the standard API.\"\n",
    "\n",
    "Please upgrade before running this notebook: pip install --upgrade openai\n",
    "\"\"\"\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))  # Get parent directory of the notebook \n",
    "sys.path.append(parent_dir)  #  to the Python path\n",
    "\n",
    "from scripts.chunking import process_latex_files\n",
    "from scripts.embedding import get_embeddings, fixed_knn_retrieval\n",
    "from scripts.prompts import gen_questions, gen_questions_s, gen_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setting API and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mostafa: \n",
    "I suggest using 'gpt-4o' for production runs, but it is more expensive.\n",
    "For embeddings, I recommend 'text-embedding-3-large.' We only need to run it once, but it also costs more.\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "# https://openai.com/index/new-embedding-models-and-api-updates/\n",
    "# https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
    "\"\"\"\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # Replace with your actual API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "production_mode = True\n",
    "chunk_by_section = True\n",
    "chpt_for_quest_answ = 10\n",
    "\n",
    "if production_mode == False:\n",
    "    llm_model_questions = \"gpt-4o-mini\"\n",
    "    llm_model_answers = llm_model_questions     # option to run different model\n",
    "    embedding_size = \"large\"                    # small or large\n",
    "elif production_mode == True:\n",
    "    llm_model_questions = \"gpt-4o\"\n",
    "    llm_model_answers = llm_model_questions     # option to run different model\n",
    "    embedding_size = \"large\"                    # small or large\n",
    "\n",
    "embedding_model = f\"text-embedding-3-{embedding_size}\"  # NOTE: this must be the same for all embeddings. \n",
    "\n",
    "# Setting path for root data folder\n",
    "main_dir = '../data/hughes_latex_Q_then_A_use_context'\n",
    "\n",
    "if not os.path.exists(main_dir):\n",
    "    os.makedirs(main_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Context Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "Space size: (57, 3072)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mostafa: \n",
    "I used fixed size chunks (512) with a 25% overlap.\n",
    "Make sure environment_sensitive is set to False for fixed size.\n",
    "\n",
    "We should embed all chapters to generate the embedding space. For the demo, I only included two chapters.\n",
    "please update the paths in latex_file_paths.\n",
    "\"\"\"\n",
    "\n",
    "# add all book chapters paths\n",
    "latex_file_paths = [ \n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter1.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter2.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter3.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter4.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter7.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter8.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter9.tex',\n",
    "    '../data/FEM_Hughes_LaTeX_Textbook/chapter10.tex'\n",
    "]\n",
    "\n",
    "tokens_per_chunk = 4096                         # was 512\n",
    "token_overlap = int(0.25 * tokens_per_chunk)    # 25% overlap\n",
    "environment_sensitive = False                   # If False, equations can split between two chunks, but chunk lengths remain fixed.\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "if chunk_by_section == False:\n",
    "    embedding_space_file_name = f'{main_dir}/hughes_latex_embedding_space_tpc{tokens_per_chunk}_o{token_overlap}_{embedding_size}.json'\n",
    "elif chunk_by_section == True:\n",
    "    embedding_space_file_name = f'{main_dir}/hughes_latex_embedding_space_by_sections_tpc{tokens_per_chunk}_{embedding_size}.json'\n",
    "    token_overlap = 0\n",
    "\n",
    "space = {}\n",
    "if not os.path.exists(embedding_space_file_name):\n",
    "    \n",
    "    chunks = process_latex_files(latex_file_paths, \n",
    "                                 tokens_per_chunk, \n",
    "                                 token_overlap, \n",
    "                                 environment_sensitive, \n",
    "                                 chunk_by_section = chunk_by_section)\n",
    "    \n",
    "    chunk_length = []\n",
    "    char_length = []\n",
    "    print(chunks)\n",
    "    for chunk in chunks:\n",
    "        print(f\"chunk word length: {len(chunk.split(\" \"))}, chunk char length: {len(chunk)}, chunk = {chunk}\")\n",
    "        chunk_length.append(len(chunk.split(\" \")))\n",
    "        char_length.append(len(chunk))\n",
    "    print(f\"max chunk length in words = {np.max(chunk_length)}\")\n",
    "    print(f\"max chunk length in char = {np.max(char_length)}\")\n",
    "    #print(f\"chunk lengths = {chunk_length}\")\n",
    "\n",
    "    # using api\n",
    "    embedding_space = get_embeddings(client, chunks, model=embedding_model)\n",
    "    \n",
    "    # save\n",
    "    with open(embedding_space_file_name, 'w') as json_file:\n",
    "        json.dump({'embedding_model': embedding_model, 'chunks': chunks, 'embedding_space': embedding_space}, json_file)\n",
    "\n",
    "    print(\"saved\")\n",
    "else:\n",
    "    # save\n",
    "    with open(embedding_space_file_name, 'r') as json_file:\n",
    "        loaded_data = json.load(json_file)\n",
    "\n",
    "    chunks = loaded_data['chunks']\n",
    "    embedding_space = np.array(loaded_data['embedding_space'])\n",
    "    print(\"loaded\")\n",
    "\n",
    "chunks = np.array(chunks)\n",
    "embedding_space = np.array(embedding_space)\n",
    "print(\"Space size:\", embedding_space.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating Questions and Their Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ../data/hughes_latex_Q_then_A_use_context/hughes_ch10_Qs_n40_by_sections_tpc1536.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mostafa: \n",
    "For generating questions, we want larger chunks with a bit of overlap.\n",
    "The following values are just for this demo, so please adjust them as needed.\n",
    "\n",
    "I only ran Chapter One.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "chapter = chpt_for_quest_answ\n",
    "latex_file_path = f'../data/FEM_Hughes_LaTeX_Textbook/chapter{chapter}.tex'\n",
    "\n",
    "max_questions = 40                             # max number of questions per chunk\n",
    "\n",
    "tokens_per_chunk = 1536                       \n",
    "token_overlap = int(0.2 * tokens_per_chunk)   # 10% overlap\n",
    "environment_sensitive = True                  # If True, equations won't be split between chunks, which may result in chunks larger than the specified tokens_per_chunk\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def embed_all_q(questions):\n",
    "    all_questions = []\n",
    "    for item in questions['data']:\n",
    "        for sub_item in item['questions']:\n",
    "            all_questions.append(sub_item['question'])\n",
    "    # using api\n",
    "    embeddings = get_embeddings(client, all_questions, model = embedding_model) \n",
    "    # add them to data:\n",
    "    k = 0\n",
    "    for item in questions['data']:\n",
    "        for sub_item in item['questions']:\n",
    "            sub_item['embedding'] = embeddings[k]\n",
    "            k +=1\n",
    "    print('Questions are embedded')\n",
    "    return questions\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "if chunk_by_section == False:\n",
    "    questions_file_name = f\"{main_dir}/hughes_ch{chapter}_Qs_n{max_questions}_tpc{tokens_per_chunk}_o{token_overlap}.json\"   \n",
    "elif chunk_by_section == True:\n",
    "    questions_file_name = f\"{main_dir}/hughes_ch{chapter}_Qs_n{max_questions}_by_sections_tpc{tokens_per_chunk}.json\"  \n",
    "    token_overlap = 0 \n",
    "\n",
    "if not os.path.exists(questions_file_name):\n",
    "    question_chunks = process_latex_files(latex_file_path, tokens_per_chunk, token_overlap, environment_sensitive, chunk_by_section=chunk_by_section)\n",
    "    \n",
    "    if production_mode == False:\n",
    "        question_chunks = question_chunks[0:7] # for testing small batch\n",
    "    \n",
    "    for question in question_chunks:\n",
    "        print(f\"chunk word length: {len(question.split(\" \"))}, chunk char length: {len(question)}, chunk = {question}\")\n",
    "\n",
    "    questions = {}  # main data\n",
    "\n",
    "    # we should save generation info we used\n",
    "    questions['info'] = {\n",
    "        'tokens_per_chunk': tokens_per_chunk,\n",
    "        'token_overlap': token_overlap,\n",
    "        'environment_sensitive': environment_sensitive,\n",
    "        'max_questions': max_questions,\n",
    "        'embedding_model': embedding_model,\n",
    "        'llm_model_questions': llm_model_questions,\n",
    "        'llm_model_answers': llm_model_answers\n",
    "    }\n",
    "\n",
    "    ## step 1: generate questions\n",
    "    questions['data'] = []\n",
    "    for i in tqdm(range(len(question_chunks)), desc=\"Generating Questions\"):\n",
    "        # q_for_chunk = gen_questions(client, question_chunks[i], max_questions, model=llm_model_questions)\n",
    "        q_for_chunk = gen_questions_s(client, question_chunks[i], max_questions, model=llm_model_questions)   # Using the new function\n",
    "        questions['data'].append({'chunk': question_chunks[i],'questions': q_for_chunk})\n",
    "    print('Questions are generated')\n",
    "\n",
    "    ## step 2: embedding all questions at once\n",
    "    questions = embed_all_q(questions)\n",
    "    \n",
    "\n",
    "    with open(questions_file_name, 'w') as json_file:\n",
    "        json.dump(questions, json_file, indent=4)\n",
    "    print('saved', questions_file_name)\n",
    "\n",
    "else:\n",
    "    with open(questions_file_name, 'r') as json_file:\n",
    "        questions = json.load(json_file)\n",
    "\n",
    "    print('loaded', questions_file_name)\n",
    "\n",
    "if questions['info']['embedding_model'] != embedding_model:\n",
    "    print(\"embedding model mismatch. re-embedding questions\")\n",
    "    questions = embed_all_q(questions)\n",
    "    questions['info']['embedding_model'] = embedding_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Context Retrieval and Generating Answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k context added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering Questions: 100%|██████████| 10/10 [28:18<00:00, 169.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions are answered\n",
      "saved ../data/hughes_latex_Q_then_A_use_context/hughes_ch10_QAs_n40_topk10_by_sections.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mostafa: \n",
    "Since we answer each question separately, this process is slow.\n",
    "We might want to consider using the batch API for this.\n",
    "\"\"\"\n",
    "\n",
    "top_k = 10   # number of retrieved closest contexts         \n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "if chunk_by_section == False:\n",
    "    questions_answers_file_name = f\"{main_dir}/hughes_ch{chapter}_QAs_n{max_questions}_topk{top_k}_tpc{tokens_per_chunk}_o{token_overlap}.json\"   \n",
    "elif chunk_by_section == True:\n",
    "    questions_answers_file_name = f\"{main_dir}/hughes_ch{chapter}_QAs_n{max_questions}_topk{top_k}_by_sections.json\"   \n",
    "\n",
    "if not os.path.exists(questions_answers_file_name):\n",
    "\n",
    "    questions_answers = questions.copy()\n",
    "\n",
    "    # step 1) finding top_k context from the book embedding and adding them to each question\n",
    "    for item in questions_answers['data']:\n",
    "        for sub_item in item['questions']:\n",
    "            ind = fixed_knn_retrieval(sub_item['embedding'], embedding_space, top_k)\n",
    "            context = ''\n",
    "            for i, chunk in enumerate(chunks[ind]):\n",
    "                context += f'\\n\\n Additional context {i}: {chunk}' \n",
    "            sub_item['context'] = context\n",
    "    print('top_k context added')\n",
    "\n",
    "    # step 2) generating answers (slow)  (should we try batch API?)\n",
    "    for item in tqdm(questions_answers['data'], desc=\"Answering Questions\"):\n",
    "        question_chunk = item['chunk']\n",
    "        for sub_item in item['questions']:\n",
    "            question = sub_item['question']\n",
    "            context = question_chunk + sub_item['context']\n",
    "            sub_item['answer'] = gen_answer(client, question, context, model = llm_model_answers)\n",
    "    print('Questions are answered')\n",
    "    \n",
    "    with open(questions_answers_file_name, 'w') as json_file:\n",
    "        json.dump(questions_answers, json_file, indent=4)\n",
    "    print('saved', questions_answers_file_name)\n",
    "\n",
    "else:\n",
    "    with open(questions_answers_file_name, 'r') as json_file:\n",
    "        questions_answers = json.load(json_file)\n",
    "\n",
    "    print('loaded', questions_answers_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_chunk</th>\n",
       "      <th>context</th>\n",
       "      <th>coverage</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this chapter we are concerned with algorith...</td>\n",
       "      <td>\\n\\n Additional context 0: In this chapter we ...</td>\n",
       "      <td>90</td>\n",
       "      <td>What is the generalized eigenproblem in the co...</td>\n",
       "      <td>The generalized eigenproblem in the context of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this chapter we are concerned with algorith...</td>\n",
       "      <td>\\n\\n Additional context 0: In this chapter we ...</td>\n",
       "      <td>85</td>\n",
       "      <td>Explain the significance of the eigenvalues an...</td>\n",
       "      <td>The eigenvalues and eigenvectors in the genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this chapter we are concerned with algorith...</td>\n",
       "      <td>\\n\\n Additional context 0: The shape functions...</td>\n",
       "      <td>80</td>\n",
       "      <td>Describe the conditions under which the eigenv...</td>\n",
       "      <td>The eigenvalues of the generalized eigenproble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this chapter we are concerned with algorith...</td>\n",
       "      <td>\\n\\n Additional context 0: In this chapter we ...</td>\n",
       "      <td>95</td>\n",
       "      <td>Why are the lower modes of the generalized eig...</td>\n",
       "      <td>The lower modes of the generalized eigenproble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this chapter we are concerned with algorith...</td>\n",
       "      <td>\\n\\n Additional context 0: In practice one oft...</td>\n",
       "      <td>75</td>\n",
       "      <td>What is the reduced system form of the general...</td>\n",
       "      <td>The reduced system form of the generalized eig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>vector is orthogonalized against this known ei...</td>\n",
       "      <td>\\n\\n Additional context 0: $\\boldsymbol{K}_{\\b...</td>\n",
       "      <td>60</td>\n",
       "      <td>What are the computational benefits of retriev...</td>\n",
       "      <td>The computational benefits of retrieving Lancz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>vector is orthogonalized against this known ei...</td>\n",
       "      <td>\\n\\n Additional context 0: amplitude of $\\bold...</td>\n",
       "      <td>75</td>\n",
       "      <td>How does the orthogonalization of $q_{j+1}$ ag...</td>\n",
       "      <td>The orthogonalization of $q_{j+1}$ against a R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>vector is orthogonalized against this known ei...</td>\n",
       "      <td>\\n\\n Additional context 0: \\subsection*{10.6.1...</td>\n",
       "      <td>55</td>\n",
       "      <td>What is the significance of monitoring the ele...</td>\n",
       "      <td>Monitoring the elements of $\\boldsymbol{h}_{j+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>vector is orthogonalized against this known ei...</td>\n",
       "      <td>\\n\\n Additional context 0: amplitude of $\\bold...</td>\n",
       "      <td>50</td>\n",
       "      <td>Explain the impact of spectral transformation ...</td>\n",
       "      <td>The impact of spectral transformation on the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>vector is orthogonalized against this known ei...</td>\n",
       "      <td>\\n\\n Additional context 0: $\\boldsymbol{K}_{\\b...</td>\n",
       "      <td>65</td>\n",
       "      <td>What are the implications of performing orthog...</td>\n",
       "      <td>Answer: Performing orthogonalization against f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question_chunk  \\\n",
       "0    In this chapter we are concerned with algorith...   \n",
       "1    In this chapter we are concerned with algorith...   \n",
       "2    In this chapter we are concerned with algorith...   \n",
       "3    In this chapter we are concerned with algorith...   \n",
       "4    In this chapter we are concerned with algorith...   \n",
       "..                                                 ...   \n",
       "161  vector is orthogonalized against this known ei...   \n",
       "162  vector is orthogonalized against this known ei...   \n",
       "163  vector is orthogonalized against this known ei...   \n",
       "164  vector is orthogonalized against this known ei...   \n",
       "165  vector is orthogonalized against this known ei...   \n",
       "\n",
       "                                               context  coverage  \\\n",
       "0    \\n\\n Additional context 0: In this chapter we ...        90   \n",
       "1    \\n\\n Additional context 0: In this chapter we ...        85   \n",
       "2    \\n\\n Additional context 0: The shape functions...        80   \n",
       "3    \\n\\n Additional context 0: In this chapter we ...        95   \n",
       "4    \\n\\n Additional context 0: In practice one oft...        75   \n",
       "..                                                 ...       ...   \n",
       "161  \\n\\n Additional context 0: $\\boldsymbol{K}_{\\b...        60   \n",
       "162  \\n\\n Additional context 0: amplitude of $\\bold...        75   \n",
       "163  \\n\\n Additional context 0: \\subsection*{10.6.1...        55   \n",
       "164  \\n\\n Additional context 0: amplitude of $\\bold...        50   \n",
       "165  \\n\\n Additional context 0: $\\boldsymbol{K}_{\\b...        65   \n",
       "\n",
       "                                              question  \\\n",
       "0    What is the generalized eigenproblem in the co...   \n",
       "1    Explain the significance of the eigenvalues an...   \n",
       "2    Describe the conditions under which the eigenv...   \n",
       "3    Why are the lower modes of the generalized eig...   \n",
       "4    What is the reduced system form of the general...   \n",
       "..                                                 ...   \n",
       "161  What are the computational benefits of retriev...   \n",
       "162  How does the orthogonalization of $q_{j+1}$ ag...   \n",
       "163  What is the significance of monitoring the ele...   \n",
       "164  Explain the impact of spectral transformation ...   \n",
       "165  What are the implications of performing orthog...   \n",
       "\n",
       "                                                answer  \n",
       "0    The generalized eigenproblem in the context of...  \n",
       "1    The eigenvalues and eigenvectors in the genera...  \n",
       "2    The eigenvalues of the generalized eigenproble...  \n",
       "3    The lower modes of the generalized eigenproble...  \n",
       "4    The reduced system form of the generalized eig...  \n",
       "..                                                 ...  \n",
       "161  The computational benefits of retrieving Lancz...  \n",
       "162  The orthogonalization of $q_{j+1}$ against a R...  \n",
       "163  Monitoring the elements of $\\boldsymbol{h}_{j+...  \n",
       "164  The impact of spectral transformation on the l...  \n",
       "165  Answer: Performing orthogonalization against f...  \n",
       "\n",
       "[166 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mostafa: \n",
    "I think it's better to work with JSON/DataFrame in the code, but for reviewing QAs, CSV is easier to work with\n",
    "\"\"\"\n",
    "\n",
    "csv_file_name = f\"{main_dir}/hughes_ch{chapter}_QAs_n{max_questions}.csv\"   \n",
    "# ----------------------------------\n",
    "\n",
    "data = []\n",
    "\n",
    "for item in questions_answers['data']:\n",
    "    question_chunk = item['chunk']\n",
    "    for sub_item in item['questions']:\n",
    "        new_item = {}\n",
    "        new_item['question_chunk'] = question_chunk\n",
    "        for k,v in sub_item.items():\n",
    "            if k == 'embedding':\n",
    "                continue\n",
    "            new_item[k] = v\n",
    "        data.append(new_item)\n",
    "\n",
    "# data[0]\n",
    "df = pd.DataFrame(data)[['question_chunk','context','coverage','question','answer']]\n",
    "df.to_csv(csv_file_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print and review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=160):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      "In Exercise 3, obtain an exact solution for the static problem $K d=F$ using an eigenvector expansion. Discuss the relative importance of low and high modes in\n",
      "this context.\n",
      "A:\n",
      "To obtain an exact solution for the static problem $K d = F$ using an eigenvector expansion, we can express the displacement vector $d$ in terms of the\n",
      "eigenvectors of the matrix $K$. Given that $K$ is symmetric and positive-semidefinite, it has a complete set of orthonormal eigenvectors\n",
      "$\\{\\psi_l\\}_{l=1}^{n_{eq}}$ corresponding to eigenvalues $\\{\\lambda_l\\}_{l=1}^{n_{eq}}$. The solution can be expanded as:  $$ d = \\sum_{l=1}^{n_{eq}} c_l \\psi_l\n",
      "$$  where $c_l$ are coefficients to be determined. Substituting this expansion into the static problem $K d = F$, we have:  $$ K \\left( \\sum_{l=1}^{n_{eq}} c_l\n",
      "\\psi_l \\right) = F $$  Using the orthogonality property of the eigenvectors with respect to $K$, we have:  $$ \\sum_{l=1}^{n_{eq}} c_l \\lambda_l \\psi_l = F $$\n",
      "To find the coefficients $c_l$, we project the force vector $F$ onto each eigenvector $\\psi_k$:  $$ \\psi_k^T K d = \\psi_k^T F $$  This simplifies to:  $$\n",
      "\\lambda_k c_k = \\psi_k^T F $$  Thus, the coefficients are given by:  $$ c_k = \\frac{\\psi_k^T F}{\\lambda_k} $$  provided $\\lambda_k \\neq 0$. If $\\lambda_k = 0$,\n",
      "the corresponding mode does not contribute to the static response.  The solution is then:  $$ d = \\sum_{l=1}^{n_{eq}} \\frac{\\psi_l^T F}{\\lambda_l} \\psi_l $$\n",
      "**Discussion on the Relative Importance of Low and High Modes:**  In the context of static problems, the low modes (those with smaller eigenvalues $\\lambda_l$)\n",
      "are generally more significant. This is because the contribution of each mode to the displacement $d$ is inversely proportional to its eigenvalue $\\lambda_l$.\n",
      "Therefore, modes with smaller eigenvalues (low modes) have a larger influence on the displacement solution.  High modes, which correspond to larger eigenvalues,\n",
      "contribute less to the static solution due to the $1/\\lambda_l$ factor. Additionally, in practical finite element discretizations, high modes often represent\n",
      "numerical artifacts rather than physical behavior, making them less relevant for engineering applications. Thus, focusing on the low modes is typically\n",
      "sufficient for capturing the essential behavior of the system in static problems.\n",
      "\n",
      "Chunk used for Q generation:\n",
      "In this chapter we are concerned with algorithms for solving the so-called generalized eigenproblem arising from finite element discretizations. Recall that\n",
      "this takes the form:\\footnote{Problems of this type are motivated and formulated in Chapter 7. To simplify subsequent writing we omit the superscript $h$ on\n",
      "$\\lambda$.} \\begin{equation*} (K-\\lambda M) \\psi=0 \\tag{10.1.1} \\end{equation*} where $K$ is symmetric and positive-semidefinite, $M$ is symmetric and positive-\n",
      "definite, and both matrices possess typical band/profile structure. For convenience we recall some basic properties of the solution of (10.1.1). We assume as\n",
      "always that the dimensions of $K$ and $M$ are $n_{e q} \\times n_{e q}$. There exist $n_{e q}$ eigenvalues and corresponding eigenvectors\\footnote{The\n",
      "eigenvectors may be nonunique.} that satisfy (10.1.1). That is, \\begin{equation*} \\left(K-\\lambda_{l} M\\right) \\psi_{l}=0, \\quad \\text { (no sum) } \\tag{10.1.2}\n",
      "\\end{equation*} where $l=1,2, \\ldots, n_{e q}$ denotes the mode number. Furthermore, \\begin{equation*} 0 \\leq \\lambda_{1} \\leq \\lambda_{2} \\leq \\cdots \\leq\n",
      "\\lambda_{n_{\\text {eq }}} \\tag{10.1.3} \\end{equation*} and \\[ \\begin{array}{lll} \\Psi_{k}^{T} M \\Psi_{l}=\\delta_{k l} & \\text { (M orthonormality) } \\\\\n",
      "\\Psi_{k}^{T} K \\Psi_{l}=\\lambda_{l} \\delta_{k l} & \\text { (no sum) } & \\text { (K orthogonality) } \\tag{10.1.5} \\end{array} \\] The eigenvectors\n",
      "$\\left\\{\\psi_{l}\\right\\}_{l=1}^{n_{e q}}$ constitute a basis for $\\mathbb{R}^{n_{e e}}$. If, additionally, $\\boldsymbol{K}$ is positivedefinite, as is often the\n",
      "case, then (10.1.3) may be strengthened as follows: \\begin{equation*} 0<\\lambda_{1} \\leq \\lambda_{2} \\leq \\cdots \\leq \\lambda_{n_{\\text {eq }}} \\tag{10.1.6}\n",
      "\\end{equation*} In practice, we are typically interested only in the lower modes. These are the most important from a physical standpoint. For example, the\n",
      "lowest mode is the most important in a structural stability (i.e., \"buckling\") calculation and the lower frequencies and corresponding mode shapes are usually\n",
      "the most important in considerations of dynamic response. Additionally, the higher modes of finite element discretizations are not accurate renditions of\n",
      "physical behavior but rather spurious artifacts of the discretization process. Consequently, they are of no engineering interest. For these reasons, we are\n",
      "interested in economical computational algorithms for extracting $\\left\\{\\lambda_{l}, \\Psi_{l}\\right\\}, 1 \\leq l \\leq n_{\\text {modes }}$, where $n_{\\text\n",
      "{modes }} \\ll n_{e q}$ is the number of desired eigenpairs. In practice $n_{\\text {eq }}$ may be very large, and thus solution of the eigenvalue problem, even\n",
      "for only a few eigenpairs, may entail an extensive and costly calculation. Most procedures used for solving the large-scale generalized eigenproblem, (10.1.1),\n",
      "involve a reduced system of the form \\begin{equation*} \\left(\\boldsymbol{K}^{*}-\\lambda^{*} \\boldsymbol{M}^{*}\\right) \\Psi^{*}=0 \\tag{10.1.7} \\end{equation*}\n",
      "where $K^{*}$ and $M^{*}$ are small, full, symmetric matrices. Algorithms, such as the generalized Jacobi method [1], are available for directly solving\n",
      "(10.1.7). Systems such as (10.1.7) may also be solved by first transforming to standard form: \\begin{equation*} \\left(\\bar{K}^{*}-\\lambda^{*}\n",
      "\\boldsymbol{I}\\right) \\bar{\\Psi}^{*}=\\mathbf{0} \\tag{10.1.8} \\end{equation*} where \\begin{align*} & \\overline{\\mathbf{K}}^{*}=\\overline{\\boldsymbol{U}}^{-T}\n",
      "\\mathbf{K}^{*} \\bar{U}^{-1} \\tag{10.1.9}\\\\ & \\overline{\\boldsymbol{\\Psi}}^{*}=\\overline{\\boldsymbol{U}} \\boldsymbol{\\Psi}^{*} \\tag{10.1.10} \\end{align*} and\n",
      "$\\boldsymbol{U}$ is the upper-triangular Cholesky factor of $M^{*}$, i.e., \\begin{equation*} \\boldsymbol{M}^{*}=\\overline{\\boldsymbol{U}}^{T}\n",
      "\\boldsymbol{\\overline{U}} \\tag{10.1.11} \\end{equation*} (The Cholesky factor is related to the Crout factor by $\\boldsymbol{\\overline{U}}=D^{1 / 2}\n",
      "\\boldsymbol{U}$, where $\\boldsymbol{M}^{*}=$ $\\boldsymbol{U}^{\\boldsymbol{T}} \\boldsymbol{D} \\boldsymbol{U}, \\boldsymbol{U}$ is upper-triangular with ones on\n",
      "the diagonal and $\\boldsymbol{D}$ is a diagonal matrix of positive numbers; see Chapter 11 for further information on the Crout factorization.) Observe that the\n",
      "eigenvalues of the standard form, (10.1.8), are identical to the generalized form, (10.1.7). However, the eigenvectors need to be transformed as indicated by\n",
      "(10.1.10) \\textbf{Exercise 1.} Derive (10.1.7) from (10.1.8) through (10.1.11). There are many classical and widely available procedures for solving (10.1.8).\n",
      "For example, the Jacobi, Givens, and Householder-QR methods may be mentioned in this regard (e.g., see Bathe [1] and Noble [2]). For general matrices, it is\n",
      "currently felt that the most efficient strategy for solving the generalized eigenproblem, (10.1.7), is to first transform to standard form, (10.1.8), and then\n",
      "use the Householder-QR algorithm. However, under certain circumstances, such as when the subspace iteration procedure is employed (see Sec. 10.5), for example,\n",
      "direct use of the generalized Jacobi method proves very effective. It is very difficult to make sweeping statements about efficiency because the type of\n",
      "computer (e.g., sequential, vector, or parallel) strongly influences the performance of algorithms. \\textbf{Exercise 2.} Consider the undamped equation of\n",
      "motion, \\begin{equation*} M \\Ddot{d}+K d=F \\tag{10.1.12} \\end{equation*} subject to zero initial displacement and velocity. Expand the solution in terms of the\n",
      "eigenvectors of the associated eigenproblem. Diagonalize the system and exactly solve the individual modal equations. Show that \\begin{equation*}\n",
      "d(t)=\\sum_{l=1}^{n_{e q}}\\left\\{\\frac{1}{\\omega_{l}} \\int_{0}^{t} F_{(l)}(\\tau) \\sin \\omega_{l}(t-\\tau) d \\tau \\Psi_{l}\\right\\} \\tag{10.1.13} \\end{equation*}\n",
      "The $1 / \\omega_{l}$ factor in the expansion illustrates the diminishing influence of the higher modes. This analysis reveals why low mode response is viewed as\n",
      "\"most important\" and therefore, why, in practical calculations the summation in (10.1.13) is truncated at $n_{\\text {modes }} \\ll n_{\\text {eq }}$.\n",
      "\\textbf{Exercise 3.} Obtain an exact solution for the static problem, \\begin{equation*} \\boldsymbol{K} \\boldsymbol{d}=\\boldsymbol{F} \\tag{10.1.14}\n",
      "\\end{equation*} by way of an eigenvector expansion. Discuss the relative importance of low and high modes for this case. \\textbf{Exercise 4.} Generalize\n",
      "Exercise 2 to account for Rayleigh damping and non-zero initial conditions. Discuss the influence of low and high modes.\n",
      "\n",
      "Retrieved context:\n",
      "\n",
      "\n",
      " 0: In this chapter we are concerned with algorithms for solving the so-called generalized eigenproblem arising from finite element discretizations. Recall that\n",
      "this takes the form:\\footnote{Problems of this type are motivated and formulated in Chapter 7. To simplify subsequent writing we omit the superscript $h$ on\n",
      "$\\lambda$.} \\begin{equation*} (K-\\lambda M) \\psi=0 \\tag{10.1.1} \\end{equation*} where $K$ is symmetric and positive-semidefinite, $M$ is symmetric and positive-\n",
      "definite, and both matrices possess typical band/profile structure. For convenience we recall some basic properties of the solution of (10.1.1). We assume as\n",
      "always that the dimensions of $K$ and $M$ are $n_{e q} \\times n_{e q}$. There exist $n_{e q}$ eigenvalues and corresponding eigenvectors\\footnote{The\n",
      "eigenvectors may be nonunique.} that satisfy (10.1.1). That is, \\begin{equation*} \\left(K-\\lambda_{l} M\\right) \\psi_{l}=0, \\quad \\text { (no sum) } \\tag{10.1.2}\n",
      "\\end{equation*} where $l=1,2, \\ldots, n_{e q}$ denotes the mode number. Furthermore, \\begin{equation*} 0 \\leq \\lambda_{1} \\leq \\lambda_{2} \\leq \\cdots \\leq\n",
      "\\lambda_{n_{\\text {eq }}} \\tag{10.1.3} \\end{equation*} and \\[ \\begin{array}{lll} \\Psi_{k}^{T} M \\Psi_{l}=\\delta_{k l} & \\text { (M orthonormality) } \\\\\n",
      "\\Psi_{k}^{T} K \\Psi_{l}=\\lambda_{l} \\delta_{k l} & \\text { (no sum) } & \\text { (K orthogonality) } \\tag{10.1.5} \\end{array} \\] The eigenvectors\n",
      "$\\left\\{\\psi_{l}\\right\\}_{l=1}^{n_{e q}}$ constitute a basis for $\\mathbb{R}^{n_{e e}}$. If, additionally, $\\boldsymbol{K}$ is positivedefinite, as is often the\n",
      "case, then (10.1.3) may be strengthened as follows: \\begin{equation*} 0<\\lambda_{1} \\leq \\lambda_{2} \\leq \\cdots \\leq \\lambda_{n_{\\text {eq }}} \\tag{10.1.6}\n",
      "\\end{equation*} In practice, we are typically interested only in the lower modes. These are the most important from a physical standpoint. For example, the\n",
      "lowest mode is the most important in a structural stability (i.e., \"buckling\") calculation and the lower frequencies and corresponding mode shapes are usually\n",
      "the most important in considerations of dynamic response. Additionally, the higher modes of finite element discretizations are not accurate renditions of\n",
      "physical behavior but rather spurious artifacts of the discretization process. Consequently, they are of no engineering interest. For these reasons, we are\n",
      "interested in economical computational algorithms for extracting $\\left\\{\\lambda_{l}, \\Psi_{l}\\right\\}, 1 \\leq l \\leq n_{\\text {modes }}$, where $n_{\\text\n",
      "{modes }} \\ll n_{e q}$ is the number of desired eigenpairs. In practice $n_{\\text {eq }}$ may be very large, and thus solution of the eigenvalue problem, even\n",
      "for only a few eigenpairs, may entail an extensive and costly calculation. Most procedures used for solving the large-scale generalized eigenproblem, (10.1.1),\n",
      "involve a reduced system of the form \\begin{equation*} \\left(\\boldsymbol{K}^{*}-\\lambda^{*} \\boldsymbol{M}^{*}\\right) \\Psi^{*}=0 \\tag{10.1.7} \\end{equation*}\n",
      "where $K^{*}$ and $M^{*}$ are small, full, symmetric matrices. Algorithms, such as the generalized Jacobi method [1], are available for directly solving\n",
      "(10.1.7). Systems such as (10.1.7) may also be solved by first transforming to standard form: \\begin{equation*} \\left(\\bar{K}^{*}-\\lambda^{*}\n",
      "\\boldsymbol{I}\\right) \\bar{\\Psi}^{*}=\\mathbf{0} \\tag{10.1.8} \\end{equation*} where \\begin{align*} & \\overline{\\mathbf{K}}^{*}=\\overline{\\boldsymbol{U}}^{-T}\n",
      "\\mathbf{K}^{*} \\bar{U}^{-1} \\tag{10.1.9}\\\\ & \\overline{\\boldsymbol{\\Psi}}^{*}=\\overline{\\boldsymbol{U}} \\boldsymbol{\\Psi}^{*} \\tag{10.1.10} \\end{align*} and\n",
      "$\\boldsymbol{U}$ is the upper-triangular Cholesky factor of $M^{*}$, i.e., \\begin{equation*} \\boldsymbol{M}^{*}=\\overline{\\boldsymbol{U}}^{T}\n",
      "\\boldsymbol{\\overline{U}} \\tag{10.1.11} \\end{equation*} (The Cholesky factor is related to the Crout factor by $\\boldsymbol{\\overline{U}}=D^{1 / 2}\n",
      "\\boldsymbol{U}$, where $\\boldsymbol{M}^{*}=$ $\\boldsymbol{U}^{\\boldsymbol{T}} \\boldsymbol{D} \\boldsymbol{U}, \\boldsymbol{U}$ is upper-triangular with ones on\n",
      "the diagonal and $\\boldsymbol{D}$ is a diagonal matrix of positive numbers; see Chapter 11 for further information on the Crout factorization.) Observe that the\n",
      "eigenvalues of the standard form, (10.1.8), are identical to the generalized form, (10.1.7). However, the eigenvectors need to be transformed as indicated by\n",
      "(10.1.10) \\textbf{Exercise 1.} Derive (10.1.7) from (10.1.8) through (10.1.11). There are many classical and widely available procedures for solving (10.1.8).\n",
      "For example, the Jacobi, Givens, and Householder-QR methods may be mentioned in this regard (e.g., see Bathe [1] and Noble [2]). For general matrices, it is\n",
      "currently felt that the most efficient strategy for solving the generalized eigenproblem, (10.1.7), is to first transform to standard form, (10.1.8), and then\n",
      "use the Householder-QR algorithm. However, under certain circumstances, such as when the subspace iteration procedure is employed (see Sec. 10.5), for example,\n",
      "direct use of the generalized Jacobi method proves very effective. It is very difficult to make sweeping statements about efficiency because the type of\n",
      "computer (e.g., sequential, vector, or parallel) strongly influences the performance of algorithms. \\textbf{Exercise 2.} Consider the undamped equation of\n",
      "motion, \\begin{equation*} M \\Ddot{d}+K d=F \\tag{10.1.12} \\end{equation*} subject to zero initial displacement and velocity. Expand the solution in terms of the\n",
      "eigenvectors of the associated eigenproblem. Diagonalize the system and exactly solve the individual modal equations. Show that \\begin{equation*}\n",
      "d(t)=\\sum_{l=1}^{n_{e q}}\\left\\{\\frac{1}{\\omega_{l}} \\int_{0}^{t} F_{(l)}(\\tau) \\sin \\omega_{l}(t-\\tau) d \\tau \\Psi_{l}\\right\\} \\tag{10.1.13} \\end{equation*}\n",
      "The $1 / \\omega_{l}$ factor in the expansion illustrates the diminishing influence of the higher modes. This analysis reveals why low mode response is viewed as\n",
      "\"most important\" and therefore, why, in practical calculations the summation in (10.1.13) is truncated at $n_{\\text {modes }} \\ll n_{\\text {eq }}$.\n",
      "\\textbf{Exercise 3.} Obtain an exact solution for the static problem, \\begin{equation*} \\boldsymbol{K} \\boldsymbol{d}=\\boldsymbol{F} \\tag{10.1.14}\n",
      "\\end{equation*} by way of an eigenvector expansion. Discuss the relative importance of low and high modes for this case. \\textbf{Exercise 4.} Generalize\n",
      "Exercise 2 to account for Rayleigh damping and non-zero initial conditions. Discuss the influence of low and high modes.\n",
      "\n",
      " 1: The developments of this section generalize those of Secs. 2.7 through 2.10. The nature of the generalization is similar in format to that of the previous\n",
      "section and the reader should first become familiar with Sec. 7.1 before considering this section even if he or she is uninterested in heat conduction. The\n",
      "initial conditions this time involve specification of both displacements and velocities. Thus \\begin{equation*} u_{0i}: \\Omega \\rightarrow \\mathbb{R}\n",
      "\\tag{7.2.1} \\end{equation*} and \\begin{equation*} \\dot{u}_{0 i}: \\Omega \\rightarrow \\mathbb{R} \\tag{7.2.2} \\end{equation*} are given functions for each $i, 1\n",
      "\\leq i \\leq n_{s d}$. The superposed-dot notation in (7.2.2) is symbolic rather than operational. The remaining prescribed data are \\begin{align*} &\n",
      "\\left.f_{i}: \\Omega \\times\\right] 0, T[\\rightarrow \\mathbb{R} \\tag{7.2.3}\\\\ & \\left.g_{i}: \\Gamma_{q_{i}} \\times\\right] 0, T[\\rightarrow \\mathbb{R}\n",
      "\\tag{7.2.4}\\\\ & \\left.h_{i}: \\Gamma_{h_{i}} \\times\\right] 0, T[\\rightarrow \\mathbb{R} \\tag{7.2.5} \\end{align*} The density, $\\rho: \\Omega \\rightarrow\n",
      "\\mathbb{R}$, assumed to be positive, needs also to be specified in the present case. The strong form of the initial/boundary-value problem is \\[\n",
      "(S)\\left\\{\\begin{array}{rlrl} \\text { Given } f_{i}, g_{i}, h_{i}, u_{0 i} & \\text { and } \\dot{u}_{0 i}, \\text { as in (7.2.1) through (7.2.5), find }\n",
      "\\tag{7.2.6}\\\\ {[0, T] \\rightarrow \\mathbb{R} \\text { such that }} & & \\\\ \\rho u_{i, t t} & =\\sigma_{ij, j}+f_{i} & & \\text { on } \\Omega \\times] 0, T[\\text {\n",
      "(equation of motion) } \\\\ u_{i} & =g_{i} & & \\text { on } \\left.\\Gamma_{g_{i}} \\times\\right] 0, T[ \\\\ \\sigma_{i j} n_{j} & =h_{i} & & \\text { on }\n",
      "\\left.\\Gamma_{h_{i}} \\times\\right] 0, T[ \\\\ u_{i}(x, 0) & =u_{0 i}(x) & & x \\in \\Omega \\\\ u_{i, t}(x, 0) & =\\dot{u}_{0 i}(x) & & x \\in \\Omega \\end{array}\\right.\n",
      "\\] Recall that $\\sigma_{i j}=c_{i j k l} u_{(k, l)}$ and $c_{i j k l}=c_{i j k l}(x)$. Note that the second time derivative (i.e., acceleration) appears in\n",
      "(7.2.6). This is the reason that two initial conditions are required.\\\\ The corresponding weak formulation is: ${ }^{1}$ \\footnotetext{${ }^{1}$ We now use\n",
      "\"direct notation\"; see Chapter 2 for elaboration. }$(W)\\left\\{\\begin{array}{c}\\text { Given } f, g, h, u_{0}, \\text { and } \\dot{u}_{0}, \\text { find } u(t) \\in\n",
      "\\mathcal{S}_{t}, t \\in[0, T], \\text { such that for all } w \\in \\mathcal{V}, \\\\ (w, \\rho \\ddot{u})+a(w, u)=(w, f)+(w, h)_{\\Gamma}\\\\ (w, \\rho u(0))=\\left(w, \\rho\n",
      "u_{0}\\right) \\\\ (w, \\rho \\dot{u}(0))=\\left(w, \\rho \\dot{u}_{0}\\right)\\end{array}\\right.$ Exercise 1. Verify the formal equivalence of $(S)$ and $(W)$. The\n",
      "arguments of Chapter 2 may be used virtually unaltered if $(\\mathbf{7 . 2 . 1 1})$ is written as $$ a(w, u)=(w, \\tilde{f})+(w, k)_\\Gamma $$ where $$\n",
      "\\tilde{f}=f-\\rho \\ddot{u} $$ The semidiscrete Galerkin formulation of elastodynamics is:\\\\ (G) $\\left\\{\\begin{array}{l}\\text { Given } f, g, k, u_{0}, \\text {\n",
      "and } \\dot{u}_{0} \\text {, find } u^{h}=v^{h}+g^{h}, u^{h}(t) \\in \\mathcal{S}_{t}^{h}, \\text { such that for all } \\\\ w^{h} \\in \\mathcal{V}^{h}, \\\\ \\left(w^{h},\n",
      "\\rho \\ddot{v}^{h}\\right)+a\\left(w^{h}, v^{h}\\right)=\\left(w^{h}, f\\right)+\\left(w^{h}, h\\right)_{\\Gamma}-\\left(w^{h}, \\rho \\ddot{q}^{h}\\right)-a\\left(w^{h},\n",
      "g^{h}\\right) \\\\ \\left(w^{h}, \\rho v^{h}(0)\\right)=\\left(w^{h}, \\rho u_{0}\\right)-\\left(w^{h}, \\rho g^{h}(0)\\right) \\\\ \\left(w^{h}, \\rho\n",
      "\\dot{v}^{h}(0)\\right)=\\left(w^{h}, \\rho \\dot{u_{0}}\\right)-\\left(w^{h}, \\rho \\dot{g}^{h}(0)\\right)\\end{array}\\right.$ The representations of $v^{h}$ and\n",
      "$g^{\\boldsymbol{h}}$ are given by \\begin{align*} & v_{i}^{h}(x, t)=\\sum_{A \\in \\eta-\\eta_{\\phi_{i}}} N_{A}(x) d_{i A}(t) \\tag{7.2.17}\\\\ & g_{i}^{h}(x,\n",
      "t)=\\sum_{A \\in \\eta_{\\phi_{i}}} N_{A}(x) g_{i A}(t) \\tag{7.2.18} \\end{align*} These and the usual arguments lead to the matrix problem: Given $F:] 0,\n",
      "T\\left[\\rightarrow \\mathbb{R}^{n_{eq}}\\right.$, find $\\left.d:\\right] 0, T\\left[\\rightarrow \\mathbb{R}^{n_{eq}}\\right.$ such that \\begin{align*} M \\ddot{d}+K d\n",
      "& =F \\quad t \\in] 0, T[ \\tag{7.2.19}\\\\ d(0) & =d_{0} \\tag{7.2.20} \\end{align*} \\begin{equation*} \\dot{d}(0)=\\dot{d}_{0} \\tag{7.2.21} \\end{equation*} where\n",
      "\\begin{align*} & M=A_{e=1}^{n_{el}}\\left(m^{e}\\right) \\\\ & m^{e}=\\left[m_{p q}^{e}\\right] \\tag{7.2.23}\\\\ & m_{p q}^{e}=\\delta_{i j} \\int_{\\Omega^{e}} N_{a} \\rho\n",
      "N_{b} d \\Omega \\tag{7.2.24} \\end{align*} $\\left(\\right.$ Recall $p=n_{e d}(a-1)+i$ and $\\left.q=n_{e d}(b-1)+j\\right)$ \\begin{align*} & K=A_{e=1}^{n_{e\n",
      "l}}\\left(k^{e}\\right) \\tag{7.2.25}\\\\ & k^{e}=\\left[k_{p q}^{e}\\right] \\tag{7.2.26}\\\\ & k_{p q}^{e}=e_i^T \\int_{\\boldsymbol{\\Omega}^{e}} B_{a}^{T} D B_{b} d\n",
      "\\Omega e_{j} \\tag{7.2.27} \\end{align*} (M) \\begin{align*} & F(t) = F_{nodal}(t) + A_{e=1}^{n_{el}} (f^e(t)) \\tag{7.2.28} \\end{align*} \\begin{align*} &\n",
      "f^{e}=\\left\\{f_{p}^{e}\\right\\} \\tag{7.2.29}\\\\ & f_{p}^{e}=\\int_{\\Omega} N_{a} f_{i} d \\Omega+\\int_{\\Gamma_{k_{i}}^{e}} N_{a} h_{i} d \\Gamma-\\sum_{q=1}^{n_{e\n",
      "q}}\\left(k_{p q}^{e} g_{q}^{e}+m_{p q}^{e} \\ddot{g}_{q}^{e}\\right) \\tag{7.2.30}\\\\ & (\\text { no sum on } i) \\end{align*} \\begin{align*} & d_{0}=M^{-1}\n",
      "\\hat{A}_{q=1}^{n_{e l}}\\left(\\hat{d}^{e}\\right) \\tag{7.2.31}\\\\ & \\hat{d}^{e}=\\left\\{\\hat{d}_{p}^{e}\\right\\} \\tag{7.2.32}\\\\ & \\hat{d}_{p}^{e}=\\int_{\\Omega^{e}}\n",
      "N_{a} \\rho u_{0 i} d \\Omega-\\sum_{q=1}^{n_{eq}} m_{p q}^{e} g_{q}^{e}(0) \\tag{7.2.33}\\\\ & \\dot{d}_{0}=M^{-1} \\hat{A}_{e=1}^{n_{e}}\\left(\\hat{\\dot{d}}^{e}\\right)\n",
      "\\tag{7.2.34}\\\\ & \\hat{\\dot{d}}^{e}=\\left\\{\\hat{\\dot{d}}_{p}^{e}\\right\\} \\tag{7.2.35}\\\\ & \\hat{\\dot{d}}_{p}^{e}=\\int_{\\Omega^{e}} N_{a} \\rho \\dot{u}_{0 i} d\n",
      "\\Omega-\\sum^{n_{eq}} m_{p q}^{e} \\dot{g}_{q}^{e}(0) \\tag{7.2.36} \\end{align*} \\subsection*{Remarks} \\begin{enumerate} \\item The main addition to what we have\n",
      "encountered previously in the elastostatics formulation of Chapter 2 is the mass matrix, $M$. The reader should verify that $\\boldsymbol{M}$ is symmetric and\n",
      "positive-definite. Except for the Kronecker delta and different material parameter inside the integrand, the mass and capacity matrix [(7.1.21) through\n",
      "(7.1.23)] are identical. To appreciate the origin of the Kronecker delta, we will sketch part of the calculation that leads to the matrix formulation. If we\n",
      "restrict attention to the eth element, then \\end{enumerate} \\begin{align*} \\left(w^{h}, \\rho \\ddot{u}^{h}\\right)^{e} & =\\int_{\\Omega^{e}} w_{i}^{h} \\rho\n",
      "\\ddot{u}_{i}^{h} d \\Omega \\\\ & =\\delta_{i j} \\int_{\\Omega^{e}} w_{i}^{h} \\rho \\ddot{u}_{j}^{h} d \\Omega \\tag{7.2.37}\\\\ & =\\sum_{A, B} c_{i A} \\delta_{i j}\n",
      "\\int_{\\Omega^{e}} N_{A} \\rho N_{B} d \\Omega \\ddot{d}_{j B} \\quad \\text { (summation of } i \\text { and } j \\text { implied) } \\end{align*} \\begin{enumerate}\n",
      "\\setcounter{enumi}{1} \\item Equation (7.2.19) is a coupled system of second-order ordinary differential equations. Algorithms for solving equations of this type\n",
      "are described in Chapter 9. \\item Note that the element mass is involved in the adjustment of forces due to nonzero boundary accelerations (see (7.2.30)). \\item\n",
      "As mentioned in the previous section, we usually simplify the specification of initial conditions in practice. Nodal interpolates in this case take the form\n",
      "\\end{enumerate} \\begin{align*} & d_{0 p}=u_{0 i}\\left(x_{A}\\right) \\tag{7.2.38}\\\\ & \\dot{d}_{0 p}=\\dot{u}_{0 i}\\left(x_{A}\\right) \\tag{7.2.39} \\end{align*}\n",
      "where $P=\\mathrm{LM}(i, A)$. Recall LM is the array described in Chapter 2.\\\\ Exercise 2. Fill in the omitted details leading to the matrix formulation of\n",
      "elastodynamics. \\subsection*{Viscous Damping} In structural dynamics we often work with systems of the form \\begin{equation*} M \\ddot{d}+C \\dot{d}+K d=F\n",
      "\\tag{7.2.40} \\end{equation*} where $C$ is the viscous damping matrix. A particularly convenient form of $\\boldsymbol{C}$ is the Rayleigh damping matrix\n",
      "\\begin{equation*} C=a M+b K \\tag{7.2.41} \\end{equation*} where $a$ and $b$ are parameters. The two constituents of Rayleigh damping are seen to\\\\ be mass and\n",
      "stiffness proportional. We would like to enlarge our theoretical framework to include Rayleigh damping. The necessary modifications are as follows: Replace the\n",
      "equation of motion, (7.2.6), by \\begin{equation*} \\rho u_{i, tt}+a \\rho u_{i, t}=\\sigma_{ij, j}+f_{i} \\tag{7.2.42} \\end{equation*} where the generalized Hooke's\n",
      "law is modified to account for the stiffness proportional effect, namely, \\begin{equation*} \\sigma_{i j}=c_{i j k l}\\left(u_{(k, l)}+b \\dot{u}_{(k, l)}\\right)\n",
      "\\tag{7.2.43} \\end{equation*} In addition to the appearance of the $\\boldsymbol{C d}$-term in (7.2.40), the effect of the viscous damping matrix is also felt in\n",
      "modifying the forces due to prescribed displacement boundary conditions. Specifically, \\begin{equation*} f_{p}^{e}=\\text { right-hand side of }(7.2\n",
      ".30)-\\sum_{q=1}^{n_{eq}} c_{p q}^{e} \\dot{q}_{g}^{e} \\tag{7.2.44} \\end{equation*} where \\begin{equation*} c^{e}=a m^{e}+b k^{e} \\tag{7.2.45} \\end{equation*}\n",
      "Everything else remains the same. The parameters $a$ and $b$ may be selected to produce desired damping characteristics. \\subsection*{Example} In one dimension,\n",
      "the above formulation leads to a wave equation. This also may be viewed as a generalization of the one-dimensional model problem of Chapter 1. Various\n",
      "interpretations are possible. For example, the axial motion of an elastic rod of length $L$ is governed by the equation \\begin{equation*} \\left.\\rho u_{,\n",
      "tt}=\\sigma_{, x}+f \\quad \\text { on }\\right] 0, L[\\times] 0, T[ \\tag{7.2.46} \\end{equation*} where \\begin{equation*} \\sigma=E u_{, x} \\tag{7.2.47}\n",
      "\\end{equation*} and $E=E(x)$ is Young's modulus. Boundary and initial conditions may be specified in analogous fashion to Chapter 1, namely, \\begin{align*} u(L,\n",
      "t) & =g(t) & & t \\in] 0, T[ \\tag{7.2.48}\\\\ -E u_{, x}(0, t) & =h(t) & & t \\in] 0, T[ \\tag{7.2.49}\\\\ u(x, 0) & =u_{0}(x) & & x \\in] 0, L[ \\tag{7.2.50}\\\\\n",
      "\\dot{u}(x, 0) & =\\dot{u}_{0}(x) & & x \\in] 0, L[ \\tag{7.2.51} \\end{align*} The resulting element arrays are virtually identical to the ones encountered in the\n",
      "one-dimensional heat equation example at the end of Sec. 7.1, viz., \\begin{equation*} m_{a b}^{e}=\\int_{\\boldsymbol{\\Omega}^{\\boldsymbol{e}}} N_{a} \\rho N_{b} d\n",
      "\\boldsymbol{\\Omega} \\tag{7.2.52} \\end{equation*} \\begin{align*} & k_{a b}^{e}=\\int_{\\Omega^{e}} N_{a, x} E N_{b, x} d \\Omega \\tag{7.2.53}\\\\ &\n",
      "f_{a}^{e}=\\int_{\\Omega^{e}} N_{a} f d \\Omega-N_{a}(0) \\delta_{e l} h-\\sum_{b=1}^{n_{e n}}\\left(k_{a b}^{e} g_{b}^{e}+m_{a b}^{e} \\ddot{g}_{b}^{e}\\right)\n",
      "\\tag{7.2.54} \\end{align*} Note that in the present case, element equation and node numbers coincide (i.e., $p=a$ and $q=b$ ). Compare (7.1.37) through (7.1.39)\n",
      "with (7.2.52) through (7.2.54). Exercise 3. In previous chapters, the element stiffness matrix, (7.2.53), was evaluated (without $E$ ) for typical $C^{0}$ shape\n",
      "functions. Assuming $\\rho$ is constant, evaluate the element mass matrix, $m^{e}$, for the following shape functions:\\\\ i. Piecewise linears. $$ \\left[\\text {\n",
      "Answer: } m^{e}=\\frac{\\rho h}{6}\\left[\\begin{array}{ll} 2 & 1 \\\\ 1 & 2 \\end{array}\\right]\\right. $$ ii. Piecewise quadratics. $$ \\left[\\text { Answer: }\n",
      "m^{e}=\\frac{\\rho h}{30}\\left[\\begin{array}{rrr} 4 & 2 & -1 \\\\ 2 & 16 & 2 \\\\ -1 & 2 & 4 \\end{array}\\right]\\right] $$ Exercise 4. The initial/boundary-value\n",
      "problem for the deflection of an elastic membrane on a Winkler foundation is stated as follows: Given $\\ell: \\Omega \\times 10, T\\left[\\rightarrow \\mathbb{R}, q:\n",
      "\\Gamma_{g} \\times\\right] 0, T\\left[\\rightarrow \\mathbb{R}, h: \\Gamma_{k} \\times\\right] 0, T[\\rightarrow \\mathbb{R}$, $u_{0}: \\boldsymbol{\\Omega} \\rightarrow\n",
      "\\mathbb{R}$, and $\\dot{u}_{0}: \\boldsymbol{\\Omega} \\rightarrow \\mathbb{R}$, find $u: \\bar{\\Omega} \\times[0, T] \\rightarrow \\mathbb{R}$ such that $$\n",
      "\\begin{aligned} u_{, ii}-\\alpha u+f & =u_{, tt} & & \\text { on } \\Omega \\times] 0, T[ \\\\ u & =g & & \\left.x \\in \\Gamma_{q}, t \\in\\right] 0, T[ \\\\ u_{, n} & =h &\n",
      "& \\left.x \\in \\Gamma_{h, t} \\in\\right] 0, T[ \\\\ u & =u_{0} & & x \\in \\Omega, t=0 \\\\ u_{, t} & =\\dot{u}_{0} & & x \\in \\Omega, t=0 \\end{aligned} $$ where $u_{,\n",
      "n}=\\partial u / \\partial n$ is the derivative in the direction of the outward unit normal vector and $\\alpha>0$. Set up the following finite element\n",
      "paraphernalia:\\\\ a. A semidiscrete weak form of the problem in which the $h$-boundary condition is \"natural.\"\\\\ b. The corresponding Galerkin form of the\n",
      "problem.\\\\ c. The matrix ordinary-differential-equation problem. \\subsection*{Solution} a. Find $u\\in \\mathcal{S_t}$ such that for all $w \\in \\mathcal{V}$ $$\n",
      "(w, \\ddot{u})+a(w, u)=\\left(w, f\\right)+(w, h)_{\\Gamma} $$ Sec. 7.3 Eigenvalue Problems: Frequency Analysis and Buckling $$ \\begin{aligned} & \\left(w,\n",
      "u(0)-u_{0}\\right)=0 \\\\ & \\left(w, \\dot{u}(0)-\\dot{u}_{0}\\right)=0 \\end{aligned} $$ where $$ \\begin{aligned} (w, \\ddot{u}) & =\\int_{\\Omega} w \\ddot{u} d \\Omega\n",
      "\\\\ a(w, u) & =\\int_{\\Omega}\\left(w_{,i} u_{,i}+\\alpha w u\\right) d \\Omega \\\\ (w, f) & =\\int_{\\Omega} w f d \\Omega \\\\ (w, k)_{\\Gamma} & =\\int_{\\Gamma_{k}} w k d\n",
      "\\Gamma \\end{aligned} $$ b. Find $u^{h}=v^{h}+g^{h} \\in \\mathcal{S}^{h}, v^{h} \\in \\mathcal{V}^{h}$ such that for all $w^{h} \\in \\mathcal{V}^{h}$ (as usual) $$\n",
      "\\begin{aligned} & \\left(w^{h}, \\ddot{u}^{h}\\right)+a\\left(w^{h}, u^{h}\\right)=\\left(w^{h}, f\\right)+(w, h)_\\Gamma \\\\ & \\left(w^{h},\n",
      "\\ddot{v}^{h}\\right)+a\\left(w^{h}, v^{h}\\right)=\\left(w^{h}, f\\right)+\\left(w^{h}, h\\right)_{\\Gamma}-\\left(w^{h}, \\ddot{g}^{h}\\right)-a\\left(w^{h}, g^{h}\\right)\n",
      "\\end{aligned} $$ (Likewise for initial conditions.)\\\\ c. $M \\ddot{d}+K d=F ; d(0)=d_{0} ; \\dot{d}(0)=\\dot{d}_{0}$\\\\ where $$ \\begin{aligned} m_{a b}^{e} &\n",
      "=\\int_{\\boldsymbol{\\Omega}^{\\mathfrak{e}}} N_{a} N_{b} d \\boldsymbol{\\Omega} \\\\ k_{a b}^{e} & =\\int_{\\mathbf{\\Omega}^{e}}\\left(N_{a, i} N_{b, i}+\\alpha N_{a}\n",
      "N_{b}\\right) d \\Omega \\\\ f_a^e & = \\int_{\\Omega^e} N_a f d\\Omega + \\int_{\\Gamma_k^e} N_a h d\\Gamma - \\sum_{b=1}^{n_{el}} (m_{ab}^e \\ddot{g}_b^e + k_{ab}^e\n",
      "g_b^e) \\end{aligned} $$ (Usual assembly algorithm plus initial conditions.)\n",
      "\n",
      " 2: As usual, $\\boldsymbol{K}$ and $\\boldsymbol{F}$ may be decomposed into sums of elemental contributions. These results will be omitted here as the reader\n",
      "should now be familiar with the ideas involved (cf. Sec. 2.5). We will proceed directly to the definitions of $\\boldsymbol{k}^{e}$ and $f^{\\boldsymbol{c}}$ :\n",
      "\\begin{align*} & \\boldsymbol{k}^{e}=\\left[k_{p q}^{e}\\right], \\quad \\boldsymbol{f}^{e}=\\left\\{f_{p}^{e}\\right\\}, \\quad 1 \\leq p, q \\leq n_{ee}=n_{ed} n_{e n}\n",
      "\\tag{2.9.1}\\footnotemark\\\\ & k_{p q}^{e}=e_{i}^{T} \\int_{\\Omega e} B_{a}^{T} D B_{b} d \\Omega e_{j}, \\quad p=n_{e d}(a-1)+i, \\\\ & q=n_{e d}(b-1)+j \\tag{2.9.2}\\\\\n",
      "& \\left(n_{s d}=2\\right) \\quad B_{a}=\\left[\\begin{array}{cc} N_{a, 1} & 0 \\\\ 0 & N_{a, 2} \\\\ N_{a, 2} & N_{a, 1} \\end{array}\\right] \\tag{2.9.3}\\\\ & \\left(n_{s\n",
      "d}=3\\right) \\quad \\boldsymbol{B}_{a}=\\left[\\begin{array}{ccc} N_{a, 1} & 0 & 0 \\\\ 0 & N_{a, 2} & 0 \\\\ 0 & 0 & N_{a, 3} \\\\ 0 & N_{a, 3} & N_{a, 2} \\\\ N_{a, 3} &\n",
      "0 & N_{a, 1} \\\\ N_{a, 2} & N_{a, 1} & 0 \\end{array}\\right] \\tag{2.9.4} \\end{align*} \\footnotetext{$n_{\\text{ee}}$ stands for the number of element equations and\n",
      "$n_{\\text{ed}}$ is the number of element degrees of freedom (per node). It is possible in practice to have $n_{\\text {ed}} \\leq n_{\\text{dof}}$, although they\n",
      "are usually equal. } and \\[ f_{p}^{e}=\\int_{\\Omega^{e}} N_{a} \\ell_{i} d \\Omega+\\int_{\\Gamma_{h_{i}}^{e}} N_{a} h_{i} d \\Gamma-\\sum_{q=1}^{n_{e e}} k_{p q}\n",
      "g_{q}^{e}, \\quad \\begin{array}{r} \\Gamma_{h_{i}}^{e}=\\Gamma_{h_{i}} \\cap \\Gamma^{e} \\tag{2.9.5}\\\\ (\\text { no sum on } i) \\end{array} \\] where $g_{q}^{e}=g_{j\n",
      "b}^{e}=g_{j}\\left(x_{b}^{e}\\right)$ if $g_{j}$ is prescribed at node $b$, and equals zero otherwise. It is useful for programming purposes to define the nodal\n",
      "submatrix \\begin{equation*} \\underbrace{\\boldsymbol{k}_{ab}^{e}}_{n_{e d} \\times n_{e d}}=\\int_{\\boldsymbol{\\Omega}^{e}} B_{a}^{T} \\boldsymbol{D} B_{b} d\n",
      "\\boldsymbol{\\Omega} \\tag{2.9.6a} \\end{equation*} From (2.9.2) we see that \\begin{equation*} k_{p q}^{e}=e_{i}^{T} k_{a b}^{e} e_{j} \\tag{2.9.6b} \\end{equation*}\n",
      "This means, \"the $p q$-component of $\\boldsymbol{k}^{e}$ is the $i j$-component of the submatrix $\\boldsymbol{k}_{\\text {ab. }}^{e}$ \" By (2.9.1) through\n",
      "(2.9.4), we see that $k^{c}$ may be written as \\begin{equation*} k^{c}=\\int_{\\Omega^{e}} B^{T} D B d \\Omega \\tag{2.9.7} \\end{equation*} where \\begin{equation*}\n",
      "\\boldsymbol{B}=\\left[\\boldsymbol{B}_{1}, \\boldsymbol{B}_{2}, \\ldots, \\boldsymbol{B}_{n_{en}}\\right] \\tag{2.9.8} \\end{equation*} For example, in the case of a\n",
      "two-dimensional (i.e., $n_{s d}=n_{e d}=2$ ), four-noded element, $\\boldsymbol{k}^{\\boldsymbol{c}}$ takes the form \\[ \\underbrace{k^e}_{8 \\times 8} =\n",
      "\\left[\\begin{array}{cccc} k_{11}^e & k_{12}^e & k_{13}^e & k_{14}^e \\\\ k_{21}^e & k_{22}^e & k_{23}^e & k_{24}^e \\\\ k_{31}^e & k_{32}^e & k_{33}^e & k_{34}^e \\\\\n",
      "k_{41}^e & k_{42}^e & k_{43}^e & k_{44}^e \\end{array}\\right] \\] In practice, the submatrices above the dashed line are computed and those below, if required,\n",
      "are determined by symmetry. The global arrays $\\boldsymbol{K}$ and $\\boldsymbol{F}$ may be formed from the element arrays $\\boldsymbol{k}^{\\boldsymbol{e}}$ and\n",
      "$\\boldsymbol{f}^{\\boldsymbol{e}}$, respectively, by way of an assembly algorithm as outlined in Sec. 1.14. \\subsection*{Exercise 1.} Let \\begin{align*} &\n",
      "\\underset{n_{ee} \\times 1}{d^{e}}=\\left\\{d_{a}^{e}\\right\\}=\\left\\{\\begin{array}{c} d_{1}^e \\\\ d_{2}^{e} \\\\ \\vdots \\\\ d^{e}_{n_{en}} \\end{array}\\right\\}\n",
      "\\tag{2.9.10}\\\\ & \\left(n_{\\text{ed }}=2\\right) \\quad d_{a}^{e}=\\left\\{\\begin{array}{l} d_{1a}^e \\\\ d_{2a}^{e} \\end{array}\\right\\} \\tag{2.9.11}\\\\ & \\left(n_{e\n",
      "d}=3\\right) \\quad d_{a}^{e}=\\left\\{\\begin{array}{l} d_{1a}^e \\\\ d_{2a}^e \\\\ d_{3a}^e \\end{array}\\right\\} \\tag{2.9.12} \\end{align*} where \\begin{equation*} d_{i\n",
      "a}^{e}=u_{i}^{h}\\left(x_{a}^{e}\\right) \\tag{2.9.13} \\end{equation*} $d^{e}$ is called the element displacement vector. Show that the stress vector (see Exercise\n",
      "4, Sec. 2.7.) at point $x \\in \\Omega^{\\boldsymbol{c}}$ can be calculated from the formula \\begin{equation*} \\sigma(x)=D(x) B(x) d^{e}=D(x) \\sum_{a=1}^{n_{e n}}\n",
      "B_{a}(x) d_{a}^{e} \\tag{2.9.14} \\end{equation*}\n",
      "\n",
      " 3: A disadvantage of reduction techniques such as the Irons-Guyan procedure is that there is no guarantee that the eigenvalues and eigenvectors of the reduced\n",
      "problem,\\\\ namely, $\\lambda_l^*$ and $R \\psi_l^*$, will be good approximations of those of the original problem, $\\lambda_{l}$ and $\\psi_{l}$, respectively.\n",
      "Consequently, methods have been developed in which a reduced problem is used along with an iterative strategy to obtain exactly the lower modes of the\n",
      "generalized eigenproblem. This is the underlying idea of the subspace iteration, or block power, method, which is widely used for large-scale finite element\n",
      "calculations. Roughly speaking, the procedure is as follows: Load patterns are selected and trial vectors are calculated. The trial vectors are used to form a\n",
      "reduced problem, which is solved. New load patterns are calculated from the \"inertial\" forces engendered by the eigenvectors of the reduced problem, namely,\n",
      "\\begin{equation*} \\underbrace{\\boldsymbol{P}}_{n_{e q} \\times n_{lp}}= \\boldsymbol{MR}\\left[\\psi_{1}^{*}, \\psi_{2}^{*}, \\ldots, \\psi_{n_{lp}}^{*}\\right]\n",
      "\\tag{10.5.1} \\end{equation*} With these load patterns the process is repeated until convergence is achieved. The calculations are summarized in the flowchart\n",
      "contained in Table 10.5.1. Extensive discussion and further details are presented in [8]. \\subsection*{TABLE 10.5.1 Subspace lieration Procedure} I.\n",
      "Initialization \\begin{enumerate} \\item Form $K$ and $M$. \\item Factorize $\\boldsymbol{K}=\\boldsymbol{U}^{\\boldsymbol{T}} \\boldsymbol{D} \\boldsymbol{U}$. \\item\n",
      "Specify initial load patterns, $P$.\\\\ II. Iteration \\item Solve for trial vectors: \\end{enumerate} $$ \\left(\\boldsymbol{U}^{\\boldsymbol{T}} \\boldsymbol{D}\n",
      "\\boldsymbol{U}\\right) \\boldsymbol{R}=\\boldsymbol{P} $$ \\begin{enumerate} \\setcounter{enumi}{1} \\item Compute reduced matrices: \\end{enumerate} $$\n",
      "\\begin{aligned} K^{*} & =R^{T} \\boldsymbol{K R}=R^{T} P \\\\ M^{*} & =R^{T} M R \\end{aligned} $$ \\begin{enumerate} \\setcounter{enumi}{2} \\item Solve the reduced\n",
      "eigenproblem: \\end{enumerate} $$ \\left(K^{*}-\\lambda_{k}^{*} M^{*}\\right) \\psi_{k}^{*}=0, \\quad k=1,2, \\ldots, n_{lp} $$ \\begin{enumerate} \\setcounter{enumi}{3}\n",
      "\\item Calculate approximations to the eigenvectors of the original system: \\end{enumerate} $$ R\\left[\\psi_{1}^{*}, \\psi_{2}^{*}, \\ldots,\n",
      "\\psi_{n_{lp}}^{*}\\right] $$ \\begin{enumerate} \\setcounter{enumi}{4} \\item Perform convergence checks. If the desired eigenvalues have converged, stop. Otherwise\n",
      "continue. \\item Calculate improved load patterns: \\end{enumerate} $$ P=M R\\left[\\psi_{1}^{*}, \\psi_{2}^{*}, \\ldots, \\psi_{n_{lp}}^{*}\\right] $$\n",
      "\\begin{enumerate} \\setcounter{enumi}{6} \\item Go to Step II-1. \\end{enumerate} \\subsection*{Remarks} \\begin{enumerate} \\item It is recommended from practical\n",
      "experience [8] that:\\\\ i. The number of load patterns employed should be calculated from\\\\ $n_{l p}=\\min \\left\\{2 n_{\\text {modes }}, n_{\\text {modes\n",
      "}}+8\\right\\}$, where $n_{\\text {modes }}$ is the number of eigenpairs desired.\\\\ ii. In the first load pattern (i.e., first column of $P$ ) a 1 should be placed\n",
      "in the entry corresponding to the minimum value of $K_{p p} / M_{p p}$, and 0 in the remaining entries. Likewise, a 1 should be placed in the entry of the\n",
      "second column corresponding to the next smallest value of $K_{p p} / M_{p p}$, and so forth. \\item Wilson [9] recommends that one load pattern be generated from\n",
      "random numbers in the interval $[0,1]$. \\item The convergence condition may be specified in terms of consecutive iterates: \\end{enumerate} $$\n",
      "\\frac{\\left(\\lambda_{k}^{*}\\right)_{l+1}-\\left(\\lambda_{k}^{*}\\right)_{l}}{\\left(\\lambda_{k}^{*}\\right)_{l}} \\leq \\epsilon, \\quad k=1,2, \\ldots, n_{\\text {modes\n",
      "}} $$ where $I$ is the iteration number and $\\epsilon$ is a preassigned error tolerance.\\\\ 4. Solution of the generalized eigenproblem in the subspace iteration\n",
      "algorithm (Step II-3 in Table 10.5.1) is efficiently carried out by way of the generalized Jacobi method [8]. The reason for this is that after a number of\n",
      "iteration steps, the generalized eigenproblem possesses diagonally dominant matrices for which the generalized Jacobi method proves very effective.\n",
      "\\subsection*{10.5.1 Spectrum Slicing} The convergence of a procedure such as subspace iteration does not necessarily guarantee that the first $n_{\\text {modes\n",
      "}}$ eigenpairs of the original system have been found. An eigenvalue can be missed if the original trial vectors are orthogonal to the corresponding\n",
      "eigenvector. To ascertain whether or not this has occurred, a spectrum slicing may be performed.\\footnote[3]{Spectrum slicing is sometimes referred to as a\n",
      "Sturm sequence check [8]. } The steps involved are as follows: Perform a Crout factorization of the matrix $K-\\alpha M$, where $\\alpha=(1+\\delta)\n",
      "\\lambda_{n_{\\text {modes }}}$ and $\\delta$ is a small positive number such that $(1+\\delta) \\lambda_{n_{\\text {modes }}}<\\lambda_{n_{\\text {modes }+1}}$. Let\n",
      "$D_{\\alpha}$ denote the diagonal matrix of pivots obtained. It follows from Sylvester's inertia theorem that the number of eigenvalues smaller than $\\alpha$\n",
      "will equal the number of negative entries in $D_{\\alpha}$. If this number, say $n_{\\alpha}$, is greater than $n_{\\text {modes }}$, then $n_{\\alpha}-n_{\\text\n",
      "{modes }}$ eigenvalues smaller than $\\alpha$ were missed in the calculation. If this is the case, a revised set of load patterns must be employed and the\n",
      "eigensolution repeated. If $n_{\\alpha}=n_{\\text {modes }}$, then a degree of confidence in the solution is attained. \\subsection*{Remark} Spectrum slicing can\n",
      "be used to determine the number of eigenvalues in an interval $] \\alpha, \\beta\\left[\\right.$, where $\\beta>\\alpha$. Factorize $K-\\alpha M$ and $K-\\beta M$. If\n",
      "$D_{\\alpha}$ and $D_{\\beta}$ are the corresponding pivots and $n_{\\alpha}$ and $n_{\\beta}$ are the number of negative entries of $D_{\\alpha}$ and $D_{\\beta}$,\n",
      "respectively, then $n_{\\beta}-n_{\\alpha}$ is the number of eigenvalues in $] \\alpha, \\beta[$. \\subsection*{10.6.2 Inverse Iteration} When the number of load\n",
      "patterns used in the subspace iteration procedure is one, the process is called inverse iteration. In this case convergence to the lowest eigenvalue occurs as\n",
      "long as the initial trial vector is not orthogonal to the corresponding eigenvector. By reversing the roles of $\\boldsymbol{K}$ and $M$, convergence to the\n",
      "largest eigenvalue, $\\lambda_{n e q}$, can be achieved. This may be seen from: $$ 0=(K-\\lambda M) \\psi=\\left(M-\\lambda^{-1} K\\right) \\psi $$ Note that when\n",
      "working with the latter form, subspace iteration requires $M$ to be nonsingular. \\textbf{Exercise 1.} Consider the following eigenvalue problem: $$ (K-\\lambda\n",
      "M) \\Psi=0, \\quad \\lambda=\\omega^{2} $$ where $$ \\begin{aligned} M & =\\left[\\begin{array}{cc} m_{1} & 0 \\\\ 0 & m_{2} \\end{array}\\right] \\\\ K &\n",
      "=\\left[\\begin{array}{cc} \\left(k_{1}+k_{2}\\right) & -k_{2} \\\\ -k_{2} & k_{2} \\end{array}\\right] \\\\ \\psi & =\\left\\{\\begin{array}{l} \\psi_{1} \\\\ \\psi_{2}\n",
      "\\end{array}\\right\\} \\end{aligned} $$ Assume $k_{1}=k_{2}=1, m_{1}=3, m_{2}=2$.\\\\ a. Calculate the frequencies (i.e., $\\omega_{1}, \\omega_{2}$ ) and mode shapes\n",
      "(i.e., $\\psi_{1}, \\psi_{2}$ ).\\\\ b. Assuming that the fundamental mode load pattern is given approximately by $$ P=\\left\\{\\begin{array}{c}\n",
      "\\frac{m_{1}}{\\left(k_{1}+k_{2}\\right)} \\\\ \\frac{m_{2}}{k_{2}} \\end{array}\\right\\} $$ use the discrete Rayleigh-Ritz reduction procedure to obtain an estimate of\n",
      "the fundamental frequency and mode shape.\\\\ c. Use the Irons-Guyan procedure to reduce the problem to one degree of freedom. Pick the degree of freedom to be\n",
      "retained according to the criterion presented in Sec. 10.4. Determine the approximate fundamental frequency and mode shape.\\\\ d. Use the subspace iteration\n",
      "procedure to calculate the fundamental frequency and mode shape. Initialize the computations with the load pattern $$ P=\\left\\{\\begin{array}{l} 0 \\\\ 1\n",
      "\\end{array}\\right\\} $$ Employ two iterations. \\subsection*{Solution} a. $$ \\begin{aligned} M & =\\left[\\begin{array}{ll} 3 & 0 \\\\ 0 & 2 \\end{array}\\right] \\quad\n",
      "K=\\left[\\begin{array}{rr} 2 & -1 \\\\ -1 & 1 \\end{array}\\right] \\\\ 0 & =\\operatorname{det}\\left[\\begin{array}{cc} 2-3 \\lambda & -1 \\\\ -1 & 1-2 \\lambda\n",
      "\\end{array}\\right]=6 \\lambda^{2}-7 \\lambda+1 \\\\ \\lambda_{1,2} & =\\frac{1}{6}, 1 \\end{aligned} $$ $$ \\begin{aligned} & \\omega_{1,2}=\\frac{1}{\\sqrt{6}},\n",
      "1=0.40825,1 \\\\ & \\psi_{1}=\\left\\{\\begin{array}{l} \\frac{2}{3} \\\\ 1 \\end{array}\\right\\} \\quad \\psi_{2}=\\left\\{\\begin{array}{r} 1 \\\\ -1 \\end{array}\\right\\}\n",
      "\\end{aligned} $$ b. $$ P=\\left\\{\\begin{array}{l} \\frac{3}{2} \\\\ 2 \\end{array}\\right\\} $$ $$ \\begin{aligned} \\boldsymbol{KR} & =\\boldsymbol{P} \\\\ \\boldsymbol{R}\n",
      "& =\\left\\{\\begin{array}{c} \\frac{7}{2} \\\\ \\frac{11}{2} \\end{array}\\right\\} \\quad \\text { (the } \\frac{1}{2} \\text { factors may be neglected) } \\\\\n",
      "\\boldsymbol{K}^{*} & =\\boldsymbol{R}^{T} \\boldsymbol{K} \\boldsymbol{R}=\\left\\langle\\begin{array}{ll} 7 & 11 \\end{array}\\right\\rangle\\left[\\begin{array}{rr} 2 &\n",
      "-1 \\\\ -1 & 1 \\end{array}\\right]\\left\\{\\begin{array}{c} 7 \\\\ 11 \\end{array}\\right\\}=65 \\\\ \\textbf{M}^{*} & =\\boldsymbol{R}^{T} M\n",
      "\\boldsymbol{R}=\\left\\langle\\begin{array}{ll} 7 & 11 \\end{array}\\right\\rangle\\left[\\begin{array}{ll} 3 & 0 \\\\ 0 & 2 \\end{array}\\right]\\left\\{\\begin{array}{l} 7\n",
      "\\\\ 11 \\end{array}\\right\\}=389 \\end{aligned} $$ $$ \\left(K^{*}-\\lambda^{*} M^{*}\\right) \\psi^{*}=0 \\Rightarrow \\lambda^{*}=\\frac{65}{389}, \\quad \\psi^{*}=1 $$ $$\n",
      "\\psi_{1} \\cong R \\psi_{1}^{*}=\\frac{1}{11}\\left\\{\\begin{array}{c} 7 \\\\ 11 \\end{array}\\right\\}=\\left\\{\\begin{array}{c} 0.64 \\\\ 1 \\end{array}\\right\\} ; \\quad\n",
      "\\omega^{*}=\\left(\\frac{65}{389}\\right)^{1 / 2}=0.4087 $$ c. \\[ \\left. \\begin{aligned} \\frac{K_{11}}{M_{11}} &= \\frac{2}{3} \\\\ \\frac{K_{22}}{M_{22}} &=\n",
      "\\frac{1}{2} \\end{aligned} \\right\\} \\quad \\Rightarrow \\text{ retain degree of freedom number 2} \\] Reorder equations into the standard partitioned form. $$\n",
      "\\begin{aligned} K & =\\left[\\begin{array}{rr} 1 & -1 \\\\ -1 & 2 \\end{array}\\right] \\quad M=\\left[\\begin{array}{ll} 2 & 0 \\\\ 0 & 3 \\end{array}\\right] \\\\ R &\n",
      "=\\left\\{\\begin{array}{c} 1 \\\\ -K_{22}^{-1} K_{21} \\end{array}\\right\\}=\\left\\{\\begin{array}{l} 1 \\\\ \\frac{1}{2} \\end{array}\\right\\} \\\\ K^{*} & =R^{T} K\n",
      "R=\\frac{1}{2} \\\\ M^{*} & =R^{T} M R=\\frac{11}{4} \\end{aligned} $$ $$ \\lambda^{*}=\\frac{2}{11}, \\quad \\omega^{*}=\\left(\\frac{2}{11}\\right)^{1 / 2}=0.4264 \\quad\n",
      "\\psi_{1}^{*}=1 $$ $$ \\psi_{1} \\cong R \\psi_{1}^{*}=\\left\\{\\begin{array}{l} 1 \\\\ \\frac{1}{2} \\end{array}\\right\\}, \\quad \\text { (reorder): } $$ $$\n",
      "\\Psi_{1}=\\left\\{\\begin{array}{l} \\frac{1}{2} \\\\ 1 \\end{array}\\right\\} $$ d. $P=\\left\\{\\begin{array}{l}0 \\\\ 1\\end{array}\\right\\} ; \\quad \\boldsymbol{K}\n",
      "\\boldsymbol{R}=P ; \\quad \\boldsymbol{R}=\\left\\{\\begin{array}{l}1 \\\\ 2\\end{array}\\right\\}$ $\\left.\\begin{array}{l}K^{*}=2 ; \\quad M^{*}=11 ; \\quad\n",
      "\\lambda^{*}=\\frac{2}{11} \\quad \\text { (same as (c)) } \\\\ \\omega^{*}=0.4264 \\quad \\psi_{1} \\cong\\left\\{\\begin{array}{l}\\frac{1}{2} \\\\\n",
      "1\\end{array}\\right\\}\\end{array}\\right\\}$ iteration number 1 \\\\ $\\boldsymbol{P}=\\boldsymbol{M} \\psi_{1}=\\left\\{\\begin{array}{l}\\frac{3}{2} \\\\\n",
      "2\\end{array}\\right\\} \\quad$ (same as (b))\\\\ Therefore $$ \\omega *=0.4087 \\quad \\psi_{1} \\cong\\left\\{\\begin{array}{c} 0.64 \\\\ 1 \\end{array}\\right\\} $$\n",
      "\n",
      " 4: In practice one often encounters eigenvalue problems which can be written in the following partitioned form: \\[ \\left(\\left[\\begin{array}{ll} K_{11} &\n",
      "K_{12} \\tag{10.2.1}\\\\ K_{21} & K_{22} \\end{array}\\right]-\\lambda\\left[\\begin{array}{cc} M_{11} & 0 \\\\ 0 & 0 \\end{array}\\right]\\right)\\left\\{\\begin{array}{l}\n",
      "\\Psi_{1} \\\\ \\Psi_{2} \\end{array}\\right\\}=0 \\] where $M_{11}$ is symmetric and positive-definite. That is, many degrees of freedom are \"massless.\" Problems of\n",
      "this type arise naturally when a relatively light structure is used to support heavy nonstructural masses which can be \"lumped\" at a few degrees of freedom. In\n",
      "such situations the structural mass is often insignificant and may be neglected, resulting in a system like (10.2.1). As it stands, (10.2.1) is ill-posed in the\n",
      "sense that the zero-diagonal masses give rise to infinite eigenvalues. The mass matrix can be \"regularized\" by the addition of small positive nonzero diagonal\n",
      "masses, in which case we return to the format of the generalized eigenvalue problem originally considered, or, alternatively, the zero-mass degrees of freedom\n",
      "can be eliminated by static condensation. To arrive at the statically condensed form, we expand (10.2.1): \\[ \\begin{array}{r} K_{11} \\Psi_{1}+K_{12}\n",
      "\\Psi_{2}-\\lambda M_{11} \\Psi_{1}=0 \\\\ K_{21} \\Psi_{1}+K_{22} \\Psi_{2}=0 \\tag{10.2.3} \\end{array} \\] The next step is to solve (10.2.3) for $\\Psi_{2}$ and then\n",
      "substitute in (10.2.2), which results in \\begin{equation*} \\left(\\boldsymbol{K}_{11}^{*}-\\lambda M_{11}\\right) \\Psi_{1}=0 \\tag{10.2.4} \\end{equation*} where\n",
      "\\begin{equation*} \\boldsymbol{K}_{11}^{*}=\\boldsymbol{K}_{11}-K_{12} K_{22}^{-1} K_{21} \\quad \\text { (statically condensed stiffness) } \\tag{10.2.5}\n",
      "\\end{equation*} The advantage of transforming to statically condensed form is that the problem size is reduced. However, $K_{11}^{*}$ tends to be full. Thus,\n",
      "unless the size of the nonzero-mass matrix is rather small, the reduction to statically condensed form may be uneconomical because the profile structure of\n",
      "$\\boldsymbol{K}$ is lost. Note that to calculate the statically condensed stiffness (10.2.5) efficiently, $\\boldsymbol{K}_{22}$ is never actually inverted. The\n",
      "following steps may be used in practice: \\begin{equation*} K_{22}=\\boldsymbol{U}^{T} D \\boldsymbol{U} \\quad \\text { (Crout factorization) } \\tag{10.2.6}\n",
      "\\end{equation*} \\begin{align*} \\boldsymbol{U} D^{1 / 2} \\boldsymbol{Z} & =\\boldsymbol{K}_{21} \\quad \\text { (solve for } \\boldsymbol{Z} \\text { ) }\n",
      "\\tag{10.2.7}\\\\ \\boldsymbol{K}_{12} \\boldsymbol{K}_{22}^{-1} \\boldsymbol{K}_{21} & =\\boldsymbol{Z}^{T} \\boldsymbol{Z} \\tag{10.2.8} \\end{align*} Equation (10.2.7)\n",
      "amounts to solution of an equation system with upper triangular coefficient array and multiple right-hand sides (i.e., the columns of $\\boldsymbol{K}_{21}$ ).\n",
      "For further computational considerations regarding static condensation, see [3].\n",
      "\n",
      " 5: \\subsection*{1. Classical Linear Elastostatics} $(\\boldsymbol{S})$ $$ \\begin{aligned} \\sigma_{i j, j}+f_{i} & =0 & & \\text { on } \\Omega \\\\ u_{i} & =g_{i} &\n",
      "& \\text { on } \\Gamma_{g_{i}} \\\\ \\sigma_{i j} n_{j} & =h_{i} & & \\text { on } \\Gamma_{h_{i}} \\end{aligned} $$ where $\\sigma_{i j}=c_{ijkl} \\epsilon_{k l}=c_{i j\n",
      "k l} u_{(k, l)}$\\\\ $(W)^{19}$Find $u \\in \\delta$, such that $\\forall w \\in \\mathcal{V}$ $$ a(w, u)=(w, \\ell)+(w, k)_{\\Gamma} $$ where $$ \\begin{aligned} a(w, u)\n",
      "& =\\int_{\\Omega} w_{(i, j)} c_{i j k l} u_{(k, l)} d \\Omega \\\\ (w, \\ell) & =\\int_{\\Omega} w_{i} \\ell_{i} d \\Omega \\\\ (w, k)_{\\Gamma} &\n",
      "=\\sum_{i=1}^{n_{sd}}\\left(\\int_{\\Gamma_{h_{i}}} w_{i} h_{i} d \\Gamma\\right) \\end{aligned} $$ (G) Find $v^{h} \\in \\mathcal{V}^{h}$, such that $\\forall\n",
      "\\boldsymbol{w}^{h} \\in \\mathcal{V}^{h}$ $$ a\\left(w^{h}, v^{h}\\right)=\\left(w^{h}, \\ell \\right)+\\left(w^{h}, k\\right)_{\\Gamma}-a\\left(w^{h}, g^{h}\\right) $$ ${\n",
      "}^{19}$ The notation $\\forall$ means \"for all.\"\\\\ (M) $K d=F$, where $K=A_{e=1}^{n_{el}}\\left(k^{e}\\right), F=F_{\\text {nodal\n",
      "}}+A_{e=1}^{n_{el}}\\left(f^{e}\\right)^{20}$ $$ \\begin{aligned} k_{p q}^{e} & =e_{i}^{T} k_{a b}^{e} e_{j}, \\quad k_{a b}^{e}=\\int_{\\Omega^{e}} B_{a}^{T} D B_{b}\n",
      "d \\Omega \\\\ f_{p}^{e} & =\\int_{\\Omega^{e}} N_{a} \\ell_{i} d \\Omega+\\int_{\\Gamma^e_{h_{i}}} N_{a} h_{i} d \\Gamma-\\sum_{q=1}^{n_{el}} k_{p q}^{e} g_{q}^{e} \\quad\n",
      "\\text { (no sum on } i \\text { ) } \\\\ p & =n_{e d}(a-1)+i \\\\ q & =n_{e d}(b-1)+j \\end{aligned} $$ Stress at a point: $\\sigma(x)=D(x) \\sum_{a=1}^{n_{e n}}\n",
      "B_{a}(x) d_{a}^{e}$ \\subsection*{2. Classical Linear Heat Conduction} (S) $$ \\begin{aligned} q_{i, i} & =\\ell & & \\text { in } \\Omega \\\\ u & =g & & \\text { on }\n",
      "\\Gamma_{g} \\\\ -q_{i} n_{i} & =h & & \\text { on } \\Gamma_{h} \\end{aligned} $$ where $q_{i}=-\\kappa_{i j} u_{, j}$\\\\ (W) Find $u \\in \\mathcal{\\delta}$, such that\n",
      "$\\forall w \\in \\mathcal{V}$ $$ a(w, u)=(w, \\ell)+(w, h)_\\Gamma $$ where $$ \\begin{aligned} a(w, u) & =\\int_{\\Omega} w_{, i} \\kappa_{i j} u_{, j} d \\Omega \\\\ (w,\n",
      "\\ell) & =\\int_{\\Omega} w \\ell d \\Omega \\\\ (w, h)_{\\Gamma} & =\\int_{\\Gamma_{h}} w h d \\Gamma \\end{aligned} $$ (G) Find $v^{h} \\in \\delta^{h}$, such that $\\forall\n",
      "w^{h} \\in \\mathcal{V}^{h}$ $$ a\\left(w^{h}, v^{h}\\right)=\\left(w^{h},\\ell \\right)+\\left(w^{h}, h\\right)_{\\Gamma}-a\\left(w^{h}, g^{h}\\right) $$\n",
      "\\footnotetext[20]{In defining $\\boldsymbol{P}$ we have added to the element contributions the term $\\boldsymbol{F}_{\\text {nodal}}$, which is a vector of nodal\n",
      "applied forces. The reason for this is that it is often easier in practice to directly input concentrated forces at nodes rather than go through the element-by-\n",
      "element form and assemble procedure. The expression for $F$ then emphasizes that both modes of constructing $F$ are to be accommodated in the computer\n",
      "implementation of problems of this type. } (M) $\\quad K d=\\boldsymbol{F}$, where $K=\\boldsymbol{A}_{e=1}^{n_{e l}}\\left(k^{e}\\right), \\quad\n",
      "\\boldsymbol{F}=\\boldsymbol{F}_{\\text {nodal }}+A_{e=1}^{n_{e l}}\\left(f^{e}\\right)^{20}$\\\\ \\[ \\begin{aligned} k_{a b}^{e} & =\\int_{\\boldsymbol{\\Omega}^{e}}\n",
      "B_{a}^{T} D B_{b} d \\Omega \\\\ f_{a}^{e} & =\\int_{\\Omega^{e}} N_{a} \\ell d \\Omega+\\int_{\\Gamma_{h}^{e}} N_{a} h d \\Gamma-\\sum_{b=1}^{n_{el}} k_{a b}^{e}\n",
      "g_{b}^{e} \\end{aligned} \\] Heat flux vector at a point: $q(x)=-D(x) \\sum_{a=1}^{n_{e n}} B_{a}(x) d_{a}^{e}$ \\subsection*{3. One-Dimensional Model Problem} \\[\n",
      "\\begin{array}{rlr} u_{, x x}+\\ell=0 & & \\text { on } \\Omega=] 0,1[ \\tag{S}\\\\ u(1)=g & & \\left(\\Gamma_{g}=\\{1\\}\\right) \\\\ -u_{, x}(0)=h & &\n",
      "\\left(\\Gamma_{h}=\\{0\\}\\right) \\end{array} \\] (W) Find $u \\in \\delta$, such that $\\forall w \\in \\mathcal{V}$ $$ a(w, u)=(w, \\ell)+w(0) h $$ where $$\n",
      "\\begin{aligned} a(w, u) & =\\int_{0}^{1} w_{, x} u_{, x} d x \\\\ (w, \\ell) & =\\int_{0}^{1} w \\ell d x \\end{aligned} $$ (G) Find $v^{h} \\in \\mathcal{V}^{h}$, such\n",
      "that $\\forall w^{h} \\in \\mathcal{V}^{h}$ $$ a\\left(w^{h}, v^{h}\\right)=\\left(w^{h}, \\ell\\right)+w^{h}(0) h-a\\left(w^{h}, g^{h}\\right) $$ (M) $\\quad K\n",
      "d=\\boldsymbol{F}$, where $K=\\boldsymbol{A}_{e=1}^{n_{e l}}\\left(k^{e}\\right), \\quad \\boldsymbol{F}=\\boldsymbol{F}_{\\text {nodal }}+A_{e=1}^{n_{e\n",
      "l}}\\left(f^{e}\\right)^{20}$\\\\ $$ \\begin{aligned} & k_{a b}^{e}=\\int_{\\Omega^{e}} N_{a, x} N_{b, x} d x \\\\ & f_{a}^{e}=\\int_{\\mathbf{\\Omega}^{e}} N_{a} \\ell d x+\n",
      "\\begin{cases}k \\delta_{a 1} & e=1 \\\\ 0 & e=2, \\ldots, n_{e l}-1 \\\\ -g k_{2 a}^{e} & e=n_{el}\\end{cases} \\end{aligned} $$\n",
      "\n",
      " 6: To develop the element point of view further, let us assume that our model consists of $n_{e l}$ elements, numbered as shown in Figure 1.13.1. Clearly $n_{e\n",
      "l}=n$ for this case. Let us take $e$ to be the variable index for the elements; thus $1 \\leq e \\leq n_{e l}$.\\\\ \\includegraphics[max width=\\textwidth,\n",
      "center]{2024_10_04_fba7dc36d090c246379ag-40} Figure 1.13.1\\\\ Now recall the definitions of the (global) stiffness matrix and force vector\\\\ \\\\ \\[ K =\n",
      "\\underbrace{\\left[ K_{AB} \\right]}_{n \\times n}, \\quad F = \\underbrace{\\left\\{ F_A \\right\\}}_{n \\times 1} \\tag{1.13.1} \\] where \\begin{gather*} K_{A\n",
      "B}=a\\left(N_{A}, N_{B}\\right)=\\int_{0}^{1} N_{A, x} N_{B, x} d x \\tag{1.13.2}\\\\ F_{A}=\\left(N_{A}, f\\right)+\\delta_{A 1} h-a\\left(N_{A}, N_{n+1}\\right) g \\\\\n",
      "=\\int_{0}^{1} N_{A} f d x+\\delta_{A 1} h-\\int_{0}^{1} N_{A, x} N_{n+1, x} d x g \\tag{1.13.3} \\end{gather*} ( $\\operatorname{In}(1.13 .3)$ we have assumed\n",
      "$N_{A}\\left(x_{1}\\right)=\\delta_{A 1}$, as for the piecewise linear finite element space.) The integrals over $[0,1]$ may be written as sums of integrals over\n",
      "the element domains. Thus \\[ \\begin{array}{ll} \\boldsymbol{K}=\\sum_{e=1}^{n_{e l}} \\boldsymbol{K}^{e}, & \\boldsymbol{K}^{e}=\\left[K_{A B}^{e}\\right] \\\\\n",
      "\\boldsymbol{F}=\\sum_{e=1}^{n_{e l}} \\boldsymbol{F}^{e}, & \\boldsymbol{F}^{e}=\\left\\{F_{\\hat{A}}^{e}\\right\\} \\tag{1.13.5} \\end{array} \\] where \\begin{align*}\n",
      "K_{A B}^{e} & =a\\left(N_{A}, N_{B}\\right)^{e}=\\int_{\\mathbf{Q}^{e}} N_{A, x} N_{B, x} d x \\tag{1.13.6}\\\\ F_{A}^{e} & =\\left(N_{A}, f\\right)^{e}+\\delta_{e 1}\n",
      "\\delta_{A 1} h-a\\left(N_{A}, N_{n+1}\\right)^{e} g \\\\ & =\\int_{\\Omega^{e}} N_{A} f d x+\\delta_{e 1} \\delta_{A 1} h-\\int_{\\Omega^{e}} N_{A, x} N_{n+1, x} d x g\n",
      "\\tag{1.13.7} \\end{align*} and $\\Omega^{e}=\\left[x_{1}^{e}, x_{2}^{e}\\right]$, the domain of the eth element.\\\\ The important observation to make is that\n",
      "$\\boldsymbol{K}$ and $\\boldsymbol{F}$ can be constructed by summing the contributions of elemental matrices and vectors, respectively. In the literature, this\n",
      "procedure is sometimes called the direct stiffmess method [10]. By the definitions of the $N_{A}$ 's, we have that \\begin{equation*} K_{A B}^{e}=0, \\quad \\text\n",
      "{ if } A \\neq e \\text { or } e+1 \\text { or } B \\neq e \\text { or } e+1 \\tag{1.13.8} \\end{equation*} and \\begin{equation*} F_{A}^{e}=0, \\quad \\text { if } A\n",
      "\\neq e \\text { or } e+1 \\tag{1.13.9} \\end{equation*} The situation for a typical element, $e$, is shown in Fig. 1.13.2. In practice we would not, of course, add\n",
      "in the zeros but merely add in the nonzero terms to the appropriate locations. For this purpose it is useful to define the eth element stiffiness matrix $k^{e}$\n",
      "and element force vector $f^{e}$ as follows: \\begin{align*} & k^{e}=\\underbrace{\\left[k_{a b}^{e}\\right]}_{2 \\times 2}, \\quad\n",
      "f^{e}=\\underbrace{\\left\\{f_{a}^{e}\\right\\}}_{2 \\times 1} \\tag{1.13.10}\\\\ & k_{a b}^{e}=a\\left(N_{a}, N_{b}\\right)^{e}=\\int_{\\Omega^{e}} N_{a, x} N_{b, x} d x\n",
      "\\tag{1.13.11}\\\\ & f_{a}^{e}=\\int_{\\Omega^{e}} N_{a} f d x+\\left\\{\\begin{array}{cl} \\delta_{a 1} h & e=1 \\\\ 0 & e=2,3, \\ldots, n_{e l}-1 \\\\ -k_{a 2 }^{e} g &\n",
      "e=n_{e l} \\end{array}\\right. \\tag{1.13.12} \\end{align*} \\begin{center} \\includegraphics[max width=\\textwidth]{2024_10_04_fba7dc36d090c246379ag-41} \\end{center}\n",
      "Here $\\boldsymbol{k}^{e}$ and $\\boldsymbol{f}^{e}$ are defined with respect to the local ordering, whereas $\\boldsymbol{K}^{e}$ and $\\boldsymbol{F}^{e}$ are\n",
      "defined with respect to the global ordering. To determine where the components of $k^{e}$ and $f^{e}$ \"go\" in $\\boldsymbol{K}$ and $\\boldsymbol{F}$,\n",
      "respectively, requires keeping additional information. This is discussed in the following section.\n",
      "\n",
      " 7: It is important for anyone who wishes to do finite element analysis to become familiar with the efficient and sophisticated computer schemes that arise in\n",
      "the finite element method. It is felt that the best way to do this is to begin with the simplest scheme, perform some hand calculations, and gradually increase\n",
      "the sophistication as time goes on. To do some of the problems we will need a fairly efficient method of solving matrix equations by hand. The following scheme\n",
      "is applicable to systems of equations\\\\ $\\boldsymbol{K} \\boldsymbol{d}=\\boldsymbol{F}$ in which no pivoting (i.e., reordering) is necessary. For example,\n",
      "symmetric, positive-definite coefficient matrices never require pivoting. The procedure is as follows: \\subsection*{Gauss Elimination} \\begin{itemize} \\item\n",
      "Solve the first equation for $d_{1}$ and elminate $d_{1}$ from the remaining $n-1$ equations. \\item Solve the second equation for $d_{2}$ and eliminate $d_{2}$\n",
      "from the remaining $n-2$ equations. \\item Solve the $n-1$ st equation for $d_{n-1}$ and eliminate $d_{n-1}$ from the $n$th equation. \\item Solve the $n$-th\n",
      "equation for $d_{n}$. \\end{itemize} The preceding steps are called forward reduction. The original matrix is reduced to upper triangular form. For example,\n",
      "suppose we began with a system of four equations as follows: $$ \\left[\\begin{array}{llll} K_{11} & K_{12} & K_{13} & K_{14} \\\\ K_{21} & K_{22} & K_{23} & K_{24}\n",
      "\\\\ K_{31} & K_{32} & K_{33} & K_{34} \\\\ K_{41} & K_{42} & K_{43} & K_{44} \\end{array}\\right]\\left\\{\\begin{array}{l} d_{1} \\\\ d_{2} \\\\ d_{3} \\\\ d_{4}\n",
      "\\end{array}\\right\\}=\\left\\{\\begin{array}{l} F_{1} \\\\ F_{2} \\\\ F_{3} \\\\ F_{4} \\end{array}\\right\\} $$ The augmented matrix corresponding to this system is \\[\n",
      "\\left[ \\begin{array}{cccc|c} K_{11} & K_{12} & K_{13} & K_{14} & F_1 \\\\ K_{21} & K_{22} & K_{23} & K_{24} & F_2 \\\\ K_{31} & K_{32} & K_{33} & K_{34} & F_3 \\\\\n",
      "K_{41} & K_{42} & K_{43} & K_{44} & F_4 \\\\ \\multicolumn{4}{c|}{\\underbrace{\\phantom{K_{11}\\, K_{12}\\, K_{13}\\, K_{14}}}_{K}} & \\underbrace{\\phantom{F_1}}_{F}\n",
      "\\end{array} \\right] \\] After the forward reduction, the augmented matrix becomes\\\\ \\[ \\left[ \\begin{array}{cccc|c} 1 & K'_{12} & K'_{13} & K‘_{14} & F'_1 \\\\ 0 &\n",
      "1 & K'_{23} & K'_{24} & F'_2 \\\\ 0 & 0 & 1 & K'_{34} & F'_3 \\\\ 0 & 0 & 0 & 1 & d_4 \\\\ \\multicolumn{4}{c|}{\\underbrace{\\phantom{K_{11}\\, K_{12}\\, K_{13}\\,\n",
      "K_{14}}}_{U}} & \\underbrace{\\phantom{F_1}}_{F'} \\end{array} \\tag{1.11.1} \\right] \\] corresponding to the upper triangular system $\\boldsymbol{U}\n",
      "\\boldsymbol{d}=\\boldsymbol{F}^{\\prime} \\cdot{ }^{4}$ It is a simply verified fact that if $\\boldsymbol{K}$ is banded, then $\\boldsymbol{U}$ will be also.\n",
      "Employing the reduced augmented matrix, proceed as follows: \\begin{itemize} \\item Eliminate $d_{n}$ from equations $n-1, n-2, \\ldots, 1$.\\\\ \\footnotetext{${\n",
      "}^{4} \\text{Primes will be used to denote intermediate quantities throughout this section}.$} \\item Eliminate $d_{n-1}$ from equations $n-2, n-3, \\ldots, 1$.\n",
      "\\item Eliminate $d_{2}$ from the first equation. \\end{itemize} This procedure is called back substitution. For example, in the example just given, after back\n",
      "substitution we obtain\\\\ \\[ \\left[ \\begin{array}{cccc|c} 1 & 0 & 0 & 0 & d_1 \\\\ 0 & 1 & 0 & 0 & d_2 \\\\ 0 & 0 & 1 & 0 & d_3 \\\\ 0 & 0 & 0 & 1 & d_4 \\\\\n",
      "\\multicolumn{4}{c|}{\\underbrace{\\phantom{K_{11}\\, K_{12}\\, K_{13}\\, K_{14}}}_{I}} & \\underbrace{\\phantom{F_1}}_{d} \\end{array} \\tag{1.11.2} \\right] \\]\n",
      "corresponding to the identity $1 \\boldsymbol{d}=\\boldsymbol{d}$. The solution winds up in the last column. \\subsection*{Hand-Calculation Algorthm} In a hand\n",
      "calculation, Gauss elimination can be performed on the augmented matrix as follows. \\subsection*{Forward reduction} \\begin{itemize} \\item Divide row 1 by\n",
      "$K_{11}$. \\item Subtract $K_{21} \\times$ row 1 from row 2. \\item Subtract $K_{31} \\times$ row 1 from row 3. \\item Subtract $K_{n 1} \\times$ row 1 from row $n$.\n",
      "\\end{itemize} Consider the example of four equations. The preceding steps reduce the first column to the form $$ \\left[\\begin{array}{llll|l} 1 &\n",
      "\\boldsymbol{K}_{12}^{\\prime} & \\boldsymbol{K}_{3}^{\\prime} & \\boldsymbol{K}_{14}^{\\prime} & \\boldsymbol{F}_{1}^{\\prime} \\\\ 0 & \\boldsymbol{K}_{22}^{\\prime\n",
      "\\prime} & \\boldsymbol{K}_{23}^{\\prime \\prime} & \\boldsymbol{K}_{24}^{\\prime \\prime} & \\boldsymbol{F}_{2}^{\\prime \\prime} \\\\ 0 & \\boldsymbol{K}_{32}^{\\prime} &\n",
      "\\boldsymbol{K}_{33}^{\\prime 3} & \\boldsymbol{K}_{34}^{\\prime} & \\boldsymbol{F}_{3}^{\\prime \\prime} \\\\ \\mathbf{0} & \\boldsymbol{K}_{42}^{\\prime} &\n",
      "\\boldsymbol{K}_{43}^{3} & \\boldsymbol{K}_{44}^{\\prime \\prime} & \\boldsymbol{F}_{4}^{\\prime \\prime} \\end{array}\\right] $$ Note that if $\\boldsymbol{K}_{\\mathbf{A\n",
      "1}}=0$, then the computation for the Ath row can be ignored. Now reduce the second column \\begin{itemize} \\item Divide row 2 by $K_{22}^{\\prime \\prime}$. \\item\n",
      "Subtract $K_{32}^{\\prime \\prime} \\times$ row 2 from row 3. \\item Subtract $K_{42}^{n} \\times$ row 2 from row 4. \\item Subtract $K_{n 2}^{\\prime \\prime} \\times$\n",
      "row 2 from row $n$. \\end{itemize} The result for the example will look like\\\\ $\\left[\\begin{array}{cccc|c}1 & \\boldsymbol{K}_{12}^{\\prime} &\n",
      "\\boldsymbol{K}_{13}^{\\prime} & \\boldsymbol{K}_{14}^{\\prime} & \\boldsymbol{F}_{1}^{\\prime} \\\\ 0 & 1 & \\boldsymbol{K}_{23}^{\\prime \\prime \\prime} &\n",
      "\\boldsymbol{K}_{24}^{\\prime \\prime \\prime} & \\boldsymbol{F}_{2}^{\\prime \\prime \\prime} \\\\ \\mathbf{0} & \\mathbf{0} & \\boldsymbol{K}_{33}^{\\prime \\prime \\prime} &\n",
      "\\boldsymbol{K}_{34}^{\\prime \\prime \\prime} & \\boldsymbol{F}_{3}^{\\prime \\prime \\prime} \\\\ \\mathbf{0} & \\mathbf{0} & \\boldsymbol{K}_{43}^{\\prime \\prime \\prime} &\n",
      "\\boldsymbol{K}_{44}^{\\prime \\prime\\prime} & \\boldsymbol{F}_{4}^{\\prime \\prime \\prime} \\\\ & & & & \\end{array}\\right]$ Note that only the submatrix enclosed in\n",
      "dashed lines is affected in this procedure.\\\\ Repeat until columns 3 to $n$ are reduced and the upper triangular form (1.11.1) is obtained. \\subsection*{Back\n",
      "substitution} \\begin{itemize} \\item Subtract $K_{n-1, n}^{\\prime} \\times$ row $n$ from row $n-1$. \\item Subtract $K_{n-2, n}^{\\prime} \\times$ row $n$ from row\n",
      "$n-2$.\\\\ \\vdots \\item Subtract $K_{1, n}^{\\prime} \\times$ row $n$ from row 1 \\end{itemize} After these steps the augmented matrix, for this example, will look\n",
      "like $$ \\left[\\begin{array}{cccc|c} 1 & \\bar{K}_{12}^{\\prime} & \\bar{K}_{3}^{\\prime} & 0 & F_{1}^{\\prime \\prime \\prime \\prime} \\\\ 0 & 1 & K_{23}^{\\prime} & 0 &\n",
      "F_{2}^{\\prime \\prime \\prime \\prime} \\\\ 0 & 0 & 1 & 0 & d_{3} \\\\ 0 & 0 & 0 & 1 & d_{4} \\end{array}\\right] $$ Note that the submatrix enclosed in dashed lines is\n",
      "unaffected by these steps, and, aside from zeroing the appropriate elements of the last column of the coefficient matrix, only the vector $F^{\\prime}$ is\n",
      "altered. Now clear the second-to-last column in the coefficient matrix: \\begin{itemize} \\item Subtract $K_{n-2, n-1}^{\\prime} \\times$ row $n-1$ from row $n-2$.\n",
      "\\item Subtract $K_{n-3, n-1}^{\\prime} \\times$ row $n-1$ from row $n-3$.\\\\ \\vdots \\item Subtract $K_{1 . n-1}^{\\prime} \\times$ row $n-1$ from row 1.\n",
      "\\end{itemize} Again we mention that the only nontrivial calculations are being performed on the last column (i.e., on $\\boldsymbol{F}$ ). Repeat as above until\n",
      "columns $\\boldsymbol{n}-2, n-3, \\ldots, 2$ are cleared. The result is (1.11.2). \\subsection*{Remarks} \\begin{enumerate} \\item In passing we note that the above\n",
      "procedure is not the same as the way one would implement Gauss elimination on a computer, which we shall treat later. In a computer program for Gauss\n",
      "elimination of symmetric matrices we would want all intermediate results to retain symmetry and thus save storage. This can be done by a small change in the\n",
      "procedure. However, it is felt that the given scheme is the clearest for hand calculations. \\item The numerical example with which we close this section\n",
      "illustrates the preceding elimination scheme. Note that the band is maintained (i.e., the zeros in the upper right-hand comer of the coefficient matrix remain\n",
      "zero throughout the calculations). The reader is urged to perform the calculations. \\end{enumerate} \\subsection*{Example of Gauss ellmination} $$\n",
      "\\left[\\begin{array}{rrrr} 1 & -1 & 0 & 0 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 2 \\end{array}\\right]\\left\\{\\begin{array}{l} d_{1} \\\\ d_{2} \\\\\n",
      "d_{3} \\\\ d_{4} \\end{array}\\right\\}=\\left\\{\\begin{array}{l} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{array}\\right\\} $$ \\subsection*{Augmented matrix} $$ \\left[\\begin{array}{rrrr|r}\n",
      "1 & -1 & 0 & 0 & 1 \\\\ -1 & 2 & -1 & 0 & 0 \\\\ 0 & -1 & 2 & -1 & 0 \\\\ 0 & 0 & -1 & 2 & 0 \\end{array}\\right] $$ Forward reduction $$ \\begin{aligned} &\n",
      "{\\left[\\begin{array}{rrrr|r} 1 & -1 & 0 & 0 & 1 \\\\ 0 & 1 & -1 & 0 & 1 \\\\ 0 & -1 & 2 & -1 & 0 \\\\ 0 & 0 & -1 & 2 & 0 \\end{array}\\right]} \\\\ &\n",
      "{\\left[\\begin{array}{rrrr|r} 1 & -1 & 0 & 0 & 1 \\\\ 0 & 1 & -1 & 0 & 1 \\\\ 0 & 0 & 1 & -1 & 1 \\\\ 0 & 0 & -1 & 2 & 0 \\end{array}\\right]} \\\\ &\n",
      "{\\left[\\begin{array}{rrrr|r} 1 & -1 & 0 & 0 & 1 \\\\ 0 & 1 & -1 & 0 & 1 \\\\ 0 & 0 & 1 & -1 & 1 \\\\ 0 & 0 & 0 & 1 & 1 \\end{array}\\right]} \\end{aligned} $$\n",
      "\\subsection*{Back substitution} $$ \\begin{aligned} & {\\left[\\begin{array}{rrrr|r} 1 & -1 & 0 & 0 & 1 \\\\ 0 & 1 & -1 & 0 & 1 \\\\ 0 & 0 & 1 & 0 & 2 \\\\ 0 & 0 & 0 & 1\n",
      "& 1 \\end{array}\\right]} \\\\ & {\\left[\\begin{array}{rrrr|r} 1 & -1 & 0 & 0 & 1 \\\\ 0 & 1 & 0 & 0 & 3 \\\\ 0 & 0 & 1 & 0 & 2 \\\\ 0 & 0 & 0 & 1 & 1 \\end{array}\\right]}\n",
      "\\\\ & {\\left[\\begin{array}{rrrr|r} 1 & 0 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 0 & 3 \\\\ 0 & 0 & 1 & 0 & 2 \\\\ 0 & 0 & 0 & 1 & 1 \\end{array}\\right]} \\\\ \\begin{array}{l}\n",
      "\\left\\{ \\begin{array}{l} d_{1} \\\\ d_{2} \\\\ d_{3} \\\\ d_{4} \\end{array} \\right\\} = \\left\\{ \\begin{array}{l} 4 \\\\ 3 \\\\ 2 \\\\ 1 \\end{array} \\right\\} \\end{array}\n",
      "\\end{aligned} $$ Exercise 1. Consider the boundary-value problem discussed in the previous sections: $$ \\begin{aligned} u_{, x x}(x)+f(x) & =0 \\quad x \\in] 0,1[\n",
      "\\\\ u(1) & =g \\\\ -u_{, x}(0) & =h \\end{aligned} $$ Assume $f=g x$, where $g$ is constant, and $g=h=0$.\\\\ a. Employing the linear finite element space with\n",
      "equally spaced nodes, set up and solve the Galerkin finite element equations for $n=4\\left(h=\\right.$ mesh parameter $\\left.=\\frac{1}{4}\\right)$. Recall that in\n",
      "Sec. 1.7 this was carried out for $n=1$ and $n=2\\left(h=1\\right.$ and $h=\\frac{1}{2}$, respectively). Do not invert the ctiffness matrix $K$; use Gauss\n",
      "elimination to solve $\\boldsymbol{K} \\boldsymbol{d}=\\boldsymbol{F}$ or a more sophisticated direct factorization scheme if you know one. You can check your\n",
      "answers since they must be exact at the nodes.\\\\ b. Let $r e_{, x}=\\left|u_{, x}^{h}-u_{. x}\\right| /(q / 2)$, the relative error in $u_{. x}$. Compute $r e_{,\n",
      "x}$ at the midpoints of the four elements. They should all be equal. (This was also the case for $n=2$.)\\\\ c. Employing the data for $h=1, \\frac{1}{2}$, and\n",
      "$\\frac{1}{4}$, plot $\\ln r e_{, x}$ versus $\\ln h$.\\\\ d. Using the error analysis for $r e_{, x}$ at the midpoints presented in Sec. 1.10, answer the following\n",
      "questions:\\\\ i. What is the significance of the slope of the graph in part (c)?\\\\ ii. What is the significance of the $y$-intercept?\n",
      "\n",
      " 8: We have already noted that the definition of the ID array must be generalized for the present case as indicated in Sec. 2.8. We iniust also generalize our\n",
      "definition of the LM array. However, the IEN array remains the same as before. In the present and fully general cases, the LM array is three-dimensional, with\n",
      "dimensions $\\boldsymbol{n}_{e d} \\times \\boldsymbol{n}_{e n} \\times \\boldsymbol{n}_{e l}$, and is defined by\\\\ \\[ \\text{LM}(i, a, e) = \\text{ID}(i,\n",
      "\\text{IEN}(a, e)) \\] \\begin{itemize} \\item $i$: Degrees of freedom number \\item $a$: Local node number \\item $e$: Element number \\end{itemize} Alternatively, it\n",
      "is sometimes convenient to think of LM as two-dimensional, with dimensions $n_{e e} \\times n_{e l}$, viz., ${ }^{17}$ \\begin{align*} &\n",
      "\\mathrm{LM}(\\underbrace{p}_{\\text{Local equation number}}, \\underbrace{e}_{\\text{Element number}})=\\mathrm{LM}(i, a, e), \\quad p=n_{e d}(a-1)+i \\end{align*} To\n",
      "see how everything works in practice, it is helpful to run through a simple example. \\subsection*{Example 1} Consider the mesh of four-node, rectangular\n",
      "elements illustrated in Fig. 2.10.1. We assume that the local node numbering begins in the lower left-hand corner for each element and proceeds in\n",
      "counterclockwise fashion. \\footnotetext[16]{The $g$-boundary conditions are accounted for in this definition.\\\\ ${ }^{17}$ The reader knowledgeable in FORTRAN\n",
      "will realize that the intemal computer storage of (2.10.1) and (2.10.2) is identical. }This is shown for element 4, which is typical. Four displacement (i.e., \"\n",
      "$g$-type\") boundary conditions are specified; namely, the horizontal displacement is specified at nodes 1 and 10 , and the vertical displacement is specified at\n",
      "nodes 1 and 3. Since $n_{\\text {np}}=12, n_{\\text {dof }}=n_{\\text {ed }}=2$, and 4 displacement degrees of freedom are specified, we have $n_{e q}=20$. As is\n",
      "usual, we adopt the convention that the global equation numbers run in ascending order with respect to the ascending order of global node numbers. ${ }^{18}$\n",
      "The ID, IEN, and LM arrays are given in Figure 2.10.2. The reader is urged to verify the results.\\\\ \\includegraphics[max width=\\textwidth,\n",
      "center]{images/chapter2.10.1.png} Figure 2.10.1 Mesh of four-node, rectangular, elasticity elements; global and local node numbers, element numbers, and\n",
      "displacement boundary conditions. In terms of the IEN and LM arrays, a precise definition of the $g_{p}^{e}$ 's may be given (see (2.9.5)): \\[ g_{p}^{e}=g_{i\n",
      "a}^{e}= \\begin{cases}0, & \\text { if } \\mathrm{LM}(i, a, e) \\neq 0 \\tag{2.10.3}\\\\ g_{i A}, & \\text { where } A=\\operatorname{IEN}(a, e), \\text { if }\n",
      "\\mathrm{LM}(i, a, e)=0\\end{cases} \\] This definition may be easily programmed.\\\\ ${ }^{18}$ In practice, equation numbers are often renumbered internally to\n",
      "minimize the bandwidth of $\\boldsymbol{K}$ and thus decrease storage and solution effort. This is especially important in analyzing large-scale systems\n",
      "involving tens of thousands of equations. An algorithm for reducing bandwidth is presented in [8]. \\includegraphics[max width=\\textwidth,\n",
      "center]{images/chapter2.10.2.png} \\subsection*{Example 2} As a final example, we consider a typical four-node, elasticity element in some large mesh; see Fig.\n",
      "2.10.3. We assume the pertinent entries of the ID array are given as follows: \\[ \\left.\\begin{array}{l} \\operatorname{ID}(1,32)=0 \\\\ \\operatorname{ID}(2,32)=0\n",
      "\\\\ \\operatorname{ID}(1,59)=115 \\\\ \\operatorname{ID}(2,59)=116 \\\\ \\operatorname{ID}(1,164)=0 \\tag{2.10.4}\\\\ \\operatorname{ID}(2,164)=325 \\\\\n",
      "\\operatorname{ID}(1,168)=332 \\\\ \\operatorname{ID}(2,168)=333 \\end{array}\\right\\} \\] The entries of IEN follow from Fig. 2.10.3: \\[ \\left.\\begin{array}{l}\n",
      "\\operatorname{IEN}(1, e)=164 \\\\ \\operatorname{IEN}(2, e)=32 \\\\ \\operatorname{IEN}(3, e)=168 \\tag{2.10.5}\\\\ \\operatorname{IEN}(4, e)=59 \\end{array}\\right\\} \\]\n",
      "\\includegraphics[max width=\\textwidth, center]{2024_10_04_037012b2cd72c3baccfbg-39}\\\\ (i) - Local node numbers Tigure 2.10.3 Typical four-node elasticity\n",
      "element; global and local node numbers. Combining (2.10.4) and (2.10.5), by way of (2.10.1), yields entries of the LM array: \\[ \\left.\\begin{array}{l}\n",
      "\\operatorname{LM}(1,1, e)=0 \\tag{2.10.6}\\\\ \\operatorname{LM}(2,1, e)=325 \\\\ \\operatorname{LM}(1,2, e)=0 \\\\ \\operatorname{LM}(2,2, e)=0 \\\\ \\operatorname{LM}(1,3,\n",
      "e)=332 \\\\ \\operatorname{LM}(2,3, e)=333 \\\\ \\operatorname{LM}(1,4, e)=115 \\\\ \\operatorname{LM}(2,4, e)=116 \\end{array}\\right\\} \\] The contribution to the global\n",
      "arrays may be deduced from LM:\\\\ Stiffness (due to symmetry, only the upper triangular portion need be assembled.) \\[ \\left.\\begin{array}{l} K_{115,115}\n",
      "\\leftarrow K_{115,115}+k_{77}^{e} \\\\ K_{115,116}^{e} \\leftarrow K_{115,116}+k_{78}^{e} \\\\ K_{115,325} \\leftarrow K_{115,325}+k_{72}^{e} \\\\ K_{115,332}\n",
      "\\leftarrow K_{115,332}+k_{75}^{e} \\\\ K_{115,333} \\leftarrow K_{115,333}+k_{76}^{e} \\\\ K_{116,116} \\leftarrow K_{116,116}+k_{88}^{e} \\\\ K_{116,325} \\leftarrow\n",
      "K_{116,325}+k_{82}^{e} \\\\ K_{116,332} \\leftarrow K_{116,332}+k_{85}^{e} \\tag{2.10.7}\\\\ K_{116,333} \\leftarrow K_{116,333}+k_{86}^{e} \\\\ K_{325,325} \\leftarrow\n",
      "K_{325,325}+k_{22}^{e} \\\\ K_{325,332} \\leftarrow K_{325,332}+k_{25}^{e} \\\\ K_{325,333} \\leftarrow K_{325,333}+k_{26}^{e} \\\\ K_{332,332} \\leftarrow\n",
      "K_{332,332}+k_{55}^{e} \\\\ K_{332,333} \\leftarrow K_{332,333}+k_{56}^{e} \\\\ K_{333,333} \\leftarrow K_{333,333}+k_{66}^{e} \\end{array}\\right\\} \\] Force \\[\n",
      "\\left.\\begin{array}{l} F_{115} \\leftarrow F_{115}+f_{7}^{e} \\tag{2.10.8}\\\\ F_{116} \\leftarrow F_{116}+f_{8}^{e} \\\\ F_{325} \\leftarrow F_{325}+f_{2}^{e} \\\\\n",
      "F_{332} \\leftarrow F_{332}+f_{5}^{e} \\\\ F_{333} \\leftarrow F_{333}+f_{6}^{e} \\end{array}\\right\\} \\] where \\begin{equation*} f_{p}^{e}=\\cdots-\\sum_{q=1}^{n_{eq}}\n",
      "k_{p q}^{e} g_{q}^{e} \\tag{2.10.9} \\end{equation*} (We have omitted the first two terms in the right-hand side of (2.9.5) in writing (2.10.9).) In the present\n",
      "example, only $g_{1}^{e}, g_{3}^{e}$ and $g_{4}^{e}$ may be nonzero. Therefore (2.10.9) may be simplified to \\begin{equation*} f_{p}^{e}=\\cdots-k_{p 1}^{e}\n",
      "g_{1}^{e}-k_{p 3}^{e} g_{3}^{e}-k_{p 4}^{e} g_{4}^{e} \\tag{2.10.10} \\end{equation*} The multiplications indicated in (2.10.10) are only performed in practice if\n",
      "the $g_{p}^{e}$ 's are nonzero. A schematic representation of the contributions of $k^{e}$ and $f^{e}$ to $K$ and $F$ is shown in Figure 2.10.4.\\\\\n",
      "\\includegraphics[max width=\\textwidth, center]{2024_10_04_037012b2cd72c3baccfbg-41} Figure 2.10.4 Contributions of elasticity element in Example 2 to global\n",
      "arrays. \\subsection*{Exercise 1.} Consider a two-dimensional elastostatic boundary-value problem. Set up the ID, IEN, and LM arrays for the following mesh of\n",
      "four-node quadrilaterals:\\\\ \\includegraphics[max width=\\textwidth, center]{2024_10_04_037012b2cd72c3baccfbg-42}\n",
      "\n",
      " 9: In the discrete Rayleigh-Ritz approach, static load patterns, $\\boldsymbol{P}$, are selected and corresponding displacement vectors, $\\boldsymbol{R}$, are\n",
      "calculated from:\\\\ where $n_{l p}$ refers to the number of load patterns. The displacements $R$, referred to as the trial vectors, are used to form the reduced\n",
      "eigenproblem, i.e., (10.1.7) by defining \\begin{align*} K^{*} & =\\boldsymbol{R}^{T} \\boldsymbol{K} \\boldsymbol{R} \\tag{10.3.2}\\\\ M^{*} & =\\boldsymbol{R}^{T}\n",
      "\\boldsymbol{M R} \\tag{10.3.3} \\end{align*} The load patterns, $\\boldsymbol{P}$, are usually subject to the following criteria:\\\\ i. The columns of\n",
      "$\\boldsymbol{P}$ should be linearly independent.\\\\ ii. The columns of $\\textbf{P}$ should be selected to arouse the low modes by activating the heaviest masses\n",
      "and most flexible areas of the model. \\subsection*{Remarks} \\begin{enumerate} \\item If $n_{l p}$ is small, $K^{*}$ and $M^{*}$ will be full, but small. \\item\n",
      "Equation (10.3.1) amounts to solution of a multiple right-hand-side system with profile coefficient matrix. \\item The discrete Rayleigh-Ritz procedure is a\n",
      "general formalism for obtaining the reduced system. However, the guidelines for selecting $\\boldsymbol{P}$ are somewhat vague and thus a more systematic\n",
      "strategy is required for practical use. \\item The discrete Rayleigh-Ritz reduction is often referred to as a \"projection method.\" \\item The eigenvector\n",
      "approximations are defined by $\\boldsymbol{\\Psi \\cong R \\Psi^*}$. \\item By virtue of the fact that the calculation of trial vectors from load patterns requires\n",
      "solution of (10.3.1), $\\boldsymbol{K}$ must be nonsingular. This precludes application to cases in which there are zero eigenvalues (e.g., structures which\n",
      "possess rigid body modes). A simple reformulation of the original problem involving a positive shifting of the eigenvalues allows us to handle this case: Note\n",
      "that by adding and subtracting $\\boldsymbol{\\alpha M} \\boldsymbol{\\Psi}$, where $\\boldsymbol{\\alpha}$ is a positive number, we produce an eigenproblem\n",
      "\\end{enumerate} \\begin{align*} (\\boldsymbol{\\overline{K}}-\\bar{\\lambda} \\boldsymbol{M}) \\Psi & =0 \\tag{10.3.4}\\\\ \\boldsymbol{\\overline{K}} &\n",
      "=\\boldsymbol{K}+\\alpha \\boldsymbol{M} \\tag{10.3.5}\\\\ \\bar{\\lambda} & =\\lambda+\\alpha \\tag{10.3.6} \\end{align*} in which $\\overline{\\boldsymbol{K}}$ is positive-\n",
      "definite, and the eigenvectors are unchanged. The eigenvalues are related by (10.3.6). This stratagem may also be employed if some of the $\\lambda$ 's are\n",
      "negative. Suppose an estimate of the smallest eigenvalue, $\\lambda_{1}$, is available. Then select $\\alpha>0$ such that $-\\alpha<\\lambda_{1} \\leq 0$. The\n",
      "$\\bar{\\lambda}$ 's are then all positive and solution may proceed as usual.\\\\ 7. Shifting is a particular example of a general class of spectral\n",
      "transformations. Let \\begin{equation*} S=\\left[\\Psi_{1}, \\Psi_{2}, \\ldots, \\Psi_{n_{e q}}\\right] \\tag{10.3.7} \\end{equation*} and \\begin{equation*}\n",
      "\\mathbf{\\Lambda}=\\operatorname{diag}\\left(\\lambda_{1}, \\lambda_{2}, \\ldots, \\lambda_{n_{\\text {eq }}}\\right) \\tag{10.3.8} \\end{equation*} Then it is easily\n",
      "verified that \\begin{equation*} \\boldsymbol{K}=\\boldsymbol{S} \\boldsymbol{\\Lambda} \\boldsymbol{S}^{\\boldsymbol{T}} \\tag{10.3.9} \\end{equation*} and\n",
      "\\begin{equation*} \\boldsymbol{M=S S^{T}} \\tag{10.3.10} \\end{equation*} Let $f=f(\\lambda)$ represent a scalar-valued function of $\\lambda$. Define a matrix-\n",
      "valued function $\\boldsymbol{f}=\\boldsymbol{f}(\\boldsymbol{K})$ by way of \\begin{equation*} f(K)=S \\operatorname{diag}\\left(f\\left(\\lambda_{1}\\right),\n",
      "f\\left(\\lambda_{2}\\right), \\ldots, f\\left(\\lambda_{n_{\\text {eq }}}\\right)\\right) S^{T} \\tag{10.3.11} \\end{equation*} Then it is readily established that\n",
      "solutions of the eigenproblem \\begin{equation*} (f(K)-\\bar{\\lambda} M) \\phi=0 \\tag{10.3.12} \\end{equation*} are related to solutions of \\begin{equation*}\n",
      "(\\boldsymbol{K}-\\lambda M) \\boldsymbol{\\Psi}=\\mathbf{0} \\tag{10.3.13} \\end{equation*} by \\begin{align*} \\bar{\\lambda} & =f(\\lambda) \\tag{10.3.14}\\\\ \\phi & =\\psi\n",
      "\\tag{10.3.15} \\end{align*} \\textbf{Exercise 1.} Consider the partitioned eigenproblem defined by (10.2.1). Show that the statically condensed eigenproblem,\n",
      "(10.2.4) and (10.2.5), can be obtained from the discrete Rayleigh-Ritz approach by selecting the trial vectors to be \\[ R=\\left[\\begin{array}{ccc} \\quad \\quad\n",
      "\\quad \\boldsymbol{I} & \\tag{10.3.16}\\\\ \\hdashline-\\boldsymbol{K}_{22}^{1} & \\boldsymbol{K}_{21} \\end{array}\\right] \\]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 9  # try different QAs\n",
    "\n",
    "print('Q:')\n",
    "print_wrapped(df.iloc[i,:]['question'])\n",
    "print('A:')\n",
    "print_wrapped(df.iloc[i,:]['answer'])\n",
    "print('\\nChunk used for Q generation:')\n",
    "print_wrapped(df.iloc[i,:]['question_chunk'])\n",
    "print('\\nRetrieved context:')\n",
    "for item in df.iloc[i,:]['context'].split('Additional context'):\n",
    "    print_wrapped(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
